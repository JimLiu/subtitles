[Script Info]

Title: LangChain_L2_v02
ScriptType: v4.00+
WrapStyle: 0
Collisions: Reverse
PlayResX: 384
PlayResY: 288
Timer: 100.0000
ScaledBorderAndShadow: no
Last Style Storage: Default
Video Aspect Ratio: 0
Video Zoom: 6
Video Position: 0

[V4+ Styles]
Format: Name,Fontname,Fontsize,PrimaryColour,SecondaryColour,OutlineColour,BackColour,Bold,Italic,Underline,StrikeOut,ScaleX,ScaleY,Spacing,Angle,BorderStyle,Outline,Shadow,Alignment,MarginL,MarginR,MarginV,Encoding
Style: Default,LXGW WenKai,16,&H000092FE,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,2,2,1,1,6,1
Style: Secondary,Helvetica,10,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,2,2,1,1,6,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:05.0,0:00:07.0,Secondary,,0,0,0,,When you interact with these models,
Dialogue: 0,0:00:07.0,0:00:12.16,Secondary,,0,0,0,,naturally they don't remember what you say before or any of the previous conversation,
Dialogue: 0,0:00:12.16,0:00:17.68,Secondary,,0,0,0,,which is an issue when you're building some applications like Chatbot and you want to have a conversation with them.
Dialogue: 0,0:00:17.68,0:00:20.52,Secondary,,0,0,0,,And so in this section, we'll cover memory,
Dialogue: 0,0:00:20.52,0:00:26.24,Secondary,,0,0,0,,which is basically how do you remember previous parts of the conversation and feed that into the language model,
Dialogue: 0,0:00:26.24,0:00:30.44,Secondary,,0,0,0,,so that they can have this conversational flow as you're interacting with them.
Dialogue: 0,0:00:30.44,0:00:36.4,Secondary,,0,0,0,,Yep. So, LangChain offers multiple sophisticated options for managing these memories.
Dialogue: 0,0:00:36.4,0:00:38.4,Secondary,,0,0,0,,Let's jump in and take a look.
Dialogue: 0,0:00:38.4,0:00:44.24,Secondary,,0,0,0,,So, let me start off by importing my OpenAI API key,
Dialogue: 0,0:00:44.24,0:00:47.44,Secondary,,0,0,0,,and then let me import a few tools that I'll need.
Dialogue: 0,0:00:47.44,0:00:50.80,Secondary,,0,0,0,,Let's use as the motivating example for memory,
Dialogue: 0,0:00:50.80,0:00:55.44,Secondary,,0,0,0,,using LangChain to manage a chat or a chatbot conversation.
Dialogue: 0,0:00:55.44,0:01:02.64,Secondary,,0,0,0,,So, to do that, I'm going to set the LLM as a chat interface of OpenAI with temperature equals 0.
Dialogue: 0,0:01:02.64,0:01:09.56,Secondary,,0,0,0,,And, um, I'm going to use the memory as a ConversationBufferMemory.
Dialogue: 0,0:01:09.56,0:01:12.40,Secondary,,0,0,0,,And you'll see later what this means.
Dialogue: 0,0:01:12.40,0:01:15.80,Secondary,,0,0,0,,Um, and I'm going to build a conversation chain.
Dialogue: 0,0:01:15.80,0:01:18.4,Secondary,,0,0,0,,Again, later in this short course,
Dialogue: 0,0:01:18.4,0:01:23.32,Secondary,,0,0,0,,Harrison will dive much more deeply into what exactly is a chain in LangChain.
Dialogue: 0,0:01:23.32,0:01:26.68,Secondary,,0,0,0,,So, don't worry too much about the details of the syntax for now.
Dialogue: 0,0:01:26.68,0:01:28.92,Secondary,,0,0,0,,But this builds an LLM.
Dialogue: 0,0:01:28.92,0:01:32.12,Secondary,,0,0,0,,And if I start to have a conversation,
Dialogue: 0,0:01:32.12,0:01:36.84,Secondary,,0,0,0,,"conversation.predict", give the input, "Hi, my name is Andrew."
Dialogue: 0,0:01:36.84,0:01:38.96,Secondary,,0,0,0,,Let's see what it says.
Dialogue: 0,0:01:38.96,0:01:40.40,Secondary,,0,0,0,,"Hello, Andrew. It's nice to meet you."
Dialogue: 0,0:01:40.40,0:01:41.44,Secondary,,0,0,0,,Right? And so on.
Dialogue: 0,0:01:41.44,0:01:44.4,Secondary,,0,0,0,,And then, let's say I ask it,
Dialogue: 0,0:01:44.4,0:01:46.64,Secondary,,0,0,0,,"What is one plus one?"
Dialogue: 0,0:01:46.64,0:01:49.20,Secondary,,0,0,0,,Um, one plus one is two.
Dialogue: 0,0:01:49.20,0:01:51.40,Secondary,,0,0,0,,And then, ask it again,
Dialogue: 0,0:01:51.40,0:01:53.0,Secondary,,0,0,0,,"You know, what's my name?"
Dialogue: 0,0:01:53.0,0:01:54.92,Secondary,,0,0,0,,"Your name is Andrew, as you mentioned earlier."
Dialogue: 0,0:01:54.92,0:01:58.68,Secondary,,0,0,0,,"Hmm, there's a lot of trace of sarcasm there. Not sure."
Dialogue: 0,0:01:58.68,0:02:05.64,Secondary,,0,0,0,,And so if you want, you can change this "verbose" variable to "True", to see what LangChain is actually doing.
Dialogue: 0,0:02:05.64,0:02:08.84,Secondary,,0,0,0,,When you run, um, predict, "Hi, my name is Andrew."
Dialogue: 0,0:02:08.84,0:02:11.40,Secondary,,0,0,0,,This is the prompt that LangChain is generating.
Dialogue: 0,0:02:11.40,0:02:16.64,Secondary,,0,0,0,,It says, "The following is a friendly conversation between a human and an AI as talkative," and so on.
Dialogue: 0,0:02:16.64,0:02:25.92,Secondary,,0,0,0,,So this is a prompt that LangChain has generated to have the system have a hopeful and friendly conversation and it has to say the conversation and here's the response.
Dialogue: 0,0:02:25.92,0:02:30.92,Secondary,,0,0,0,,And when you execute this on the,
Dialogue: 0,0:02:33.56,0:02:35.56,Secondary,,0,0,0,,it keeps the prompt as follows.
Dialogue: 0,0:02:35.56,0:02:39.48,Secondary,,0,0,0,,And notice that by the time I'm uttering, "What is my name?"
Dialogue: 0,0:02:39.48,0:02:42.76,Secondary,,0,0,0,,This is the third turn, that's my third input.
Dialogue: 0,0:02:42.76,0:02:47.40,Secondary,,0,0,0,,It has stored the current conversation as follows.
Dialogue: 0,0:02:47.40,0:02:48.60,Secondary,,0,0,0,,"Hi, my name is Andrew.
Dialogue: 0,0:02:48.60,0:02:49.84,Secondary,,0,0,0,,What is one plus one?"
Dialogue: 0,0:02:49.84,0:02:56.76,Secondary,,0,0,0,,And so on. And so this memory or this history of a conversation gets longer and longer.
Dialogue: 0,0:02:56.76,0:03:01.88,Secondary,,0,0,0,,In fact, up on top, I had used the memory variable to store the memory.
Dialogue: 0,0:03:01.88,0:03:08.40,Secondary,,0,0,0,,So if I were to print "memory.buffer", it has stored the conversation so far.
Dialogue: 0,0:03:08.40,0:03:13.52,Secondary,,0,0,0,,Um, you can also print this out, "memory.load_memory_variables".
Dialogue: 0,0:03:13.52,0:03:17.94,Secondary,,0,0,0,,Um, the curly braces here is actually an empty dictionary.
Dialogue: 0,0:03:17.94,0:03:24.92,Secondary,,0,0,0,,There's some more advanced features that you can use with a more sophisticated input, but we won't talk about them in this short course.
Dialogue: 0,0:03:24.92,0:03:28.36,Secondary,,0,0,0,,So don't worry about why there's an empty curly braces here.
Dialogue: 0,0:03:28.36,0:03:33.44,Secondary,,0,0,0,,But this is what LangChain has remembered in the memory of the conversation so far.
Dialogue: 0,0:03:33.44,0:03:38.12,Secondary,,0,0,0,,It's just everything that the AI or that the human has said.
Dialogue: 0,0:03:38.12,0:03:41.12,Secondary,,0,0,0,,I encourage you to pause the video and run the code.
Dialogue: 0,0:03:41.12,0:03:48.81,Secondary,,0,0,0,,So the way that LangChain is storing the conversation is with this ConversationBufferMemory.
Dialogue: 0,0:03:48.81,0:03:54.96,Secondary,,0,0,0,,in order to use the ConversationBufferMemory, to specify a couple of inputs and outputs.
Dialogue: 0,0:03:54.96,0:03:59.8,Secondary,,0,0,0,,This is how you add new things to the memory if you wish to do so explicitly.
Dialogue: 0,0:03:59.8,0:04:02.80,Secondary,,0,0,0,,"memory.save_context" says, "Hi, what's up?"
Dialogue: 0,0:04:02.80,0:04:08.84,Secondary,,0,0,0,,I know this is not the most exciting conversation, but I wanted to have a short example.
Dialogue: 0,0:04:08.84,0:04:15.22,Secondary,,0,0,0,,Um, and with that, this is what the status of the memory is.
Dialogue: 0,0:04:15.22,0:04:21.24,Secondary,,0,0,0,,And once again, let me actually show the memory variables.
Dialogue: 0,0:04:21.24,0:04:27.24,Secondary,,0,0,0,,Now, if you want to add additional data to the memory,
Dialogue: 0,0:04:27.24,0:04:29.32,Secondary,,0,0,0,,you can keep on saving additional context.
Dialogue: 0,0:04:29.32,0:04:33.68,Secondary,,0,0,0,,So conversation goes on, not much, just hanging, cool.
Dialogue: 0,0:04:33.68,0:04:38.4,Secondary,,0,0,0,,And if you print out the memory, you know, there's now more stuff in it.
Dialogue: 0,0:04:38.4,0:04:42.64,Secondary,,0,0,0,,So when you use a large language model for a chat conversation,
Dialogue: 0,0:04:42.64,0:04:46.62,Secondary,,0,0,0,,um, the large language model itself is actually stateless.
Dialogue: 0,0:04:46.62,0:04:51.60,Secondary,,0,0,0,,The language model itself does not remember the conversation you've had so far.
Dialogue: 0,0:04:51.60,0:04:55.40,Secondary,,0,0,0,,And each transaction, each call to the API endpoint is independent.
Dialogue: 0,0:04:55.40,0:05:07.40,Secondary,,0,0,0,,And chatbots appear to have memory only because there's usually rapid code that provides the full conversation that's been had so far as context to the LLM.
Dialogue: 0,0:05:07.40,0:05:15.0,Secondary,,0,0,0,,And so the memory can store explicitly the terms or the utterances so far, "Hi, my name is Andrew."
Dialogue: 0,0:05:15.0,0:05:16.68,Secondary,,0,0,0,,"Hello, it's just nice to meet you," and so on.
Dialogue: 0,0:05:16.68,0:05:21.80,Secondary,,0,0,0,,And this memory storage is used as input or additional context to the LLM,
Dialogue: 0,0:05:21.80,0:05:29.86,Secondary,,0,0,0,,so that it can generate an output as if it's just having the next conversational turn knowing what's been said before.
Dialogue: 0,0:05:29.86,0:05:33.64,Secondary,,0,0,0,,And as the conversation becomes long,
Dialogue: 0,0:05:33.64,0:05:40.24,Secondary,,0,0,0,,the amounts of memory needed becomes really, really long and does the cost of sending a lot of tokens to the LLM,
Dialogue: 0,0:05:40.24,0:05:46.48,Secondary,,0,0,0,,which usually charges based on the number of tokens it needs to process, will also become more expensive.
Dialogue: 0,0:05:46.48,0:05:54.24,Secondary,,0,0,0,,So LangChain provides several convenient kinds of memory to store and accumulate the conversation.
Dialogue: 0,0:05:54.24,0:05:57.90,Secondary,,0,0,0,,So far, we've been looking at the conversation buffer memory.
Dialogue: 0,0:05:57.90,0:06:00.36,Secondary,,0,0,0,,Let's look at a different type of memory.
Dialogue: 0,0:06:00.36,0:06:09.80,Secondary,,0,0,0,,I'm going to import the ConversationBufferWindowMemory, that only keeps a window of memory.
Dialogue: 0,0:06:09.80,0:06:14.28,Secondary,,0,0,0,,If I set memory to ConversationBufferWindowMemory with k equals 1,
Dialogue: 0,0:06:14.28,0:06:20.52,Secondary,,0,0,0,,the variable k equals 1 specifies that I wanted to remember just one conversational exchange.
Dialogue: 0,0:06:20.52,0:06:25.36,Secondary,,0,0,0,,That is, one utterance from me and one utterance from the chatbot.
Dialogue: 0,0:06:25.36,0:06:31.28,Secondary,,0,0,0,,So now if I were to have it save context, "Hi, what's up? No much, just hanging."
Dialogue: 0,0:06:31.28,0:06:38.82,Secondary,,0,0,0,,If I were to look at "memory.load_variables", it only remembers the most recent utterance.
Dialogue: 0,0:06:38.82,0:06:40.76,Secondary,,0,0,0,,Notice it's dropped, "Hi, what's up?"
Dialogue: 0,0:06:40.76,0:06:45.44,Secondary,,0,0,0,,It's just saying, "Human says not much, just hanging" and the AI says, "Cool."
Dialogue: 0,0:06:45.44,0:06:47.92,Secondary,,0,0,0,,So that's because k was equal to 1.
Dialogue: 0,0:06:47.92,0:06:56.16,Secondary,,0,0,0,,So this is a nice feature because it lets you keep track of just the most recent few conversational terms.
Dialogue: 0,0:06:56.16,0:07:02.92,Secondary,,0,0,0,,In practice, you probably won't use this with k equals 1, you use this with k set to a larger number.
Dialogue: 0,0:07:02.92,0:07:10.42,Secondary,,0,0,0,,But still, this prevents the memory from growing without limit, as the conversation goes longer.
Dialogue: 0,0:07:10.42,0:07:25.58,Secondary,,0,0,0,,And so if I were to rerun the conversation that we had just now, we'll say, "Hi, my name is Andrew. What is 1 plus 1?"
Dialogue: 0,0:07:25.58,0:07:30.98,Secondary,,0,0,0,,And now I ask it, "What is my name?"
Dialogue: 0,0:07:30.98,0:07:33.54,Secondary,,0,0,0,,Because k equals 1,
Dialogue: 0,0:07:37.24,0:07:41.26,Secondary,,0,0,0,,The answer is 1 plus 1 equals 2, and it's forgotten this early exchange which is now,
Dialogue: 0,0:07:41.26,0:07:45.6,Secondary,,0,0,0,,now says, "Sorry, don't have access to that information."
Dialogue: 0,0:07:45.6,0:07:56.66,Secondary,,0,0,0,,One thing I hope you will do is pause the video, change this to "True" in the code on the left, and rerun this conversation with verbose equals "True".
Dialogue: 0,0:07:56.66,0:08:00.54,Secondary,,0,0,0,,And then you will see the prompts actually used to generate this.
Dialogue: 0,0:08:00.54,0:08:07.84,Secondary,,0,0,0,,And hopefully you'll see that the memory, when you're calling the LLM on what is my name,
Dialogue: 0,0:08:07.84,0:08:15.92,Secondary,,0,0,0,,that the memory has dropped this exchange where it learned what is my name, which is why it now says it doesn't know what is my name.
Dialogue: 0,0:08:15.92,0:08:28.32,Secondary,,0,0,0,,With the ConversationalTokenBufferMemory, the memory will limit the number of tokens saved.
Dialogue: 0,0:08:28.32,0:08:38.58,Secondary,,0,0,0,,And because a lot of LLM pricing is based on tokens, this maps more directly to the cost of the LLM calls.
Dialogue: 0,0:08:38.58,0:08:47.6,Secondary,,0,0,0,,So if I were to say the "max_token_limit" is equal to 50, and actually let me inject a few comments.
Dialogue: 0,0:08:47.6,0:08:51.14,Secondary,,0,0,0,,So let's say the conversation is, "AI is what?", "Amazing!".
Dialogue: 0,0:08:51.14,0:08:53.2,Secondary,,0,0,0,,"Backpropagation is what?", "Beautiful!".
Dialogue: 0,0:08:53.2,0:08:54.50,Secondary,,0,0,0,,"Chatbot is what?", "Charming!".
Dialogue: 0,0:08:54.50,0:08:58.54,Secondary,,0,0,0,,I use ABC as the first letter of all of these conversational terms.
Dialogue: 0,0:08:58.54,0:09:02.62,Secondary,,0,0,0,,We can keep track of, um, what was said when.
Dialogue: 0,0:09:02.62,0:09:08.62,Secondary,,0,0,0,,If I run this with a high token limit, um, it has almost the whole conversation.
Dialogue: 0,0:09:08.62,0:09:16.30,Secondary,,0,0,0,,If I increase the token limit to 100, it now has the whole conversation starting with "AI is what?".
Dialogue: 0,0:09:16.30,0:09:29.26,Secondary,,0,0,0,,If I decrease it, then, you know, it chops off the earlier parts of this conversation to retain the number of tokens corresponding to the most recent exchanges, um,
Dialogue: 0,0:09:31.94,0:09:39.18,Secondary,,0,0,0,,And in case you're wondering why we needed to specify an LLM, is because different LLMs use different ways of counting tokens.
Dialogue: 0,0:09:39.18,0:09:46.50,Secondary,,0,0,0,,So this tells it to use the way of counting tokens that the, um, ChatOpenAI LLM uses.
Dialogue: 0,0:09:46.50,0:09:54.42,Secondary,,0,0,0,,I encourage you to pause the video and run the code, and also try modifying the prompt to see if you can get a different output.
Dialogue: 0,0:09:54.42,0:09:58.30,Secondary,,0,0,0,,Finally, there's one last type of memory I want to illustrate here,
Dialogue: 0,0:09:58.30,0:10:04.32,Secondary,,0,0,0,,which is the ConversationSummaryBufferMemory.
Dialogue: 0,0:10:04.32,0:10:15.4,Secondary,,0,0,0,,And the idea is, instead of limiting the memory to fixed number of tokens based on the most recent utterances or a fixed number of conversational exchanges,
Dialogue: 0,0:10:15.4,0:10:23.90,Secondary,,0,0,0,,let's use an LLM to write a summary of the conversation so far, and let that be the memory.
Dialogue: 0,0:10:23.90,0:10:28.70,Secondary,,0,0,0,,So here's an example where I'm going to create a long string with someone's schedule.
Dialogue: 0,0:10:28.70,0:10:33.72,Secondary,,0,0,0,,You know, there's meeting at 8AM with your product team, you need your PowerPoint presentation, and so on and so on.
Dialogue: 0,0:10:33.72,0:10:37.92,Secondary,,0,0,0,,So this is a long string saying what's your schedule, you know,
Dialogue: 0,0:10:37.92,0:10:46.24,Secondary,,0,0,0,,maybe ending with a noon lunch at the Italian restaurant with a customer, bring your laptop, show the latest LLM demo.
Dialogue: 0,0:10:46.24,0:10:52.60,Secondary,,0,0,0,,And so let me use a ConversationSummaryBufferMemory,
Dialogue: 0,0:10:52.60,0:10:57.88,Secondary,,0,0,0,,um, with a max token limits of 400 in this case, pretty high token limit.
Dialogue: 0,0:10:57.88,0:11:10.14,Secondary,,0,0,0,,And I'm going to insert in a few conversational terms in which we start with, "Hello", "what's up". "Not much, just hanging", "uh, cool."
Dialogue: 0,0:11:10.14,0:11:13.44,Secondary,,0,0,0,,And then, "What is on the schedule today?"
Dialogue: 0,0:11:13.44,0:11:17.4,Secondary,,0,0,0,,And the response is, you know, that long schedule.
Dialogue: 0,0:11:17.4,0:11:22.44,Secondary,,0,0,0,,So this memory now has quite a lot of text in it.
Dialogue: 0,0:11:22.44,0:11:37.20,Secondary,,0,0,0,,In fact, let's take a look, um, at the memory variables, it contains that entire, um, piece of text because 400 tokens was sufficient to store all this text.
Dialogue: 0,0:11:37.20,0:11:46.58,Secondary,,0,0,0,,But now, if I were to reduce the max_token_limit, say to 100 tokens, remember this stores the entire conversational history.
Dialogue: 0,0:11:46.58,0:11:57.64,Secondary,,0,0,0,,If I reduce the number of tokens to 100, then the ConversationSummaryBufferMemory has actually used an LLM,
Dialogue: 0,0:11:57.64,0:12:05.36,Secondary,,0,0,0,,the OpenAI endpoint in this case because that's what we have set the LLM to, to actually generate a summary of the conversation so far.
Dialogue: 0,0:12:05.36,0:12:12.84,Secondary,,0,0,0,,So the summary is, "The human and AI engage in small talk before discussing the day's schedule, and AI informs the human of a morning meeting, blah, blah, blah,
Dialogue: 0,0:12:12.84,0:12:17.92,Secondary,,0,0,0,,um, and a lunch meeting with a customer interested in the latest AI developments."
Dialogue: 0,0:12:17.92,0:12:32.88,Secondary,,0,0,0,,And so, if we were to have a conversation using this LLM, then create a conversation chain, same as before.
Dialogue: 0,0:12:32.88,0:12:40.84,Secondary,,0,0,0,,And, um, let's say that we were to ask, you know, input what would be a good demo to show.
Dialogue: 0,0:12:40.84,0:12:43.0,Secondary,,0,0,0,,Um, I set "variables" equals "True".
Dialogue: 0,0:12:43.0,0:12:44.72,Secondary,,0,0,0,,So here's the prompt.
Dialogue: 0,0:12:44.72,0:12:55.84,Secondary,,0,0,0,,The LLM thinks the current conversation has had this discussion so far, because that's the summary of the conversation.
Dialogue: 0,0:12:55.84,0:12:58.40,Secondary,,0,0,0,,And just one note,
Dialogue: 0,0:12:58.40,0:13:06.72,Secondary,,0,0,0,,if you're familiar with the OpenAI chat API endpoint, there is a specific system message.
Dialogue: 0,0:13:06.72,0:13:14.36,Secondary,,0,0,0,,In this example, this is not using the official OpenAI system message, it's just including it as part of the prompt here.
Dialogue: 0,0:13:14.36,0:13:16.60,Secondary,,0,0,0,,But, but it nonetheless works pretty well.
Dialogue: 0,0:13:16.60,0:13:24.76,Secondary,,0,0,0,,And given this prompt, you know, the LLM outputs base on customer interest in AI developments, so it's just showcasing our latest NLP capabilities.
Dialogue: 0,0:13:24.76,0:13:26.20,Secondary,,0,0,0,,Okay, that's cool.
Dialogue: 0,0:13:26.20,0:13:29.80,Secondary,,0,0,0,,Um, well, it's, you know,
Dialogue: 0,0:13:29.80,0:13:34.24,Secondary,,0,0,0,,making some suggestions to the cool demos and makes you think, if I was meeting a customer,
Dialogue: 0,0:13:34.24,0:13:42.76,Secondary,,0,0,0,,I would say, boy, if only there were open source framework available to help me build cool NLP applications using LLMs.
Dialogue: 0,0:13:42.76,0:13:44.92,Secondary,,0,0,0,,Hmm, good things are launching.
Dialogue: 0,0:13:44.92,0:13:54.92,Secondary,,0,0,0,,Um, and the interesting thing is, if you now look at what has happened to the memory.
Dialogue: 0,0:13:54.92,0:14:04.24,Secondary,,0,0,0,,So notice that, um, here it has incorporated the most recent AI system output,
Dialogue: 0,0:14:04.24,0:14:10.92,Secondary,,0,0,0,,whereas my utterance asking it, what would be a good demo to show, has been incorporated into the system message.
Dialogue: 0,0:14:10.92,0:14:14.24,Secondary,,0,0,0,,Um, you know, the overall summary of the conversation so far.
Dialogue: 0,0:14:14.24,0:14:27.24,Secondary,,0,0,0,,With the ConversationSummaryBufferMemory, what it tries to do is keep the explicit storage of the messages up to the number of tokens we have specified as a limit.
Dialogue: 0,0:14:27.24,0:14:34.12,Secondary,,0,0,0,,So, you know, this part, the explicit storage, we're trying to cap at 100 tokens because that's what we're asked for.
Dialogue: 0,0:14:34.12,0:14:40.68,Secondary,,0,0,0,,And then anything beyond that, it will use the LLM to generate a summary, which is what is seen up here.
Dialogue: 0,0:14:40.68,0:14:46.64,Secondary,,0,0,0,,And even though I've illustrated these different memories using a chat as a running example,
Dialogue: 0,0:14:46.64,0:14:49.80,Secondary,,0,0,0,,these memories are useful for other applications too,
Dialogue: 0,0:14:49.80,0:14:54.76,Secondary,,0,0,0,,where you might keep on getting new snippets of text, or keep on getting new information,
Dialogue: 0,0:14:54.76,0:14:59.20,Secondary,,0,0,0,,such as if your system repeatedly goes online to search for facts,
Dialogue: 0,0:14:59.20,0:15:07.56,Secondary,,0,0,0,,but you want to keep the total memory used to store this growing list of facts as you know, capped and not growing arbitrarily long.
Dialogue: 0,0:15:07.56,0:15:10.36,Secondary,,0,0,0,,I encourage you to pause the video and run the code.
Dialogue: 0,0:15:10.36,0:15:15.16,Secondary,,0,0,0,,In this video, you saw a few types of memory,
Dialogue: 0,0:15:15.16,0:15:26.52,Secondary,,0,0,0,,including buffer memories that limits based on number of conversation exchanges or tokens or a memory that can summarize tokens above a certain limit.
Dialogue: 0,0:15:26.52,0:15:29.88,Secondary,,0,0,0,,LangChain actually supports additional memory types as well.
Dialogue: 0,0:15:29.88,0:15:33.16,Secondary,,0,0,0,,One of the most powerful is vector data memory.
Dialogue: 0,0:15:33.16,0:15:39.4,Secondary,,0,0,0,,If you're familiar with word embeddings and text embeddings, the vector database actually stores such embeddings.
Dialogue: 0,0:15:39.4,0:15:41.48,Secondary,,0,0,0,,If you don't know what that means, don't worry about it.
Dialogue: 0,0:15:41.48,0:15:43.32,Secondary,,0,0,0,,Harrison will explain it later.
Dialogue: 0,0:15:43.32,0:15:51.12,Secondary,,0,0,0,,And it can then retrieve the most relevant blocks of text using this type of vector database for its memory.
Dialogue: 0,0:15:51.12,0:15:54.48,Secondary,,0,0,0,,And LangChain also supports entity memories,
Dialogue: 0,0:15:54.48,0:16:00.64,Secondary,,0,0,0,,which is applicable when you wanted to remember details about specific people or specific other entities,
Dialogue: 0,0:16:00.64,0:16:12.28,Secondary,,0,0,0,,such as if you talk about a specific friend, you can have LangChain remember facts about that friend, which would be an entity in an explicit way.
Dialogue: 0,0:16:12.28,0:16:14.60,Secondary,,0,0,0,,When you're implementing applications using LangChain,
Dialogue: 0,0:16:14.60,0:16:17.24,Secondary,,0,0,0,,you can also use multiple types of memories,
Dialogue: 0,0:16:17.24,0:16:26.48,Secondary,,0,0,0,,such as using one of the types of conversation memory that you saw in this video, plus additionally, entity memory to recall individuals.
Dialogue: 0,0:16:26.48,0:16:35.16,Secondary,,0,0,0,,So this way, you can remember maybe a summary of the conversation, plus an explicit way of storing important facts about important people in the conversation.
Dialogue: 0,0:16:35.16,0:16:38.0,Secondary,,0,0,0,,And of course, in addition to using these memory types,
Dialogue: 0,0:16:38.0,0:16:45.92,Secondary,,0,0,0,,it's also not uncommon for developers to store the entire conversation in the conventional database, some sort of key-value store or SQL database.
Dialogue: 0,0:16:45.92,0:16:51.56,Secondary,,0,0,0,,So you could refer back to the whole conversation for auditing or for improving the system further.
Dialogue: 0,0:16:51.56,0:16:53.68,Secondary,,0,0,0,,And so that's memory types.
Dialogue: 0,0:16:53.68,0:16:57.0,Secondary,,0,0,0,,I hope you find this useful building your own applications.
Dialogue: 0,0:16:57.0,0:17:05.20,Secondary,,0,0,0,,And now, let's go on to the next video to learn about the key building block of LangChain, namely, the chain.
Dialogue: 0,0:00:05.0,0:00:07.0,Default,,0,0,0,,当你与这些模型互动时，
Dialogue: 0,0:00:07.0,0:00:12.16,Default,,0,0,0,,正常情况下它们无法记住\N你之前说过的话或之前的对话，
Dialogue: 0,0:00:12.16,0:00:17.68,Default,,0,0,0,,这对构建像聊天机器人\N这样的应用来说是个问题，\N因为你希望与模型对话时它们能有记忆。
Dialogue: 0,0:00:17.68,0:00:20.52,Default,,0,0,0,,所以在这一堂课，我们将讨论记忆存储，
Dialogue: 0,0:00:20.52,0:00:26.24,Default,,0,0,0,,也就是如何记住前面的对话\N内容，并能将其输入到语言模型中，
Dialogue: 0,0:00:26.24,0:00:30.44,Default,,0,0,0,,这样聊天机器人在与你\N互动时就能让对话更流畅。
Dialogue: 0,0:00:30.44,0:00:36.4,Default,,0,0,0,,LangChain针对复杂的\N记忆存储管理提供了多种选项。
Dialogue: 0,0:00:36.4,0:00:38.4,Default,,0,0,0,,让我们深入了解一下。
Dialogue: 0,0:00:38.4,0:00:44.24,Default,,0,0,0,,首先，让我导入我的OpenAI API密钥，
Dialogue: 0,0:00:44.24,0:00:47.44,Default,,0,0,0,,然后让我导入一些我需要的工具。
Dialogue: 0,0:00:47.44,0:00:50.80,Default,,0,0,0,,让我们以记忆存储为例子，
Dialogue: 0,0:00:50.80,0:00:55.44,Default,,0,0,0,,用LangChain管理聊天或聊天机器人对话。
Dialogue: 0,0:00:55.44,0:01:02.64,Default,,0,0,0,,为此，我将把LLM设置为\NOpenAI的聊天对话模式，temperature为0。
Dialogue: 0,0:01:02.64,0:01:09.56,Default,,0,0,0,,嗯，我将memory设置为\NConversationBufferMemory的实例引用。
Dialogue: 0,0:01:09.56,0:01:12.40,Default,,0,0,0,,稍后你会明白这样做有什么意义。
Dialogue: 0,0:01:12.40,0:01:15.80,Default,,0,0,0,,嗯，我要创建一个\N对话链（ConversationChain）。
Dialogue: 0,0:01:15.80,0:01:18.4,Default,,0,0,0,,在这个短课程的后面，
Dialogue: 0,0:01:18.4,0:01:23.32,Default,,0,0,0,,Harrison会更深入地讲解\NLangChain中的链到底是什么。
Dialogue: 0,0:01:23.32,0:01:26.68,Default,,0,0,0,,现在不用太担心语法细节。
Dialogue: 0,0:01:26.68,0:01:28.92,Default,,0,0,0,,但这会构建一个基于LLM的聊天对话。
Dialogue: 0,0:01:28.92,0:01:32.12,Default,,0,0,0,,如果我开始发送消息，
Dialogue: 0,0:01:32.12,0:01:36.84,Default,,0,0,0,,通过"conversation.predict"函数，\N输入”嗨，我叫Andrew。“
Dialogue: 0,0:01:36.84,0:01:38.96,Default,,0,0,0,,看看它会说什么。
Dialogue: 0,0:01:38.96,0:01:40.40,Default,,0,0,0,,“你好，Andrew。很高兴认识你。”
Dialogue: 0,0:01:40.40,0:01:41.44,Default,,0,0,0,,对吧？然后继续。
Dialogue: 0,0:01:41.44,0:01:44.4,Default,,0,0,0,,然后，假设我问它，
Dialogue: 0,0:01:44.4,0:01:46.64,Default,,0,0,0,,“一加一等于几？”
Dialogue: 0,0:01:46.64,0:01:49.20,Default,,0,0,0,,嗯，“一加一等于二。”
Dialogue: 0,0:01:49.20,0:01:51.40,Default,,0,0,0,,然后，再问一遍，
Dialogue: 0,0:01:51.40,0:01:53.0,Default,,0,0,0,,“你知道我的名字吗？”
Dialogue: 0,0:01:53.0,0:01:54.92,Default,,0,0,0,,“你的名字是Andrew，你之前提到过。”
Dialogue: 0,0:01:54.92,0:01:58.68,Default,,0,0,0,,嗯，有点嘲讽的意味\N在里面。但我没有证据：）
Dialogue: 0,0:01:58.68,0:02:05.64,Default,,0,0,0,,如果你想了解LangChain运行时的\N更多细节，可以把这个"verbose"变量\N改成"True"，看看它实际在做什么。
Dialogue: 0,0:02:05.64,0:02:08.84,Default,,0,0,0,,当你输入“嗨，我叫Andrew。”\N后运行"conversation.predict"
Dialogue: 0,0:02:08.84,0:02:11.40,Default,,0,0,0,,这是LangChain生成的提示词（Prompt）。
Dialogue: 0,0:02:11.40,0:02:16.64,Default,,0,0,0,,它说，"以下是人类和\NAI之间的友好对话，健谈的，"等等。
Dialogue: 0,0:02:16.64,0:02:25.92,Default,,0,0,0,,所以这是LangChain生成的提示词，\N让系统进行愉快友好的对话，\N并且必须要有回应，这是生成的内容。
Dialogue: 0,0:02:25.92,0:02:33.56,Default,,0,0,0,,当你在向模型发送第二\N句话和第三句话时，
Dialogue: 0,0:02:33.56,0:02:35.56,Default,,0,0,0,,它会在提示词中保留这些信息：
Dialogue: 0,0:02:35.56,0:02:39.48,Default,,0,0,0,,注意到当我说：“我的名\N字是什么？”的时候，
Dialogue: 0,0:02:39.48,0:02:42.76,Default,,0,0,0,,这是第三轮对话，也是我的第三次输入。
Dialogue: 0,0:02:42.76,0:02:47.40,Default,,0,0,0,,它已经按下面的格式存储\N了当前对话的历史消息：
Dialogue: 0,0:02:47.40,0:02:48.60,Default,,0,0,0,,“嗨，我叫Andrew。”
Dialogue: 0,0:02:48.60,0:02:49.84,Default,,0,0,0,,“一加一等于几？”
Dialogue: 0,0:02:49.84,0:02:56.76,Default,,0,0,0,,随着时间的推移，这段对话\N的记忆或历史变得越来越长。
Dialogue: 0,0:02:56.76,0:03:01.88,Default,,0,0,0,,实际上，在顶部，我用变量\N"memory"来保存这个记忆。
Dialogue: 0,0:03:01.88,0:03:08.40,Default,,0,0,0,,所以如果我打印"memory.buffer"，\N它已经存储了到目前为止对话中的所有消息。
Dialogue: 0,0:03:08.40,0:03:13.52,Default,,0,0,0,,嗯，你也可以用\N"memory.load_memory_variables({})"\N将"memory"中的内容打印出来。
Dialogue: 0,0:03:13.52,0:03:17.94,Default,,0,0,0,,这对花括号实际上是一个空字典。
Dialogue: 0,0:03:17.94,0:03:24.92,Default,,0,0,0,,可以通过往这个花括号里面\N传入一些值来修改选项做一些高级的定制，\N但在本次课程中我们不打算进一步讨论。
Dialogue: 0,0:03:24.92,0:03:28.36,Default,,0,0,0,,所以不用担心为什么这里\N有一个空的花括号。
Dialogue: 0,0:03:28.36,0:03:33.44,Default,,0,0,0,,这是LangChain到目前为止\N在对话记忆中所记住的内容。
Dialogue: 0,0:03:33.44,0:03:38.12,Default,,0,0,0,,这就是目前人类和AI之\N间的所有对话内容。
Dialogue: 0,0:03:38.12,0:03:41.12,Default,,0,0,0,,我建议你暂停视频，运行代码。
Dialogue: 0,0:03:41.12,0:03:48.81,Default,,0,0,0,,LangChain提供了一个\NConversationBufferMemory\N方法来临时存储对话记忆。
Dialogue: 0,0:03:48.81,0:03:54.96,Default,,0,0,0,,要使用ConversationBufferMemory\N存储消息，可以往其中添加输入和输出。
Dialogue: 0,0:03:54.96,0:03:59.8,Default,,0,0,0,,如果你想要往存储里面添加\N新内容，按照这样的方法做就好了。
Dialogue: 0,0:03:59.8,0:04:02.80,Default,,0,0,0,,通过"memory.save_context"加入：\N“嗨“，”最近怎么样？”
Dialogue: 0,0:04:02.80,0:04:08.84,Default,,0,0,0,,我知道这对话内容平淡无奇，\N但我只是想举个简短的例子。
Dialogue: 0,0:04:08.84,0:04:15.22,Default,,0,0,0,,嗯，有了这个，这就是记忆存储的状态。
Dialogue: 0,0:04:15.22,0:04:21.24,Default,,0,0,0,,让我再来打印一下记忆存储中的内容。
Dialogue: 0,0:04:21.24,0:04:27.24,Default,,0,0,0,,现在，如果你想向记忆存\N储中添加更多数据，
Dialogue: 0,0:04:27.24,0:04:29.32,Default,,0,0,0,,你可以继续保存更多的上下文。
Dialogue: 0,0:04:29.32,0:04:33.68,Default,,0,0,0,,聊天继续：“没什么，\N就这样”，“挺好的”。
Dialogue: 0,0:04:33.68,0:04:38.4,Default,,0,0,0,,如果你把记忆中存储的信息\N打印出来，现在里面有更多的内容。
Dialogue: 0,0:04:38.4,0:04:42.64,Default,,0,0,0,,当你使用大语言模型进行聊天对话中时，
Dialogue: 0,0:04:42.64,0:04:46.62,Default,,0,0,0,,大语言模型自身实际上是无状态的。
Dialogue: 0,0:04:46.62,0:04:51.60,Default,,0,0,0,,语言模型自身不会记住\N和你对话之间的历史消息。
Dialogue: 0,0:04:51.60,0:04:55.40,Default,,0,0,0,,每个请求交互，每次\N调用API都是独立的。
Dialogue: 0,0:04:55.40,0:05:07.40,Default,,0,0,0,,聊天机器人之所以看起来好像\N有记忆，是因为借助代码的帮助，提供\N历史消息作为和LLM对话的上下文。
Dialogue: 0,0:05:07.40,0:05:15.0,Default,,0,0,0,,所以记忆存储可以明确地存储到目前为止的\N对话消息，比如“嗨，我叫Andrew。”
Dialogue: 0,0:05:15.0,0:05:16.68,Default,,0,0,0,,“你好，很高兴认识你”等等。
Dialogue: 0,0:05:16.68,0:05:21.80,Default,,0,0,0,,这个记忆存储被用作\NLLM的输入或额外上下文，
Dialogue: 0,0:05:21.80,0:05:29.86,Default,,0,0,0,,这样它在生成输出时，就可以基于之前\N所说过的会话内容，再生成新的会话，\N让你感觉它好像“记得”你说过的话。
Dialogue: 0,0:05:29.86,0:05:33.64,Default,,0,0,0,,随着对话变得越来越长，
Dialogue: 0,0:05:33.64,0:05:40.24,Default,,0,0,0,,所需的记忆存储量也变得非常\N非常大，而向LLM发送大量\N令牌（Token）的成本也会增加，
Dialogue: 0,0:05:40.24,0:05:46.48,Default,,0,0,0,,因为它通常根据需要处\N理的令牌数量收费。
Dialogue: 0,0:05:46.48,0:05:54.24,Default,,0,0,0,,所以LangChain提供了几种便捷的记忆\N存储方案来存储对话消息和累积对话内容。
Dialogue: 0,0:05:54.24,0:05:57.90,Default,,0,0,0,,到目前为止，我们一直\N在研究对话的记忆存储方案。
Dialogue: 0,0:05:57.90,0:06:00.36,Default,,0,0,0,,现在让我们看看另一种类\N型的记忆存储方案：
Dialogue: 0,0:06:00.36,0:06:09.80,Default,,0,0,0,,ConversationBufferWindowMemory，\N保留窗口记忆，也就是\N仅保留最后若干轮对话消息。
Dialogue: 0,0:06:09.80,0:06:14.28,Default,,0,0,0,,如果我将传入\NConversationBufferWindowMemory\N的k参数设置为1，
Dialogue: 0,0:06:14.28,0:06:20.52,Default,,0,0,0,,变量k等于1表示我只想\N记住最后一轮对话，
Dialogue: 0,0:06:20.52,0:06:25.36,Default,,0,0,0,,也就是：我最后发出的一句话\N和聊天机器人的最后一句话。
Dialogue: 0,0:06:25.36,0:06:31.28,Default,,0,0,0,,现在如果我让它保存上下文，\N“嗨，最近怎么样？”，\N“没什么，就这样。”
Dialogue: 0,0:06:31.28,0:06:38.82,Default,,0,0,0,,如果我查看"memory.load_variables"，\N它只记得最近的话语。
Dialogue: 0,0:06:38.82,0:06:40.76,Default,,0,0,0,,注意它已经丢掉了\N“嗨，最近怎么样？”
Dialogue: 0,0:06:40.76,0:06:45.44,Default,,0,0,0,,它只是说，人类说：\N“没什么，就这样。”，\NAI说：“酷”
Dialogue: 0,0:06:45.44,0:06:47.92,Default,,0,0,0,,这是因为k等于1。
Dialogue: 0,0:06:47.92,0:06:56.16,Default,,0,0,0,,这是一个很好的功能，\N因为它让你跟踪最近的几个对话。
Dialogue: 0,0:06:56.16,0:07:02.92,Default,,0,0,0,,你在实际使用这个功能时，\N可能不会用k等于1，\N而是将k设置为一个较大的数字。
Dialogue: 0,0:07:02.92,0:07:10.42,Default,,0,0,0,,但是一样可以防止记忆存储量\N随着对话的进行而无限增长。
Dialogue: 0,0:07:10.42,0:07:25.58,Default,,0,0,0,,所以如果我再来一次刚才的对话，\N我们会说，“嗨，我叫Andrew”，\N“1加1等于几？”
Dialogue: 0,0:07:25.58,0:07:30.98,Default,,0,0,0,,现在我问它：“我的名字是什么？”
Dialogue: 0,0:07:30.98,0:07:37.24,Default,,0,0,0,,因为k等于1，它只记得上一次的\N会话，关于1加1等于几？
Dialogue: 0,0:07:37.24,0:07:41.26,Default,,0,0,0,,答案是1加1等于2，但现在\N已经忘记了之前交流的内容，
Dialogue: 0,0:07:41.26,0:07:45.6,Default,,0,0,0,,现在说：“抱歉，无法获取那些信息。”
Dialogue: 0,0:07:45.6,0:07:56.66,Default,,0,0,0,,我建议你暂停视频，在左侧代码中\N将"verbose"参数设置为"True"，\N然后重新运行这个对话。
Dialogue: 0,0:07:56.66,0:08:00.54,Default,,0,0,0,,然后你会看到实际运行时用到的提示词。
Dialogue: 0,0:08:00.54,0:08:07.84,Default,,0,0,0,,希望你能看到，\N当你问LLM：“我的名字是什么？”时，
Dialogue: 0,0:08:07.84,0:08:15.92,Default,,0,0,0,,在它的提示词中，已经丢失了\N前面有关名字的交流，所以\N现在它说不知道我的名字是什么。
Dialogue: 0,0:08:15.92,0:08:28.32,Default,,0,0,0,,使用ConversationalTokenBufferMemory，\N将限制保存在记忆存储的令牌数量。
Dialogue: 0,0:08:28.32,0:08:38.58,Default,,0,0,0,,由于很多LLM定价是基于令牌的，\N令牌的数量直接反映了LLM调用的成本。
Dialogue: 0,0:08:38.58,0:08:47.6,Default,,0,0,0,,如果我设置"max_token_limit"\N为50，实际上让我插入一些消息。
Dialogue: 0,0:08:47.6,0:08:51.14,Default,,0,0,0,,比如说对话是，“AI是什么？”，“太棒了！”
Dialogue: 0,0:08:51.14,0:08:53.2,Default,,0,0,0,,“反向传播是什么？”, “美丽！”
Dialogue: 0,0:08:53.2,0:08:54.50,Default,,0,0,0,,“聊天机器人是什么？”,“迷人！”
Dialogue: 0,0:08:54.50,0:08:58.54,Default,,0,0,0,,我用ABC作为所有\N这些对话单词的第一个字母。
Dialogue: 0,0:08:58.54,0:09:02.62,Default,,0,0,0,,这样我们可以记录\N什么时候说了什么。
Dialogue: 0,0:09:02.62,0:09:08.62,Default,,0,0,0,,如果我把令牌限制的值调的比较高，\N运行这段代码，它几乎可以包含整个对话。
Dialogue: 0,0:09:08.62,0:09:16.30,Default,,0,0,0,,如果我把令牌限制的值提高到100，\N现在它有整个从“AI是什么？”开始的对话。
Dialogue: 0,0:09:16.30,0:09:31.94,Default,,0,0,0,,如果我减少值，那么它会删掉这个\N对话的最早的那部分消息，只保留\N最近对话的消息，并且保证总的消息\N内容长度不超过设置的令牌限制的值。
Dialogue: 0,0:09:31.94,0:09:39.18,Default,,0,0,0,,如果你想知道为什么我们需要\N指定一个LLM参数，那是因为不同的\NLLM使用不同的令牌计算方法。
Dialogue: 0,0:09:39.18,0:09:46.50,Default,,0,0,0,,所以这告诉它使用ChatOpenAI \NLLM使用的计算令牌的方法。
Dialogue: 0,0:09:46.50,0:09:54.42,Default,,0,0,0,,我建议你暂停视频，\N运行代码，尝试修改提示词，\N看看能否得到不同的输出。
Dialogue: 0,0:09:54.42,0:09:58.30,Default,,0,0,0,,我想在这里说明的\N最后一种记忆存储类型是
Dialogue: 0,0:09:58.30,0:10:04.32,Default,,0,0,0,,那就是\NConversationSummaryBufferMemory。
Dialogue: 0,0:10:04.32,0:10:15.4,Default,,0,0,0,,这个想法是，与其将记忆的存储量限制在\N最近若干对话数量上，或限制在令牌数量上，
Dialogue: 0,0:10:15.4,0:10:23.90,Default,,0,0,0,,不如让LLM为所有历史消息生成摘要，\N在记忆中存储历史消息的摘要。
Dialogue: 0,0:10:23.90,0:10:28.70,Default,,0,0,0,,来举一个例子，我将创建一个\N关于某人日程安排的长字符串。
Dialogue: 0,0:10:28.70,0:10:33.72,Default,,0,0,0,,比如说，早上8点与产品\N团队有一个会议，需要\NPowerPoint演示文稿，等等。
Dialogue: 0,0:10:33.72,0:10:37.92,Default,,0,0,0,,这是一个长字符串，说的是你的日程安排，
Dialogue: 0,0:10:37.92,0:10:46.24,Default,,0,0,0,,可能以中午在意大利餐厅与\N客户共进午餐结束，带上你的笔记本\N电脑，展示最新的LLM演示。
Dialogue: 0,0:10:46.24,0:10:52.60,Default,,0,0,0,,那么，让我使用\NConversationSummaryBufferMemory，
Dialogue: 0,0:10:52.60,0:10:57.88,Default,,0,0,0,,在这种情况下，最大令牌限制\N为400，相当高的令牌限制。
Dialogue: 0,0:10:57.88,0:11:10.14,Default,,0,0,0,,我要加入一些对话内容，比如：\N"你好"，"最近怎么样"，\N"没什么，就这样"，"嗯，酷。"
Dialogue: 0,0:11:10.14,0:11:13.44,Default,,0,0,0,,然后是：\N"今天的日程安排是什么？"
Dialogue: 0,0:11:13.44,0:11:17.4,Default,,0,0,0,,回答是，前面那个很长的日程安排字符串。
Dialogue: 0,0:11:17.4,0:11:22.44,Default,,0,0,0,,所以现在这个记忆存储里有很多文本。
Dialogue: 0,0:11:22.44,0:11:37.20,Default,,0,0,0,,事实上，让我们看一下记忆存储中的\N内容，它包含了所有的文本，因为\N400个令牌足以存储所有这些文本。
Dialogue: 0,0:11:37.20,0:11:46.58,Default,,0,0,0,,但是，如果我现在把最大令牌数\N限制减少到100个令牌，\N记住这里存储了整个对话历史。
Dialogue: 0,0:11:46.58,0:11:57.64,Default,,0,0,0,,如果我把令牌数限制减少到100，\N那么ConversationSummaryBufferMemory\N实际会调用LLM，
Dialogue: 0,0:11:57.64,0:12:05.36,Default,,0,0,0,,在这种情况下是OpenAI API，\N因为这就是我们设置的LLM，\N来生成当前所有会话内容的摘要。
Dialogue: 0,0:12:05.36,0:12:12.84,Default,,0,0,0,,所以摘要是：“人类和AI进行了闲聊，\N然后讨论了当天的日程安排，AI告诉\N人类早上有一个会议”，等等，
Dialogue: 0,0:12:12.84,0:12:17.92,Default,,0,0,0,,嗯，还有一个与客户一起的午餐\N会议，客户对最新AI发展感兴趣。
Dialogue: 0,0:12:17.92,0:12:32.88,Default,,0,0,0,,如果我们用这个LLM进行对话，然后创建\N一个ConversationChain，就像之前一样。
Dialogue: 0,0:12:32.88,0:12:40.84,Default,,0,0,0,,那么，假设我们要问：\N“（给客户）演示什么比较好？”
Dialogue: 0,0:12:40.84,0:12:43.0,Default,,0,0,0,,我设置了“verbose”等于“True”。
Dialogue: 0,0:12:43.0,0:12:44.72,Default,,0,0,0,,这是提示词。
Dialogue: 0,0:12:44.72,0:12:55.84,Default,,0,0,0,,这是LLM知道的目前已经进行过的\N对话讨论，因为这里有对之前对话的总结。
Dialogue: 0,0:12:55.84,0:12:58.40,Default,,0,0,0,,还有一点需要注意，
Dialogue: 0,0:12:58.40,0:13:06.72,Default,,0,0,0,,如果你熟悉OpenAI Chat API，\N通常要设置一个特定的系统消息。
Dialogue: 0,0:13:06.72,0:13:14.36,Default,,0,0,0,,在这个例子中，这并不是一个\NOpenAI Chat的系统消息，而是\N提示词中用来描述历史会话摘要的部分。
Dialogue: 0,0:13:14.36,0:13:16.60,Default,,0,0,0,,但是，它还是效果很好。
Dialogue: 0,0:13:16.60,0:13:24.76,Default,,0,0,0,,有了这个提示词，基于客户\N对AI发展很有兴趣，LLM建议向客户\N演示我们最新的自然语言处理能力。
Dialogue: 0,0:13:24.76,0:13:26.20,Default,,0,0,0,,好的，这很酷。
Dialogue: 0,0:13:26.20,0:13:29.80,Default,,0,0,0,,嗯，这个就是，
Dialogue: 0,0:13:29.80,0:13:34.24,Default,,0,0,0,,一个让LLM给你的酷炫演示\N提供建议的例子，这可能\N会让你想：“如果我在见客户的时候，
Dialogue: 0,0:13:34.24,0:13:42.76,Default,,0,0,0,,我会说，哇，如果有\N开源框架可以帮我用\NLLM构建酷炫的NLP应用就好了！”
Dialogue: 0,0:13:42.76,0:13:44.92,Default,,0,0,0,,嗯，这样优秀的项目正在推出。
Dialogue: 0,0:13:44.92,0:13:54.92,Default,,0,0,0,,有趣的是，现在看看\N记忆存储中发生了什么。
Dialogue: 0,0:13:54.92,0:14:04.24,Default,,0,0,0,,注意到这里，它已经\N包含了最近的AI系统输出，
Dialogue: 0,0:14:04.24,0:14:10.92,Default,,0,0,0,,而我问它的问题：“演示什么比较好？”\N，已经被归纳进了系统消息。
Dialogue: 0,0:14:10.92,0:14:14.24,Default,,0,0,0,,嗯，到目前为止，整个对话的总结。
Dialogue: 0,0:14:14.24,0:14:27.24,Default,,0,0,0,,对于ConversationSummaryBufferMemory，\N它试图将消息的显性记忆保持在\N我们指定的令牌数上限。
Dialogue: 0,0:14:27.24,0:14:34.12,Default,,0,0,0,,所以，这部分显性记忆，\N我们试图将其限制在100个\N令牌，因为这是我们前面指定的。
Dialogue: 0,0:14:34.12,0:14:40.68,Default,,0,0,0,,然后，它会使用LLM生成\N摘要，就像这里看到的那样。
Dialogue: 0,0:14:40.68,0:14:46.64,Default,,0,0,0,,尽管我用聊天作为例子来\N说明这些不同的记忆存储方案，
Dialogue: 0,0:14:46.64,0:14:49.80,Default,,0,0,0,,这些记忆存储方案对\N其他应用程序也很有用，
Dialogue: 0,0:14:49.80,0:14:54.76,Default,,0,0,0,,比如你可能会不断收到\N新的文本片段或新的信息，
Dialogue: 0,0:14:54.76,0:14:59.20,Default,,0,0,0,,例如，如果你的系统\N需要经常上网检索内容，
Dialogue: 0,0:14:59.20,0:15:07.56,Default,,0,0,0,,检索结果会存储在一个列表中，\N但你希望列表的存储总数保持在一个\N限定的范围内，而不是无限地增长。
Dialogue: 0,0:15:07.56,0:15:10.36,Default,,0,0,0,,我建议你暂停视频并运行代码。
Dialogue: 0,0:15:10.36,0:15:15.16,Default,,0,0,0,,在这个视频中，你看到了\N几种类型的记忆存储方案，
Dialogue: 0,0:15:15.16,0:15:26.52,Default,,0,0,0,,包括基于对话次数或令牌数量限制的记忆\N存储方案，或者可以对超过特定令牌数\N的会话内容进行总结的方案。
Dialogue: 0,0:15:26.52,0:15:29.88,Default,,0,0,0,,LangChain实际上还\N支持其他类型的记忆存储。
Dialogue: 0,0:15:29.88,0:15:33.16,Default,,0,0,0,,其中最强大的是向量数据存储。
Dialogue: 0,0:15:33.16,0:15:39.4,Default,,0,0,0,,如果你熟悉词嵌入\N（Embeddings）和文本嵌入，向量\N数据库实际上就是存储这些嵌入的。
Dialogue: 0,0:15:39.4,0:15:41.48,Default,,0,0,0,,如果你不知道这是什么意思，不用担心。
Dialogue: 0,0:15:41.48,0:15:43.32,Default,,0,0,0,,Harrison稍后会解释。
Dialogue: 0,0:15:43.32,0:15:51.12,Default,,0,0,0,,它可以使用这种向量数据库\N来检索最相关的文本块。
Dialogue: 0,0:15:51.12,0:15:54.48,Default,,0,0,0,,LangChain还支持实体记忆存储，
Dialogue: 0,0:15:54.48,0:16:00.64,Default,,0,0,0,,当你想记住关于特定人或其他\N实体的详细信息时，这是适用的，
Dialogue: 0,0:16:00.64,0:16:12.28,Default,,0,0,0,,比如，如果你谈论一个特定的朋友，\N你可以让LangChain记住关于那个朋友\N的事实，这将以明确的方式成为一个实体。
Dialogue: 0,0:16:12.28,0:16:14.60,Default,,0,0,0,,当你使用LangChain实现应用程序时，
Dialogue: 0,0:16:14.60,0:16:17.24,Default,,0,0,0,,你还可以使用多种类型的记忆存储，
Dialogue: 0,0:16:17.24,0:16:26.48,Default,,0,0,0,,比如使用本视频中看到的\N某种对话记忆存储类型，再加上\N实体记忆存储来回忆个人。
Dialogue: 0,0:16:26.48,0:16:35.16,Default,,0,0,0,,这样，你可以记住对话的\N大致内容，以及明确记录对话\N中重要人物的重要事实。
Dialogue: 0,0:16:35.16,0:16:38.0,Default,,0,0,0,,当然，除了使用这些记忆存储类型，
Dialogue: 0,0:16:38.0,0:16:45.92,Default,,0,0,0,,开发者也经常将整个对话存储\N在传统数据库中，如键值存储\N（key-value store）或SQL数据库。
Dialogue: 0,0:16:45.92,0:16:51.56,Default,,0,0,0,,这样你可以回顾整个对话，\N进行审计或进一步改进系统。
Dialogue: 0,0:16:51.56,0:16:53.68,Default,,0,0,0,,这就是记忆存储类型。
Dialogue: 0,0:16:53.68,0:16:57.0,Default,,0,0,0,,希望这些知识能有效地\N帮助你更好的构建自己的应用程序。
Dialogue: 0,0:16:57.0,0:17:05.20,Default,,0,0,0,,现在，让我们继续下一个视频，了解\NLangChain的关键构建模块，也就是链。