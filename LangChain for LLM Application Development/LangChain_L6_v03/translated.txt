有时候人们把大语言模型看作是知识库，
就好像它学会并记忆了大量的从互联网上获取的信息，
所以当你问问题时，它可以回答问题。
但我认为更有用的方式是把大语言模型看作是一个推理引擎，
你可以给它提供一些文本或其他信息来源。
然后大型语言模型，LLM，
可能会使用它从互联网上学习的这些背景知识，
但是也会利用你提供的新信息来帮助你回答问题，或者推理内容，甚至决定接下来要做什么。
这就是LangChain的代理框架能帮助你做的事。
代理可能是我最喜欢的LangChain功能。
我认为代理也是最强大的功能之一，但也是较新的功能。
对于这个领域的每个人来说，涌现了很多新的技术，
这节课程将会令人期待，因为我们将会深入了解什么是代理，
如何创建和使用代理，
如何配备不同类型的工具，比如内置在LangChain中的搜索引擎。
然后还有如何创建自己的工具，这样你就可以让代理与任何数据存储、API、或者功能进行互动。
这是令人兴奋的前沿技术，而且已经有了一些重要的应用案例。
那么，让我们开始吧。
首先，我们将设置环境变量并导入一些内容，稍后将会用到。
接下来，我们将初始化一个语言模型。
我们将使用ChatOpenAI。
首先，我们要把temperature参数设为0。
这点很重要，因为我们将使用语言模型作为代理的推理引擎，它会连接到其他数据和计算资源，
所以，我们希望这个推理引擎尽可能地好并且尽可能精确。
所以我们把temperature参数设为0，消除任何可能出现的随机性。
接下来，我们要加载一些工具。
我们要加载的两个工具是llm-math工具和维基百科工具。
llm-math工具实际上是一个链，它结合了语言模型和计算器来解决数学问题。
维基百科工具是一个连接到维基百科API的程序，
允许你查询维基百科上的内容，并返回搜索结果。
最后，我们将初始化一个代理。
我们将用“工具列表”、“语言模型”和“代理类型”初始化代理。
这里，我们将使用名为CHAT_ZERO_SHOT_REACT_DESCRIPTION的代理类型。
这里面首先要注意的是CHAT。
这是一个专为与Chat模型一起工作而优化的代理。
其次是REACT。
REACT是一种组织Prompt的技术，能最大化语言模型的推理能力。
我们还将设置handle_parsing_errors参数的值为True。
当语言模型输出的内容无法被正常解析时，这很有用。
实际上就是遇到内容无法被正常解析时，将格式错误的内容传回语言模型，并要求它自行纠正。
最后，我们将设置verbose参数的值为True。
这会打印出每一个步骤的详细记录，让我们可以在Jupyter Notebook中清楚地了解正在发生的事情。
稍后我们还会在全局级别设置debug为True
这样我们可以更详细地了解到底发生了什么。
首先，我们要问代理一个数学问题：
“300的25%是多少？”
这是一个相当简单的问题，但对于我们了解具体发生了什么非常有帮助。
我们可以看到，当它进入AgentExecutor链时，首先会考虑需要做什么。
所以它有一个THOUGHT（思考）。
然后它有一个ACTION（操作）。
这个ACTION实际上是一个JSON对象，其中有两部分内容：一个action（操作）和一个action_input（操作输入）。
action对应的是要使用的工具，
这里写的是计算器。
action_input对应的是该工具的输入，
这里是一个“300*0.25”的字符串。
接下来，我们可以看到Observation（观察结果）和Answer（答案）是用不同颜色显示的。
这个Observation后面的“Answer: 75.0”，实际上是来自计算器工具返回的结果。
接下来我们回到语言模型，文字变为绿色，语言模型Thought（思考）：
“我们得到了问题的答案。
最后答案是75.0”。这就是我们得到的输出结果。
建议你现在暂停一下，自己尝试测试一些不同的数学问题。
接下来，我们将展示一个使用维基百科API的示例。
在这里，我们将向它问一个关于Tom Mitchell的问题（Tom M. Mitchell是美国计算机科学家，卡内基梅隆大学的教授。他写了什么书？），
我们可以查看中间步骤，了解它的工作原理。
我们再次看到它在思考，并正确地意识到应该使用维基百科工具。
它显示action是“维基百科”，action_input是“Tom M. Mitchell”。
这次返回的Observation（观察结果）是黄色的，
我们用不同的颜色表示不同的工具，
这是Tom M. Mitchell页面的维基百科摘要结果。
从维基百科返回的Observation
实际上是两个结果，两个页面，
因为有两个不同的Tom M. Mitchell。
我们可以看到第一个结果是一位计算机科学家，
第二个结果看起来像是一位澳大利亚足球运动员。
我们可以看到回答这个问题所需的关键信息，
也就是他写的那本书的名字：《机器学习》，
出现在第一个Tom Mitchell的摘要中。
接下来我们可以看到代理试图查找关于这本书的更多信息。
所以它在维基百科上查找了《机器学习》这本书。
这其实没太有必要，
这是一个有趣的例子，说明代理还不完全可靠。
我们可以看到在这次查找之后，
代理意识到它已经有了回答所需的所有信息，并给出了正确答案：《机器学习》。
我们接下来要讲的例子非常酷。
如果你见过像GitHub Copilot，或者ChatGPT的代码解释器插件这样的东西，
它们所做的就是用语言模型写代码，然后执行生成的代码。
我们在这里也可以做同样的事情。
所以我们要创建一个Python代理，使用之前一样的LLM。
我们会给它一个工具，PythonREPLTool。
REPL基本上是一种与代码互动的方式，
你可以把它想象成一个Jupyter Notebook，
代理可以用这个REPL执行代码。
然后我们会得到代码运行结果，这些结果会传回给代理，让它决定接下来要做什么。
我们需要这个代理解决的问题是让它给一组客户名单排序。
可以看到我们这里有一组名字，"Harrison Chase"，"Lang Chain"，"Elle Elem"，"Geoff Fusion"，"Trance Former"，"Jen Ayai"。
我们要求代理先按姓氏再按名字对这些名字进行排序，然后打印输出结果。
重要的是，我们要求它打印输出结果，以便可以看到实际结果是什么。
这些打印出来的内容将在后面被反馈到语言模型中，
这样它就可以对代码输出的结果进行推理。
让我们试试看。
我们可以看到当进入AgentExecutor链时，
它首先意识到可以使用sorted函数对名单进行排序。
它在底层使用了不同类型的代理，
这就是为什么你可以看到Action和Action Input实际上格式有些不同。
这里，它使用的Action是Python REPL，
然后你可以看到Action Input是一段代码，
它首先写出customers等于这个列表，然后对customers进行排序，
然后遍历这个列表并打印它。
你可以看到代理在Thought（思考）该做什么，并意识到需要写一段代码。
它使用的Action和Action Input的格式实际上与以前略有不同。
它在底层使用了不同的代理类型。
对于Action，它将使用Python REPL。
对于Action Input，有一段代码。
如果我们看看这段代码在做什么，它首先创建一个"customers"变量来列出这些客户名称。
首先对其进行排序并创建一个新变量"sorted_customers"。
然后遍历这个新变量，按照我们的要求逐行打印出排序后的名单。
我们可以看到我们得到了Observation（观察结果），这是一份名单列表。
然后代理意识到任务完成，返回这份名单。
我们可以从打印出来的内容看到一些大概的情况，

但让我们再深入一点，将“langchain.debug”设置为“True”并运行。
因为这会打印出所有级别，所有正在运行的不同的链，
让我们逐一查看究竟发生了什么。
首先，我们从AgentExecutor开始。
这是第一级的代理运行器。
我们可以看到这里有我们的输入，
按姓氏和名字对这些客户进行排序，然后打印输出。
从这里，我们调用一个LLMChain。
这是代理正在使用的LLMChain。
LLMChain，记住，是Prompt和LLM的组合。
目前，它只有input和agent_scratchpad，
稍后我们会回到这个问题，然后是"stop"参数，告诉语言模型何时停止生成。
在下一级，我们看到了对语言模型的调用。
可以看到完整的格式化了的Prompt，
其中包括关于它可以访问哪些工具的说明，以及返回何种格式的输出。
从那里，我们可以看到语言模型的详细输出。
我们可以看到text键，其中包含了Thought（思考）、Action（操作）和Action Input（操作输入）。
然后它退出LLMChain。
接下来它调用的是一个工具。
在这里我们可以看到工具的详细输入。
我们还可以看到工具的名称：“Python REPL”，
然后我们可以看到输入，也就是这段代码。
接着我们可以看到这个工具的输出，也就是这个打印出来的字符串。
之所以有这段代码是因为我们特意要求Python REPL打印出正在进行的操作。
然后我们可以看到下一个输入到LLMChain，同样，这里的LLMChain是代理。
这里，如果你看"input"变量，
这没有改变，
这是我们要代理实现的目标。但现在"agent_scratchpad"参数有一些新值。
你可以看到这实际上是之前的输出和工具输出的组合。
我们把这个传回去
让语言模型了解之前发生了什么
并用这些信息来推理出接下来应该做什么。
接下来的几个打印语句都在讲述语言模型意识到
它基本上完成了它的工作。
所以我们可以看到语言模型的完整的格式化了的Prompt。
它意识到任务完成并输出了最终答案，
这是代理用来识别它完成工作的顺序。
然后我们可以看到它退出LLMChain，然后退出AgentExecutor。
这应该能让你对代理内部发生了什么有一个很好的了解，
这应该能让你对代理内部发生了什么有一个很好的了解，
建议你暂停并为这个编码代理设定自己的目标，希望能对你有启发。
这种调试模式也可以用来发现出错的地方，就像上面的维基百科示例中调用了不必要的查询，
有时代理的表现会出人意料，所以这些信息对于帮助你理解发生了什么非常有帮助。
到目前为止，我们已经使用了LangChain中内置的工具。
但是代理的一大优势是你可以将其连接到你自己的信息来源，你自己的API，你自己的数据。
那么在这里，我们将介绍如何创建一个自定义工具，以便您可以将其连接到您想要的任何地方。
让我们制作一个工具，它会告诉我们当前的日期是什么。
首先，我们要导入这个工具装饰器。
它可以应用于任何函数，并将其转换为LangChain可以使用的工具。
接下来，我们将编写一个名为time的函数，它可以接收任何文本字符串。
我们并不真正使用它。
它将返回今天的日期。
除了函数的名称外，我们还写了一份非常详细的DocString格式的注释说明。
因为代理会利用注释中的信息来知道何时应该调用这个工具（函数），以及应该如何调用这个工具。
例如，在这里我们说输入应该始终为空字符串。
那是因为我们不用它。
如果我们对输入有更严格的要求，
比如，如果我们有一个函数，它应该总是接收搜索查询或SQL语句，
你需要在这里说明。
我们现在要创建另一个代理。
这次我们把time工具加到现有工具列表里。
最后，让我们调用代理，问它今天是什么日期。
它意识到需要使用time工具，并在这里指定
它的action_input是一个空字符串。
这很棒！
这就是我们让它做的事情。
然后它返回一个Observation（观察结果）。
接着，语言模型根据这个Observation回复用户：
“今天是2023年5月21日。”
建议你暂停视频，尝试输入不同的内容，看看返回的结果。
这就是关于代理的课程总结。
这是LangChain中比较新，也比较激动人心部分，还处于实验性阶段。
希望你能喜欢！
希望这堂课向你展示了如何将语言模型作为推理引擎来采取不同的操作，
并连接到其他函数和数据源。