1
00:00:05,000 --> 00:00:08,800
在第一课中，我们将介绍模型、提示和解析器。
In lesson one, we'll be covering models, prompts, and parsers.

2
00:00:08,800 --> 00:00:13,600
所谓模型，是指作为基础的语言模型。
So models refers to the language models underpinning a lot of it.

3
00:00:13,600 --> 00:00:18,760
提示（Prompt）指创建输入，是用来给模型传递信息的一种方式。
Prompts refers to the style of creating inputs to pass into the models.

4
00:00:18,760 --> 00:00:20,760
而解析器则与之相反，
And then parsers is on the opposite end.

5
00:00:20,760 --> 00:00:27,760
它接收模型的输出，并将输出结果解析成更结构化的格式，以便你可以对其进行后续操作。
It involves taking the output of these models and parsing it into a more structured format so that you can do things downstream with it.

6
00:00:27,760 --> 00:00:32,640
因此，当您使用LLM构建应用程序时，通常会有可重用的模块。
So when you build an application using an LLM, there'll often be reusable models.

7
00:00:32,640 --> 00:00:40,140
我们反复提示模型，解析输出，所以LangChain提供了一套简单的抽象来执行此类操作。
We have repeatedly prompted model, parsers output, and so LangChain gives an easy set of abstractions to do this type of operation.

8
00:00:40,140 --> 00:00:45,160
那么，让我们开始研究模型、提示和解析器。
So with that, let's jump in and take a look at models, prompts, and parsers.

9
00:00:45,160 --> 00:00:47,640
首先，这里有一些入门代码。
So to get started, here's a little bit of starter code.

10
00:00:47,640 --> 00:00:53,720
我将导入"os"库，导入"openai"库，并加载我的OpenAI密钥。
I'm going to import OS, import OpenAI, and load my OpenAI secret key.

11
00:00:53,720 --> 00:00:58,040
"openai"库已经安装在我的Jupyter Notebook环境中。
The OpenAI library is already installed in my Jupyter notebook environment.

12
00:00:58,040 --> 00:01:03,440
如果你在本地运行，还没有安装"openai"，你可能需要运行它。
If you're running this locally and you don't have OpenAI installed yet, you might need to run that.

13
00:01:03,440 --> 00:01:07,360
虽然可以用"!pip install openai"，但这里我不会这么做。
"!pip install openai", but I'm not going to do that here.

14
00:01:07,360 --> 00:01:09,000
然后这里有一个辅助函数。
And then here's a helper function.

15
00:01:09,000 --> 00:01:20,680
这个辅助函数实际上与我和OpenAI的Isa Fulford一起讲过的《给开发者的ChatGPT提示工程》课程中的辅助函数非常相似。
This is actually very similar to the helper function that you might have seen in the "ChatGPT Prompt Engineering for Developers" course that I offered together with OpenAI's Isa Fulford.

16
00:01:20,680 --> 00:01:26,960
有了这个辅助函数，你可以对“1+1是多少”这样的问题使用get_completion。
And so with this helper function, you can say get_completion on what is one plus one,

17
00:01:26,960 --> 00:01:36,200
这将调用ChatGPT，或者更准确地说是GPT 3.5 Turbo模型，给你一个像这样的答案。
and this will call ChatGPT or technically the model GPT 3.5 Turbo to give you an answer back like this.

18
00:01:36,200 --> 00:01:49,840
现在，为了阐明LangChain对模型提示和解析的抽象，假设你收到了一封用非英语写的客户邮件。
Now to motivate the LangChain abstractions for model prompts and parsers, let's say you get an email from a customer in a language other than English.

19
00:01:49,840 --> 00:01:55,285
为了确保这是可接受的，我将使用另一种语言，海盗风格的英语。
In order to make sure this is accessible, the other language I'm going to use is the English pirate language,

20
00:01:55,286 --> 00:02:02,680
邮件内容是：“我简直被气得七窍生烟，因为我的搅拌机盖子飞了出去，把我的厨房墙上都溅满了果汁。”
where the content says, "I be fuming that me blender lid flew off and splattered my kitchen walls with smoothie.

21
00:02:02,680 --> 00:02:06,080
更糟糕的是，保修不包括清理厨房的费用。
And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen.

22
00:02:06,080 --> 00:02:08,600
我现在需要你的帮助，伙计。
I need your help right now, matey."

23
00:02:08,600 --> 00:02:18,360
我们要做的是让这个LLM把文本翻译成平静、尊重的美式英语。
And so what we will do is ask this LLM to translate the text to American English in a calm and respectful tone.

24
00:02:18,360 --> 00:02:23,400
所以我要把风格设为平静、尊重的美式英语。
So I'm going to set style to American English in a calm and respectful tone.

25
00:02:23,400 --> 00:02:29,320
为了实现这个目标，如果你之前看过一些提示相关的课程，
And so in order to actually accomplish this, if you've seen a little bit of prompting before,

26
00:02:29,320 --> 00:02:32,986
我会用"f"字符串和说明来指定提示，
I'm going to specify the prompt using an "f" string with the instructions,

27
00:02:32,987 --> 00:02:40,160
把用三个反引号括起来的文本翻译成"style"那样的风格，然后插入这两种风格。
Translate the text that is delimited by triple backticks into style that is "style", and then plug in these two styles.

28
00:02:40,160 --> 00:02:46,120
这样就生成了一个提示说：“翻译这段文本”等等。
And so this generates a prompt that says, "Translate the text," and so on.

29
00:02:46,120 --> 00:02:54,800
我建议你暂停视频，运行代码，还可以尝试修改提示，看看能否得到不同的输出。
I encourage you to pause the video and run the code, and also try modifying the prompt to see if you can get a different output.

30
00:02:54,800 --> 00:03:03,080
然后你可以提示大语言模型得到一个结果。
You can then prompt the large language model to get a response.

31
00:03:03,080 --> 00:03:04,080
我们来看看返回的结果是什么。
Let's see what the response is.

32
00:03:04,080 --> 00:03:07,871
它说把海盗风格英语的信息翻译成了这段礼貌的英语文字：
It says, "Translated the English pirate's message into this very polite,

33
00:03:07,872 --> 00:03:13,540
“我真的很伤心，因为我的搅拌机盖子飞了出去，把我的厨房墙上弄得一团糟…
'I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie,'" and so on.

34
00:03:13,540 --> 00:03:16,520
我现在真的需要你的帮助，朋友！”
I could really use your help right now, my friend.

35
00:03:16,520 --> 00:03:18,760
听起来很不错。
That sounds very nice.

36
00:03:18,761 --> 00:03:27,271
如果现在你有不同的客户，用不同的语言写评论，不仅仅是海盗风格英语，还有法语、德语、日语等等，
So if you have different customers writing reviews in different languages,  not just English pirate, but French, German, Japanese, and so on,

37
00:03:27,272 --> 00:03:34,500
你可以想象，这需要生成一整套针对各种不同语言的提示来生成这样的翻译。
you can imagine having to generate a whole sequence of prompts to generate such translations.

38
00:03:34,500 --> 00:03:40,360
让我们看看如何用LangChain更方便地实现这一点。
Let's look at how we can do this in a more convenient way using LangChain.

39
00:03:40,360 --> 00:03:44,600
我要导入ChatOpenAI。
I'm going to import ChatOpenAI.

40
00:03:44,600 --> 00:03:49,780
这是LangChain对ChatGPT API访问的抽象。
This is LangChain's abstraction for the ChatGPT API endpoint.

41
00:03:49,780 --> 00:03:54,157
如果我把"chat"设置为ChatOpenAI的实例，然后看看"chat"是什么，
And so if I then set chat equals ChatOpenAI and look at what chat is,

42
00:03:54,158 --> 00:04:02,960
它会创建一个如下的对象，使用的是ChatGPT模型，也叫做gpt-3.5-turbo。
it creates this object as follows that uses the ChatGPT model, which is also called gpt-3.5-turbo.

43
00:04:02,960 --> 00:04:09,740
当我构建应用程序时，我经常会把temperature参数设置为0。
When I'm building applications, one thing I will often do is set the temperature parameter to be equal to zero.

44
00:04:09,740 --> 00:04:20,400
默认的temperature是0.7，但让我实际上用temperature等于0.0重做一遍。
So the default temperature is 0.7, but let me actually redo that with temperature equals 0.0.

45
00:04:20,400 --> 00:04:27,960
现在temperature设为0，让输出的随机性降低一点。
And now the temperature is set to zero to make this output a little bit less random.

46
00:04:27,960 --> 00:04:30,960
现在让我定义一个模板字符串。
And now let me define the template string as follows.

47
00:04:30,960 --> 00:04:35,280
把用三个反引号分隔的文本翻译成"style"的风格。
Translate the text delimited by triple backticks into style is style.

48
00:04:35,280 --> 00:04:37,480
然后是这里的文本。
And then here's the text.

49
00:04:37,480 --> 00:04:47,040
为了反复使用这个模板，让我们导入LangChain的ChatPromptTemplate。
And to repeatedly reuse this template, let's import LangChain's ChatPromptTemplate.

50
00:04:47,040 --> 00:05:00,760
然后让我用我们刚才写的模板字符串创建一个提示模板。
And then let me create a prompt template using that template string that we just wrote above.

51
00:05:00,760 --> 00:05:04,860
从提示模板中，你可以提取原始的提示。
From the prompt template, you can actually extract the original prompt.

52
00:05:04,860 --> 00:05:17,040
它意识到这个提示有两个输入变量，"style"和"text"，这里用大括号表示。
And it realizes that this prompt has two input variables, the style and the text, which were shown here with the curly braces.

53
00:05:17,040 --> 00:05:19,720
这里也有我们之前指定的原始模板。
And here is the original template as well that we had specified.

54
00:05:19,720 --> 00:05:28,200
实际上，如果我把这个打印出来，它知道它有两个输入变量，"style"和"text"。
In fact, if I print this out, it realizes it has two input variables, style and text.

55
00:05:28,200 --> 00:05:30,360
现在让我们指定风格。
Now let's specify the style.

56
00:05:30,360 --> 00:05:33,960
这是我希望客户信息被翻译成的风格。
This is a style that I want the customer message to be translated to.

57
00:05:33,960 --> 00:05:37,240
所以我要把这个叫做customer_style。
So I'm going to call this customer style.

58
00:05:37,240 --> 00:05:44,960
这是我之前的相同客户邮件。
And here's my same customer email as before.

59
00:05:44,960 --> 00:05:59,640
现在如果我创建customer_messages，这将生成提示，并在一分钟内传递给大型语言模型以获得返回结果。
And now if I create customer messages, this will generate the prompt and will pass this a large language model in a minute to get a response.

60
00:05:59,640 --> 00:06:05,200
所以如果你想看看类型，customer_messages实际上是一个列表。
So if you want to look at the types, the customer message is actually a list.

61
00:06:05,200 --> 00:06:16,400
如果你看列表的第一个元素，这基本上就是你期望得到的提示。
And if you look at the first element of the list, this is more or less that prompt that you would expect this to be creating.

62
00:06:16,400 --> 00:06:20,560
最后，让我们把这个提示传给LLM。
Lastly, let's pass this prompt to the LLM.

63
00:06:20,560 --> 00:06:32,560
接下来我要调用"chat"，我们之前把它设置为OpenAI ChatGPT的实例引用。
So I'm going to call chat, which we had set earlier as a reference to the OpenAI ChatGPT endpoint.

64
00:06:32,560 --> 00:06:45,400
如果我们打印出客户回复的内容，那么它会把这段从海盗式英语翻译成礼貌的美式英语。
If we print out the customer responses content, then it gives you back this text translated from English pirate to polite American English.

65
00:06:45,400 --> 00:06:50,560
当然，你可以想象其他情况，比如客户邮件是用其他语言写的。
And of course, you can imagine other use cases where the customer emails are in other languages.

66
00:06:50,560 --> 00:06:58,240
这也可以用来为英语使用者翻译消息，以便他们理解并回复。
And this too can be used to translate the messages for an English speaking to understand and reply to.

67
00:06:58,240 --> 00:07:06,720
我建议你暂停视频，运行代码，尝试修改提示，看看能否得到不同的输出。
I encourage you to pause the video and run the code and also try modifying the prompt to see if you can get a different output.

68
00:07:06,720 --> 00:07:11,880
现在让我们希望客服代表用客户的原始语言回复客户。
Now let's hope our customer service agent replied to the customer in their original language.

69
00:07:11,880 --> 00:07:17,040
假设英语客服代表写了这个并说：“嘿，亲爱的客户，
So let's say English speaking customer service agent writes this and says, "Hey there customer,

70
00:07:17,040 --> 00:07:20,400
保修不包括厨房的清洁费用，因为这是你的错。
warranty does not cover, clean expenses for the kitchen because it's your fault.

71
00:07:20,400 --> 00:07:23,800
你在使用搅拌机时忘了盖上盖子。
You misused your blender by forgetting to put on the lid.

72
00:07:23,800 --> 00:07:25,800
真倒霉，再见。”
Tough luck. See ya."

73
00:07:25,800 --> 00:07:32,800
这个回复不太礼貌，但假设这是客服想说的。
Not a very polite message, but let's say this is what a customer service agent wants.

74
00:07:32,800 --> 00:07:39,600
我们要把这个服务信息翻译成海盗式英语风格。
We are going to specify that the service message is going to be translated to this pirate style.

75
00:07:39,600 --> 00:07:45,520
所以我们希望它是一种礼貌的海盗式英语语调。
So we want it to be in a polite tone that speaks in English pirate.

76
00:07:45,520 --> 00:07:48,271
因为我们之前创建了那个提示模板，
And because we previously created that prompt template,

77
00:07:48,272 --> 00:07:58,920
很酷的是，我们现在可以重复使用那个提示模板，并指定我们想要的输出风格是这种客服风格的海盗式英语，文本是这个服务回复。
the cool thing is we can now reuse that prompt template and specify that the output style we want is this service style pirate and the text is this service reply.

78
00:07:58,920 --> 00:08:07,080
如果我们这样做，那就是提示。
And if we do that, that's the prompt.

79
00:08:07,080 --> 00:08:12,440
如果我们在ChatGPT上提示，这就是它给我们的回应。
And if we prompt on ChatGPT, this is the response it gives us back.

80
00:08:12,440 --> 00:08:21,440
“啊，伙计，我必须友善地告诉你，保修不包括费用或清洁你的厨房。”等等。
"Ahoy there, matey. I must kindly inform you that the warranty be not covering the expenses or cleaning your galley." And so on.

82
00:08:21,440 --> 00:08:23,920
“哎，运气不好。再见，伙计。”
"Aye, tough luck. Farewell, me hearty."

83
00:08:23,920 --> 00:08:29,200
那么你可能会想，为什么我们要用提示模板而不是"f"字符串呢？
So you might be wondering why are we using prompt templates instead of, you know, just an F string?

84
00:08:29,200 --> 00:08:35,840
答案是，当你构建复杂的应用程序时，提示可能会很长且详细。
The answer is that as you build sophisticated applications, prompts can be quite long and detailed.

85
00:08:35,840 --> 00:08:43,360
因此，提示模板是一种有用的抽象，可以帮助你在需要时重用好的提示。
And so prompt templates are a useful abstraction to help you reuse good prompts when you can.

86
00:08:43,360 --> 00:08:52,480
这是一个相对较长的示例，用于为在线学习应用程序的学生提交作品评分。
This is an example of a relatively long prompt to grade a student's submission for an online learning application.

87
00:08:52,480 --> 00:09:03,080
像这样的提示可能会很长，你可以要求LLM先解决问题，然后以某种格式输出。
And a prompt like this can be quite long in which you can ask the LLM to first solve the problem and then have the output in a certain format and output in a certain format.

88
00:09:03,080 --> 00:09:09,440
将这个提示包装在LangChain的提示中，可以更容易地重用这样的提示。
And wrapping this in a LangChain prompt makes it easier to reuse a prompt like this.

89
00:09:09,440 --> 00:09:22,580
你会看到，LangChain为一些常见操作提供了提示，如摘要、回答问题、连接到SQL数据库或连接到不同的API。
So you see later that LangChain provides prompts for some common operations such as summarization or question answering or connecting to SQL databases or connecting to different APIs.

90
00:09:22,580 --> 00:09:32,300
通过使用LangChain的内置提示，你可以快速地使应用程序运行，而无需设计自己的提示。
And so by using some of LangChain's built-in prompts, you can quickly get an application working without needing to engineer your own prompts.

91
00:09:32,300 --> 00:09:43,340
LangChain的提示库的另一个方面是它还支持输出解析，我们稍后会讲到。
One other aspect of LangChain's prompt libraries is that it also supports output parsing, which we'll get to in a minute.

92
00:09:43,340 --> 00:09:55,600
但是当你使用LLM构建一个复杂的应用程序时，你通常会指示LLM以某种格式生成输出，比如使用特定的关键词。
But when you're building a complex application using an LLM, you often instruct the LLM to generate its output in a certain format, such as using specific keywords.

93
00:09:55,600 --> 00:10:06,540
左边的这个例子展示了如何使用一个叫做"ReAct"的框架，让LLM执行一种叫做思维链推理的操作。
This example on the left illustrates using an LLM to carry out something called chain of thought reasoning using a framework called the ReAct framework.

94
00:10:06,540 --> 00:10:09,380
但不用担心技术细节。
But don't worry about the technical details.

95
00:10:09,380 --> 00:10:21,660
关键是这个"Thought"就是LLM在思考的内容，因为给LLM留出思考的空间，它往往能得出更准确的结论。
But the keys of that is that the thought is what the LLM is thinking because by giving an LLM space to think, it can often get to more accurate conclusions.

96
00:10:21,660 --> 00:10:31,700
然后用"Action"这个关键词来执行特定的动作，接着用"Observation"来展示它从这个动作中观察到了什么，等等。
Then action as a keyword to carry the specific action, and then observation to show what it learned from that action, and so on.

97
00:10:31,700 --> 00:10:39,599
如果你有一个提示让LLM使用这些特定的关键词："Thought"、"Action"和"Observation"，
And if you have a prompt that instructs the LLM to use these specific keywords, thought, action, and observation,

98
00:10:39,600 --> 00:10:48,140
那么这个提示可以与一个解析器结合，提取出用这些特定关键词标记的文本。
then this prompt can be coupled with a parser to extract out the text that has been tagged with these specific keywords.

99
00:10:48,140 --> 00:11:01,460
这样一来，就可以很好地抽象地指定LLM的输入，然后让解析器正确地解释LLM给出的输出。
And so that together gives a very nice abstraction to specify the input to an LLM, and then also have a parser correctly interpret the output that the LLM gives.

100
00:11:01,460 --> 00:11:09,140
有了这个，让我们回到一个使用LangChain的输出解析器的例子。
And so with that, let's return to see an example of an output parser using LangChain.

101
00:11:09,140 --> 00:11:17,700
在这个例子中，让我们看看如何让LLM输出JSON，并使用LangChain解析这个输出。
In this example, let's take a look at how you can have an LLM output JSON and use LangChain to parse that output.

102
00:11:17,700 --> 00:11:29,240
我将使用的运行示例是从产品评论中提取信息，并将输出格式化为JSON格式。
And the running example that I'll use will be to extract information from a product review and format that output in a JSON format.

103
00:11:29,240 --> 00:11:33,780
这是一个输出格式的示例。
So here's an example of how you would like the output to be formatted.

104
00:11:33,780 --> 00:11:45,140
从技术上讲，这是一个Python字典，其中“产品是否为礼品”是"False"，“交付所需的天数”是"5"，“价格值”是“相当实惠”。
Technically, this is a Python dictionary where whether or not the product is a gift, maps the falls, the number of days it took to deliver, was five, and the price value was pretty affordable.

105
00:11:45,140 --> 00:11:48,860
这是一个期望输出的例子。
So this is one example of a desired output.

106
00:11:48,860 --> 00:11:57,580
这是一个客户评论的例子，以及尝试获得JSON输出的模板。
Here is an example of customer review as well as a template to try to get to that JSON output.

107
00:11:57,580 --> 00:11:58,580
这是一条客户评论。
So here's a customer review.

108
00:11:58,580 --> 00:12:00,540
它说，“这个吹叶机非常神奇。
It says, "This leaf blower is pretty amazing.

109
00:12:00,540 --> 00:12:05,260
它有四个档位：微风、和风，大风和龙卷风。
It has four settings, candle blower, gentle breeze, windy city, and tornado.

110
00:12:05,260 --> 00:12:08,620
它在两天内送达，正好赶上我妻子的周年纪念礼物。
It arrived in two days, just in time for my wife's anniversary present.

111
00:12:08,620 --> 00:12:11,100
我想我的妻子也很喜欢，她都没说什么。
I think my wife liked it so much she was speechless.

112
00:12:11,100 --> 00:12:14,340
到目前为止，我是唯一一个使用它的人，等等。
So far I've been the only one using it," and so on.

113
00:12:14,340 --> 00:12:15,620
这里有一个评论模板。
And here's a review_template.

114
00:12:15,620 --> 00:12:20,260
对于以下文本，请提取以下信息：“这是不是一个礼物？”
For the following text, extract the following information, specify was this a gift

115
00:12:20,260 --> 00:12:24,180
所以在这种情况下，答案是肯定的，因为这是一个礼物。
So in this case, it would be yes because this is a gift

116
00:12:24,180 --> 00:12:26,940
还有“送货天数”，需要多长时间送达。
And also delivery days, how long did it take to deliver.

117
00:12:26,940 --> 00:12:30,100
看起来在这种情况下，它两天就到了。
It looks like in this case, it arrived in two days.

118
00:12:30,100 --> 00:12:32,140
“价格值”是多少？
And what's the price value?

119
00:12:32,140 --> 00:12:36,220
稍微贵一点，比别的吹叶机贵一些，等等。
You know, slightly more expensive than the leaf b'l'o'w'ers, and so on.

120
00:12:36,220 --> 00:12:52,460
评论模板要求LLM将客户评论作为输入，提取这三个字段，然后将输出格式化为JSON，带有以下键。
So the review_template asks the LLM to take as input a customer review and extract these three fields, and then format the output as JSON, um, with the following keys.

121
00:12:55,460 --> 00:12:57,340
好的。
All right.

122
00:12:57,340 --> 00:13:01,380
这就是如何将其封装在LongChain中。
So here's how you can wrap this in LongChain.

123
00:13:01,380 --> 00:13:03,020
让我们导入聊天提示模板。
Let's import the ChatPrompt template.

124
00:13:03,020 --> 00:13:04,880
其实我们之前已经导入过了。
We'd actually imported this already earlier.

125
00:13:04,880 --> 00:13:16,580
从技术上讲，这行是多余的，但我还是会再次导入，然后从上面的review_template创建提示模板。
So technically, this line is redundant, but I'll just import it again and then have the prompt templates, um, created from the review_template up on top.

126
00:13:16,580 --> 00:13:20,700
这就是提示模板。
And so here's the prompt template.

127
00:13:20,700 --> 00:13:33,020
现在，与我们之前使用提示模板类似，让我们创建要传递给OpenAI API的消息。
And now, similar to our early usage of a prompt template, let's create the messages to pass to the OpenAI, uh, endpoint.

128
00:13:33,020 --> 00:13:39,420
创建OpenAI API，调用该API，然后打印出响应。
Create the OpenAI endpoint, call that endpoint, and then let's print out the response.

129
00:13:39,420 --> 00:13:45,700
我建议你暂停视频并运行代码。
I encourage you to pause the video and run the code.

130
00:13:45,700 --> 00:13:46,700
就是这样。
And there it is.

131
00:13:46,700 --> 00:13:52,940
它显示：是礼物，送货天数为2天，价格值看起来也相当准确。
It says, "Gift is true, delivery days is two," and the price value also looks pretty accurate.

132
00:13:52,940 --> 00:14:04,220
嗯，但请注意，如果我们检查返回数据的类型，这实际上是一个字符串。
Um, but note that if we check the type of the response, this is actually a string.

133
00:14:04,220 --> 00:14:09,580
它看起来像JSON，看起来有键值对，但实际上不是字典。
So it looks like JSON and looks like it has key value pairs, but it's actually not a dictionary.

134
00:14:09,580 --> 00:14:12,220
这只是一个很长的字符串。
This is just one long string.

135
00:14:12,220 --> 00:14:17,420
所以我真正想做的是去解析返回的内容，从键"gift"中获取值，这应该是"True"。
So what I'd really like to do is go to the response content and get the value from the gift key, which should be true.

136
00:14:17,420 --> 00:14:22,020
但是当我运行这个时，这应该会产生一个错误，因为，嗯，这实际上是一个字符串。
But I run this, this should generate an error because, well, this is actually a string.

137
00:14:22,020 --> 00:14:24,820
这不是一个Python字典。
This is not a Python dictionary.

138
00:14:24,820 --> 00:14:31,860
那么让我们看看如何使用LangChain的解析器来完成这个任务。
So let's see how we would use LangChain's, um, parser in order to do this.

139
00:14:31,860 --> 00:14:40,140
我将从LangChain导入ResponseSchema和StructuredOutputParser。
I'm going to import ResponseSchema and StructuredOutputParser from LangChain.

140
00:14:40,140 --> 00:14:46,480
然后我将通过指定这些返回的JSON的格式规范告诉LangChain我希望它解析什么。
And I'm going to tell it what I want it to parse by specifying these response schemas.

141
00:14:46,480 --> 00:14:50,340
在JSON格式规范中代表“礼物”的名称是"gift"，这是它的描述。
So the gift schema is named gift, and here's the description.

142
00:14:50,340 --> 00:14:52,420
这个物品是为别人购买礼物吗？
Does the item purchase a gift for someone else?

143
00:14:52,420 --> 00:14:56,540
嗯，回答是或者对，否则回答不是或者未知等等。
Uh, answer true or yes, false if not or unknown, and so on.

144
00:14:56,540 --> 00:15:05,820
所以有一个礼物规范、送货日期规范、价格值规范，然后像这样把它们都放到一个列表里。
So have a gift schema, delivery day schema, price value schema, and then let's put all three of them into a list as follows.

145
00:15:05,820 --> 00:15:20,380
现在我已经为这些指定了规范，呃，LangChain实际上可以通过让output_parser告诉你它希望你发送给LLM的指令来给你提示。
Now that I've specified the schema for these, um, LangChain can actually give you the prompt itself by having the output parser tell you what instructions it wants you to send to the LLM.

146
00:15:20,380 --> 00:15:34,980
所以如果我要打印格式指令，它对LLM有一套相当精确的指令，可以让LLM生成指定的内容格式以便解析器可以解析。
So if I were to print format instructions, she has a pretty precise set of instructions for the LLM that will cause it to generate an output that the output parser can process.

147
00:15:34,980 --> 00:15:44,056
所以这是新的review_template，review_template包括LangChain生成的格式指令，
So here's the new review_template, and the review_template includes the format instructions that LangChain generated,

148
00:15:44,057 --> 00:15:58,700
这样它就可以从review_template中创建提示，然后创建传递给OpenAI API的消息。
and so it can create a prompt from the review_template too, and then create the messages that will pass to the OpenAI endpoint.

149
00:15:58,700 --> 00:16:16,180
如果你愿意，你可以看一下实际的提示，它会给你提取礼物、送货天数、价格值等字段的指令，这是文本，然后这是格式指令。
If you want, you can take a look at the actual prompt, which gives you instructions to extract the fields, gift, delivery days, price value, here's the text, and then here are the formatting instructions.

150
00:16:16,180 --> 00:16:30,260
最后，如果我们调用OpenAI API，让我们看看会得到什么返回结果。
Finally, if we call the OpenAI endpoint, let's take a look at what response we got.

151
00:16:30,260 --> 00:16:41,586
现在是这样的，现在如果我们使用之前创建的output_parser，
It is now this, and now if we use the output_parser that we created earlier,

152
00:16:41,600 --> 00:16:48,843
你就可以把这个解析成一个output_dict，如果我打印出来就是这样的，
you can then parse this into an output dictionary, which if I print looks like this,

153
00:16:48,844 --> 00:16:56,586
注意到这是字典类型，而不是字符串，
and notice that this is of type dictionary, not a string,

154
00:16:56,587 --> 00:17:09,020
这就是为什么我现在可以提取与“礼物”关联的值并得到"True"，或者与“送货天数”关联的值并得到"2"，
which is why I can now extract the value associated with the key gift and get true, or the value associated with delivery days and get two,

155
00:17:09,020 --> 00:17:14,760
或者你还可以提取与“价格值”关联的值。
or you can also extract the value associated with price value.

156
00:17:14,760 --> 00:17:24,800
这是一种将LLM输出解析为Python字典的巧妙方法，使输出更易于在后续处理中使用。
So this is a nifty way to take your LLM output and parse it into a Python dictionary to make the output easier to use in downstream processing.

157
00:17:24,800 --> 00:17:29,200
我建议你暂停视频并运行代码。
I encourage you to pause the video and run the code.

158
00:17:29,200 --> 00:17:32,780
关于模型、提示和解析器就是这些了。
And so that's it for models, prompts, and parsers.

159
00:17:32,780 --> 00:17:37,960
有了这些工具，希望你能更轻松地重用自己的提示模板，
With these tools, hopefully you'll be able to reuse your own prompt templates easily,

160
00:17:37,960 --> 00:17:42,280
与合作伙伴共享提示模板，甚至使用LangChain的内置
share prompt templates with others that you're collaborating with, even use LangChain's built-in

161
00:17:42,280 --> 00:17:51,975
提示模板，正如你刚刚看到的，通常可以与输出解析器配合使用，以便输入提示以特定格式输出
prompt templates, which as you just saw, can often be coupled with an output_parser, so that the input prompt to output in a specific format

162
00:17:51,976 --> 00:18:02,280
然后解析器解析输出，将数据存储在Python字典或其他数据结构中，以便用于后续处理的。
and then the parser parses that output to store the data in a Python dictionary or some other data structure that makes it easy for downstream processing.

163
00:18:02,280 --> 00:18:06,400
希望这些知识能对你有用，帮助你应用在自己的应用开发中。
I hope you find this useful in many of your applications.

164
00:18:06,400 --> 00:18:08,300
说到这里，我们接下来将继续下一个视频
And with that, let's go into the next video

165
00:18:08,301 --> 00:18:16,557
在那里我们将学习LangChain如何帮助你构建更好的聊天机器人，
where we'll see how LangChain can help you build better chatbots or have an LLM have more effective chats

166
00:18:16,558 --> 00:18:21,240
让LLM通过更好地管理历史对话，达到更好的聊天效果。
by better managing what it remembers from the conversation you've had so far.
