在第一课中，我们将\N介绍模型、提示和解析器。 所谓模型，是指\N作为基础的语言模型。 提示（Prompt）指创建\N输入，是用来给模型\N传递信息的一种方式。 而解析器则与之相反， 它接收模型的输出，并将输出\N结果解析成更结构化的格式，\N以便你可以对其进行后续操作。 因此，当您使用LLM构建应用程序\N时，通常会有可重用的模块。 我们反复提示模型，解析\N输出，所以LangChain提供了\N一套简单的抽象来执行此类操作。 那么，让我们开始\N研究模型、提示和解析器。 首先，这里有一些入门代码。 我将导入"os"库，导入"openai"库，\N并加载我的OpenAI密钥。 "openai"库已经安装在我的Jupyter Notebook环境中。 如果你在本地运行，还没有\N安装"openai"，你可能需要运行它。 虽然可以用"!pip install openai"，\N但这里我不会这么做。 然后这里有一个辅助函数。 这个辅助函数实际上与我和OpenAI的Isa \NFulford一起讲过的《给开发者的ChatGPT\N提示工程》课程中的辅助函数非常相似。 有了这个辅助函数，\N你可以对“1+1是多少”这样的\N问题使用get_completion。 这将调用ChatGPT，或者\N更准确地说是GPT 3.5 Turbo\N模型，给你一个像这样的答案。 现在，为了阐明LangChain对模型\N提示和解析的抽象，假设你收到了\N一封用非英语写的客户邮件。 为了确保这是可接受的，我将\N使用另一种语言，海盗风格的英语。 邮件内容是：“我简直被气得七窍生烟，\N因为我的搅拌机盖子飞了出去，\N把我的厨房墙上都溅满了果汁。” 更糟糕的是，保修不包括清理厨房的费用。 我现在需要你的帮助，伙计。 我们要做的是让这个LLM把\N文本翻译成平静、尊重的美式英语。 所以我要把风格设为平静、尊重的美式英语。 为了实现这个目标，如果\N你之前看过一些提示相关的课程， 我会用"f"字符串和说明来指定提示， 把用三个反引号括起来的文本翻译成\N"style"那样的风格，然后插入这两种风格。 这样就生成了一个提示说：\N“翻译这段文本”等等。 我建议你暂停视频，运行代码，还可以\N尝试修改提示，看看能否得到不同的输出。 然后你可以提示大语言模型得到一个结果。 我们来看看返回的结果是什么。 它说把海盗风格英语的\N信息翻译成了这段礼貌的英语文字： “我真的很伤心，因为我的搅拌机盖子\N飞了出去，把我的厨房墙上弄得一团糟… 我现在真的需要你的帮助，朋友！” 听起来很不错。 如果现在你有不同的客户，\N用不同的语言写评论，不仅仅是\N海盗风格英语，还有法语、德语、日语等等， 你可以想象，这需要生成一整套针对\N各种不同语言的提示来生成这样的翻译。 让我们看看如何用\NLangChain更方便地实现这一点。 我要导入ChatOpenAI。 这是LangChain对ChatGPT API访问的抽象。 如果我把"chat"设置为ChatOpenAI的实例，\N然后看看"chat"是什么， 它会创建一个如下的对象，使用的\N是ChatGPT模型，也叫做gpt-3.5-turbo。 当我构建应用程序时，\N我经常会把temperature参数设置为0。 默认的temperature是0.7，但让我\N实际上用temperature等于0.0重做一遍。 现在temperature设为0，\N让输出的随机性降低一点。 现在让我定义一个模板字符串。 把用三个反引号分隔的\N文本翻译成"style"的风格。 然后是这里的文本。 为了反复使用这个模板，让我们\N导入LangChain的ChatPromptTemplate。 然后让我用我们刚才写的\N模板字符串创建一个提示模板。 从提示模板中，你可以提取原始的提示。 它意识到这个提示有两个输入变量，\N"style"和"text"，这里用大括号表示。 这里也有我们之前指定的原始模板。 实际上，如果我把这个打印出来，它知道\N它有两个输入变量，"style"和"text"。 现在让我们指定风格。 这是我希望客户信息被翻译成的风格。 所以我要把这个叫做customer_style。 这是我之前的相同客户邮件。 现在如果我创建customer_messages，\N这将生成提示，并在一分钟内\N传递给大型语言模型以获得返回结果。 所以如果你想看看类型，\Ncustomer_messages实际上是一个列表。 如果你看列表的第一个元素，\N这基本上就是你期望得到的提示。 最后，让我们把这个提示传给LLM。 接下来我要调用"chat"，我们之前\N把它设置为OpenAI ChatGPT的实例引用。 如果我们打印出客户回复\N的内容，那么它会把这段\N从海盗式英语翻译成礼貌的美式英语。 当然，你可以想象其他情况，\N比如客户邮件是用其他语言写的。 这也可以用来为英语使用者\N翻译消息，以便他们理解并回复。 我建议你暂停视频，运行代码，\N尝试修改提示，看看能否得到不同的输出。 现在让我们希望客服代表\N用客户的原始语言回复客户。 假设英语客服代表写了\N这个并说：“嘿，亲爱的客户， 保修不包括厨房的\N清洁费用，因为这是你的错。 你在使用搅拌机时忘了盖上盖子。 真倒霉，再见。” 这个回复不太礼貌，但假设这是客服想说的。 我们要把这个服务信息\N翻译成海盗式英语风格。 所以我们希望它是一种\N礼貌的海盗式英语语调。 因为我们之前创建了那个提示模板， 很酷的是，我们现在可以重复使用那个提示\N模板，并指定我们想要的输出风格是这种客服\N风格的海盗式英语，文本是这个服务回复。 如果我们这样做，那就是提示。 如果我们在ChatGPT上提示，\N这就是它给我们的回应。 “啊，伙计，我必须友善地告诉你，\N保修不包括费用或清洁你的厨房。”等等。  “哎，运气不好。再见，伙计。” 那么你可能会想，为什么我们\N要用提示模板而不是"f"字符串呢？ 答案是，当你构建复杂的\N应用程序时，提示可能会很长且详细。 因此，提示模板是一种有用的抽象，\N可以帮助你在需要时重用好的提示。 这是一个相对较长的示例，用于为\N在线学习应用程序的学生提交作品评分。 像这样的提示可能会很长，你可以\N要求LLM先解决问题，然后以某种格式输出。 将这个提示包装在LangChain的\N提示中，可以更容易地重用这样的提示。 你会看到，LangChain为一些\N常见操作提供了提示，如摘要、回答问题、\N连接到SQL数据库或连接到不同的API。 通过使用LangChain的内置提示，你可以快速\N地使应用程序运行，而无需设计自己的提示。 LangChain的提示库的另一个方面\N是它还支持输出解析，我们稍后会讲到。 但是当你使用LLM构建一个复杂的\N应用程序时，你通常会指示LLM以\N某种格式生成输出，比如使用特定的关键词。 左边的这个例子展示了如何\N使用一个叫做"ReAct"的框架，\N让LLM执行一种叫做思维链推理的操作。 但不用担心技术细节。 关键是这个"Thought"就是LLM在\N思考的内容，因为给LLM留出思考\N的空间，它往往能得出更准确的结论。 然后用"Action"这个关键词\N来执行特定的动作，接着用"Observation"\N来展示它从这个动作中观察到了什么，等等。 如果你有一个提示让LLM\N使用这些特定的关键词：\N"Thought"、"Action"和"Observation"， 那么这个提示可以与一个解析器结合，\N提取出用这些特定关键词标记的文本。 这样一来，就可以很好地\N抽象地指定LLM的输入，然后\N让解析器正确地解释LLM给出的输出。 有了这个，让我们回到一个使用\NLangChain的输出解析器的例子。 在这个例子中，让我们看看如何让LLM\N输出JSON，并使用LangChain解析这个输出。 我将使用的运行示例是从产品评论中\N提取信息，并将输出格式化为JSON格式。 这是一个输出格式的示例。 从技术上讲，这是一个Python字典，其中\N“产品是否为礼品”是"False"，“交付\N所需的天数”是"5"，“价格值”是“相当实惠”。 这是一个期望输出的例子。 这是一个客户评论的例子，\N以及尝试获得JSON输出的模板。 这是一条客户评论。 它说，“这个吹叶机非常神奇。 它有四个档位：微风、\N和风，大风和龙卷风。 它在两天内送达，\N正好赶上我妻子的周年纪念礼物。 我想我的妻子也很喜欢，她都没说什么。 到目前为止，我是唯一\N一个使用它的人，等等。 这里有一个评论模板。 对于以下文本，请提取\N以下信息：“这是不是一个礼物？” 所以在这种情况下，答案是\N肯定的，因为这是一个礼物。 还有“送货天数”，需要多长时间送达。 看起来在这种情况下，它两天就到了。 “价格值”是多少？ 稍微贵一点，比别的吹叶机贵一些，等等。 评论模板要求LLM将客户评论\N作为输入，提取这三个字段，然后\N将输出格式化为JSON，带有以下键。 好的。 这就是如何将其封装在LongChain中。 让我们导入聊天提示模板。 其实我们之前已经导入过了。 从技术上讲，这行是多余的，但我\N还是会再次导入，然后从上面的\Nreview_template创建提示模板。 这就是提示模板。 现在，与我们之前使用\N提示模板类似，让我们创建\N要传递给OpenAI API的消息。 创建OpenAI API，调用\N该API，然后打印出响应。 我建议你暂停视频并运行代码。 就是这样。 它显示：是礼物，送货天数为\N2天，价格值看起来也相当准确。 嗯，但请注意，如果我们检查\N返回数据的类型，这实际上是一个字符串。 它看起来像JSON，看起来\N有键值对，但实际上不是字典。 这只是一个很长的字符串。 所以我真正想做的是去解析返回的内容，\N从键"gift"中获取值，这应该是"True"。 但是当我运行这个时，这应该会产生一个\N错误，因为，嗯，这实际上是一个字符串。 这不是一个Python字典。 那么让我们看看如何使用\NLangChain的解析器来完成这个任务。 我将从LangChain\N导入ResponseSchema\N和StructuredOutputParser。 然后我将通过指定这些返回的JSON的\N格式规范告诉LangChain我希望它解析什么。 在JSON格式规范中代表“礼物”的\N名称是"gift"，这是它的描述。 这个物品是为别人购买礼物吗？ 嗯，回答是或者对，\N否则回答不是或者未知等等。 所以有一个礼物规范、送货日期规范、价格值\N规范，然后像这样把它们都放到一个列表里。 现在我已经为这些指定了规范，呃，\NLangChain实际上可以通过让output_parser\N告诉你它希望你发送给LLM的指令来给你提示。 所以如果我要打印格式指令，\N它对LLM有一套相当精确的指令，可以让\NLLM生成指定的内容格式以便解析器可以解析。 所以这是新的review_template，\Nreview_template包括\NLangChain生成的格式指令， 这样它就可以从review_template中创建提示，\N然后创建传递给OpenAI API的消息。 如果你愿意，你可以看一下实际的提示，\N它会给你提取礼物、送货天数、价格值等字段\N的指令，这是文本，然后这是格式指令。 最后，如果我们调用OpenAI API，\N让我们看看会得到什么返回结果。 现在是这样的，现在如果\N我们使用之前创建的output_parser， 你就可以把这个解析成一个output_dict\N，如果我打印出来就是这样的， 注意到这是字典类型，而不是字符串， 这就是为什么我现在可以\N提取与“礼物”关联的值并得到"True"，\N或者与“送货天数”关联的值并得到"2"， 或者你还可以提取与“价格值”关联的值。 这是一种将LLM输出解析为Python字典的\N巧妙方法，使输出更易于在后续处理中使用。 我建议你暂停视频并运行代码。 关于模型、提示和解析器就是这些了。 有了这些工具，希望你\N能更轻松地重用自己的提示模板， 与合作伙伴共享提示模板，\N甚至使用LangChain的内置 提示模板，正如你刚刚看到的，\N通常可以与输出解析器配合\N使用，以便输入提示以特定格式输出 然后解析器解析输出，将\N数据存储在Python字典或其他\N数据结构中，以便用于后续处理的。 希望这些知识能对你有用，帮助你应用在自己的应用开发中。 说到这里，我们接下来将继续下一个视频 在那里我们将学习LangChain\N如何帮助你构建更好的聊天机器人， 让LLM通过更好地管理\N历史对话，达到更好的聊天效果。