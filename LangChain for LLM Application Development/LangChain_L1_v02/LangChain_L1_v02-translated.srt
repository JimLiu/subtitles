1
00:00:05,000 --> 00:00:08,800
在第一课中，我们将介绍模型、提示和解析器。

2
00:00:08,800 --> 00:00:13,600
所谓模型，是指作为基础的语言模型。

3
00:00:13,600 --> 00:00:18,760
提示（Prompt）指创建输入，是用来给模型传递信息的一种方式。

4
00:00:18,760 --> 00:00:20,760
而解析器则与之相反，

5
00:00:20,760 --> 00:00:27,760
它接收模型的输出，并将输出结果解析成更结构化的格式，以便你可以对其进行后续操作。

6
00:00:27,760 --> 00:00:32,640
因此，当您使用LLM构建应用程序时，通常会有可重用的模块。

7
00:00:32,640 --> 00:00:40,140
我们反复提示模型，解析输出，所以LangChain提供了一套简单的抽象来执行此类操作。

8
00:00:40,140 --> 00:00:45,160
那么，让我们开始研究模型、提示和解析器。

9
00:00:45,160 --> 00:00:47,640
首先，这里有一些入门代码。

10
00:00:47,640 --> 00:00:53,720
我将导入"os"库，导入"openai"库，并加载我的OpenAI密钥。

11
00:00:53,720 --> 00:00:58,040
"openai"库已经安装在我的Jupyter Notebook环境中。

12
00:00:58,040 --> 00:01:03,440
如果你在本地运行，还没有安装"openai"，你可能需要运行它。

13
00:01:03,440 --> 00:01:07,360
虽然可以用"!pip install openai"，但这里我不会这么做。

14
00:01:07,360 --> 00:01:09,000
然后这里有一个辅助函数。

15
00:01:09,000 --> 00:01:20,680
这个辅助函数实际上与我和OpenAI的Isa Fulford一起讲过的《给开发者的ChatGPT提示工程》课程中的辅助函数非常相似。

16
00:01:20,680 --> 00:01:26,960
有了这个辅助函数，你可以对“1+1是多少”这样的问题使用get_completion。

17
00:01:26,960 --> 00:01:36,200
这将调用ChatGPT，或者更准确地说是GPT 3.5 Turbo模型，给你一个像这样的答案。

18
00:01:36,200 --> 00:01:49,840
现在，为了阐明LangChain对模型提示和解析的抽象，假设你收到了一封用非英语写的客户邮件。

19
00:01:49,840 --> 00:01:55,285
为了确保这是可接受的，我将使用另一种语言，海盗风格的英语。

20
00:01:55,286 --> 00:02:02,680
邮件内容是：“我简直被气得七窍生烟，因为我的搅拌机盖子飞了出去，把我的厨房墙上都溅满了果汁。”

21
00:02:02,680 --> 00:02:06,080
更糟糕的是，保修不包括清理厨房的费用。

22
00:02:06,080 --> 00:02:08,600
我现在需要你的帮助，伙计。

23
00:02:08,600 --> 00:02:18,360
我们要做的是让这个LLM把文本翻译成平静、尊重的美式英语。

24
00:02:18,360 --> 00:02:23,400
所以我要把风格设为平静、尊重的美式英语。

25
00:02:23,400 --> 00:02:29,320
为了实现这个目标，如果你之前看过一些提示相关的课程，

26
00:02:29,320 --> 00:02:32,986
我会用"f"字符串和说明来指定提示，

27
00:02:32,987 --> 00:02:40,160
把用三个反引号括起来的文本翻译成"style"那样的风格，然后插入这两种风格。

28
00:02:40,160 --> 00:02:46,120
这样就生成了一个提示说：“翻译这段文本”等等。

29
00:02:46,120 --> 00:02:54,800
我建议你暂停视频，运行代码，还可以尝试修改提示，看看能否得到不同的输出。

30
00:02:54,800 --> 00:03:03,080
然后你可以提示大语言模型得到一个结果。

31
00:03:03,080 --> 00:03:04,080
我们来看看返回的结果是什么。

32
00:03:04,080 --> 00:03:07,871
它说把海盗风格英语的信息翻译成了这段礼貌的英语文字：

33
00:03:07,872 --> 00:03:13,540
“我真的很伤心，因为我的搅拌机盖子飞了出去，把我的厨房墙上弄得一团糟…

34
00:03:13,540 --> 00:03:16,520
我现在真的需要你的帮助，朋友！”

35
00:03:16,520 --> 00:03:18,760
听起来很不错。

36
00:03:18,761 --> 00:03:27,271
如果现在你有不同的客户，用不同的语言写评论，不仅仅是海盗风格英语，还有法语、德语、日语等等，

37
00:03:27,272 --> 00:03:34,500
你可以想象，这需要生成一整套针对各种不同语言的提示来生成这样的翻译。

38
00:03:34,500 --> 00:03:40,360
让我们看看如何用LangChain更方便地实现这一点。

39
00:03:40,360 --> 00:03:44,600
我要导入ChatOpenAI。

40
00:03:44,600 --> 00:03:49,780
这是LangChain对ChatGPT API访问的抽象。

41
00:03:49,780 --> 00:03:54,157
如果我把"chat"设置为ChatOpenAI的实例，然后看看"chat"是什么，

42
00:03:54,158 --> 00:04:02,960
它会创建一个如下的对象，使用的是ChatGPT模型，也叫做gpt-3.5-turbo。

43
00:04:02,960 --> 00:04:09,740
当我构建应用程序时，我经常会把temperature参数设置为0。

44
00:04:09,740 --> 00:04:20,400
默认的temperature是0.7，但让我实际上用temperature等于0.0重做一遍。

45
00:04:20,400 --> 00:04:27,960
现在temperature设为0，让输出的随机性降低一点。

46
00:04:27,960 --> 00:04:30,960
现在让我定义一个模板字符串。

47
00:04:30,960 --> 00:04:35,280
把用三个反引号分隔的文本翻译成"style"的风格。

48
00:04:35,280 --> 00:04:37,480
然后是这里的文本。

49
00:04:37,480 --> 00:04:47,040
为了反复使用这个模板，让我们导入LangChain的ChatPromptTemplate。

50
00:04:47,040 --> 00:05:00,760
然后让我用我们刚才写的模板字符串创建一个提示模板。

51
00:05:00,760 --> 00:05:04,860
从提示模板中，你可以提取原始的提示。

52
00:05:04,860 --> 00:05:17,040
它意识到这个提示有两个输入变量，"style"和"text"，这里用大括号表示。

53
00:05:17,040 --> 00:05:19,720
这里也有我们之前指定的原始模板。

54
00:05:19,720 --> 00:05:28,200
实际上，如果我把这个打印出来，它知道它有两个输入变量，"style"和"text"。

55
00:05:28,200 --> 00:05:30,360
现在让我们指定风格。

56
00:05:30,360 --> 00:05:33,960
这是我希望客户信息被翻译成的风格。

57
00:05:33,960 --> 00:05:37,240
所以我要把这个叫做customer_style。

58
00:05:37,240 --> 00:05:44,960
这是我之前的相同客户邮件。

59
00:05:44,960 --> 00:05:59,640
现在如果我创建customer_messages，这将生成提示，并在一分钟内传递给大型语言模型以获得返回结果。

60
00:05:59,640 --> 00:06:05,200
所以如果你想看看类型，customer_messages实际上是一个列表。

61
00:06:05,200 --> 00:06:16,400
如果你看列表的第一个元素，这基本上就是你期望得到的提示。

62
00:06:16,400 --> 00:06:20,560
最后，让我们把这个提示传给LLM。

63
00:06:20,560 --> 00:06:32,560
接下来我要调用"chat"，我们之前把它设置为OpenAI ChatGPT的实例引用。

64
00:06:32,560 --> 00:06:45,400
如果我们打印出客户回复的内容，那么它会把这段从海盗式英语翻译成礼貌的美式英语。

65
00:06:45,400 --> 00:06:50,560
当然，你可以想象其他情况，比如客户邮件是用其他语言写的。

66
00:06:50,560 --> 00:06:58,240
这也可以用来为英语使用者翻译消息，以便他们理解并回复。

67
00:06:58,240 --> 00:07:06,720
我建议你暂停视频，运行代码，尝试修改提示，看看能否得到不同的输出。

68
00:07:06,720 --> 00:07:11,880
现在让我们希望客服代表用客户的原始语言回复客户。

69
00:07:11,880 --> 00:07:17,040
假设英语客服代表写了这个并说：“嘿，亲爱的客户，

70
00:07:17,040 --> 00:07:20,400
保修不包括厨房的清洁费用，因为这是你的错。

71
00:07:20,400 --> 00:07:23,800
你在使用搅拌机时忘了盖上盖子。

72
00:07:23,800 --> 00:07:25,800
真倒霉，再见。”

73
00:07:25,800 --> 00:07:32,800
这个回复不太礼貌，但假设这是客服想说的。

74
00:07:32,800 --> 00:07:39,600
我们要把这个服务信息翻译成海盗式英语风格。

75
00:07:39,600 --> 00:07:45,520
所以我们希望它是一种礼貌的海盗式英语语调。

76
00:07:45,520 --> 00:07:48,271
因为我们之前创建了那个提示模板，

77
00:07:48,272 --> 00:07:58,920
很酷的是，我们现在可以重复使用那个提示模板，并指定我们想要的输出风格是这种客服风格的海盗式英语，文本是这个服务回复。

78
00:07:58,920 --> 00:08:07,080
如果我们这样做，那就是提示。

79
00:08:07,080 --> 00:08:12,440
如果我们在ChatGPT上提示，这就是它给我们的回应。

80
00:08:12,440 --> 00:08:21,440
“啊，伙计，我必须友善地告诉你，保修不包括费用或清洁你的厨房。”等等。

82
00:08:21,440 --> 00:08:23,920
“哎，运气不好。再见，伙计。”

83
00:08:23,920 --> 00:08:29,200
那么你可能会想，为什么我们要用提示模板而不是"f"字符串呢？

84
00:08:29,200 --> 00:08:35,840
答案是，当你构建复杂的应用程序时，提示可能会很长且详细。

85
00:08:35,840 --> 00:08:43,360
因此，提示模板是一种有用的抽象，可以帮助你在需要时重用好的提示。

86
00:08:43,360 --> 00:08:52,480
这是一个相对较长的示例，用于为在线学习应用程序的学生提交作品评分。

87
00:08:52,480 --> 00:09:03,080
像这样的提示可能会很长，你可以要求LLM先解决问题，然后以某种格式输出。

88
00:09:03,080 --> 00:09:09,440
将这个提示包装在LangChain的提示中，可以更容易地重用这样的提示。

89
00:09:09,440 --> 00:09:22,580
你会看到，LangChain为一些常见操作提供了提示，如摘要、回答问题、连接到SQL数据库或连接到不同的API。

90
00:09:22,580 --> 00:09:32,300
通过使用LangChain的内置提示，你可以快速地使应用程序运行，而无需设计自己的提示。

91
00:09:32,300 --> 00:09:43,340
LangChain的提示库的另一个方面是它还支持输出解析，我们稍后会讲到。

92
00:09:43,340 --> 00:09:55,600
但是当你使用LLM构建一个复杂的应用程序时，你通常会指示LLM以某种格式生成输出，比如使用特定的关键词。

93
00:09:55,600 --> 00:10:06,540
左边的这个例子展示了如何使用一个叫做"ReAct"的框架，让LLM执行一种叫做思维链推理的操作。

94
00:10:06,540 --> 00:10:09,380
但不用担心技术细节。

95
00:10:09,380 --> 00:10:21,660
关键是这个"Thought"就是LLM在思考的内容，因为给LLM留出思考的空间，它往往能得出更准确的结论。

96
00:10:21,660 --> 00:10:31,700
然后用"Action"这个关键词来执行特定的动作，接着用"Observation"来展示它从这个动作中观察到了什么，等等。

97
00:10:31,700 --> 00:10:39,599
如果你有一个提示让LLM使用这些特定的关键词："Thought"、"Action"和"Observation"，

98
00:10:39,600 --> 00:10:48,140
那么这个提示可以与一个解析器结合，提取出用这些特定关键词标记的文本。

99
00:10:48,140 --> 00:11:01,460
这样一来，就可以很好地抽象地指定LLM的输入，然后让解析器正确地解释LLM给出的输出。

100
00:11:01,460 --> 00:11:09,140
有了这个，让我们回到一个使用LangChain的输出解析器的例子。

101
00:11:09,140 --> 00:11:17,700
在这个例子中，让我们看看如何让LLM输出JSON，并使用LangChain解析这个输出。

102
00:11:17,700 --> 00:11:29,240
我将使用的运行示例是从产品评论中提取信息，并将输出格式化为JSON格式。

103
00:11:29,240 --> 00:11:33,780
这是一个输出格式的示例。

104
00:11:33,780 --> 00:11:45,140
从技术上讲，这是一个Python字典，其中“产品是否为礼品”是"False"，“交付所需的天数”是"5"，“价格值”是“相当实惠”。

105
00:11:45,140 --> 00:11:48,860
这是一个期望输出的例子。

106
00:11:48,860 --> 00:11:57,580
这是一个客户评论的例子，以及尝试获得JSON输出的模板。

107
00:11:57,580 --> 00:11:58,580
这是一条客户评论。

108
00:11:58,580 --> 00:12:00,540
它说，“这个吹叶机非常神奇。

109
00:12:00,540 --> 00:12:05,260
它有四个档位：微风、和风，大风和龙卷风。

110
00:12:05,260 --> 00:12:08,620
它在两天内送达，正好赶上我妻子的周年纪念礼物。

111
00:12:08,620 --> 00:12:11,100
我想我的妻子也很喜欢，她都没说什么。

112
00:12:11,100 --> 00:12:14,340
到目前为止，我是唯一一个使用它的人，等等。

113
00:12:14,340 --> 00:12:15,620
这里有一个评论模板。

114
00:12:15,620 --> 00:12:20,260
对于以下文本，请提取以下信息：“这是不是一个礼物？”

115
00:12:20,260 --> 00:12:24,180
所以在这种情况下，答案是肯定的，因为这是一个礼物。

116
00:12:24,180 --> 00:12:26,940
还有“送货天数”，需要多长时间送达。

117
00:12:26,940 --> 00:12:30,100
看起来在这种情况下，它两天就到了。

118
00:12:30,100 --> 00:12:32,140
“价格值”是多少？

119
00:12:32,140 --> 00:12:36,220
稍微贵一点，比别的吹叶机贵一些，等等。

120
00:12:36,220 --> 00:12:52,460
评论模板要求LLM将客户评论作为输入，提取这三个字段，然后将输出格式化为JSON，带有以下键。

121
00:12:55,460 --> 00:12:57,340
好的。

122
00:12:57,340 --> 00:13:01,380
这就是如何将其封装在LongChain中。

123
00:13:01,380 --> 00:13:03,020
让我们导入聊天提示模板。

124
00:13:03,020 --> 00:13:04,880
其实我们之前已经导入过了。

125
00:13:04,880 --> 00:13:16,580
从技术上讲，这行是多余的，但我还是会再次导入，然后从上面的review_template创建提示模板。

126
00:13:16,580 --> 00:13:20,700
这就是提示模板。

127
00:13:20,700 --> 00:13:33,020
现在，与我们之前使用提示模板类似，让我们创建要传递给OpenAI API的消息。

128
00:13:33,020 --> 00:13:39,420
创建OpenAI API，调用该API，然后打印出响应。

129
00:13:39,420 --> 00:13:45,700
我建议你暂停视频并运行代码。

130
00:13:45,700 --> 00:13:46,700
就是这样。

131
00:13:46,700 --> 00:13:52,940
它显示：是礼物，送货天数为2天，价格值看起来也相当准确。

132
00:13:52,940 --> 00:14:04,220
嗯，但请注意，如果我们检查返回数据的类型，这实际上是一个字符串。

133
00:14:04,220 --> 00:14:09,580
它看起来像JSON，看起来有键值对，但实际上不是字典。

134
00:14:09,580 --> 00:14:12,220
这只是一个很长的字符串。

135
00:14:12,220 --> 00:14:17,420
所以我真正想做的是去解析返回的内容，从键"gift"中获取值，这应该是"True"。

136
00:14:17,420 --> 00:14:22,020
但是当我运行这个时，这应该会产生一个错误，因为，嗯，这实际上是一个字符串。

137
00:14:22,020 --> 00:14:24,820
这不是一个Python字典。

138
00:14:24,820 --> 00:14:31,860
那么让我们看看如何使用LangChain的解析器来完成这个任务。

139
00:14:31,860 --> 00:14:40,140
我将从LangChain导入ResponseSchema和StructuredOutputParser。

140
00:14:40,140 --> 00:14:46,480
然后我将通过指定这些返回的JSON的格式规范告诉LangChain我希望它解析什么。

141
00:14:46,480 --> 00:14:50,340
在JSON格式规范中代表“礼物”的名称是"gift"，这是它的描述。

142
00:14:50,340 --> 00:14:52,420
这个物品是为别人购买礼物吗？

143
00:14:52,420 --> 00:14:56,540
嗯，回答是或者对，否则回答不是或者未知等等。

144
00:14:56,540 --> 00:15:05,820
所以有一个礼物规范、送货日期规范、价格值规范，然后像这样把它们都放到一个列表里。

145
00:15:05,820 --> 00:15:20,380
现在我已经为这些指定了规范，呃，LangChain实际上可以通过让output_parser告诉你它希望你发送给LLM的指令来给你提示。

146
00:15:20,380 --> 00:15:34,980
所以如果我要打印格式指令，它对LLM有一套相当精确的指令，可以让LLM生成指定的内容格式以便解析器可以解析。

147
00:15:34,980 --> 00:15:44,056
所以这是新的review_template，review_template包括LangChain生成的格式指令，

148
00:15:44,057 --> 00:15:58,700
这样它就可以从review_template中创建提示，然后创建传递给OpenAI API的消息。

149
00:15:58,700 --> 00:16:16,180
如果你愿意，你可以看一下实际的提示，它会给你提取礼物、送货天数、价格值等字段的指令，这是文本，然后这是格式指令。

150
00:16:16,180 --> 00:16:30,260
最后，如果我们调用OpenAI API，让我们看看会得到什么返回结果。

151
00:16:30,260 --> 00:16:41,586
现在是这样的，现在如果我们使用之前创建的output_parser，

152
00:16:41,600 --> 00:16:48,843
你就可以把这个解析成一个output_dict，如果我打印出来就是这样的，

153
00:16:48,844 --> 00:16:56,586
注意到这是字典类型，而不是字符串，

154
00:16:56,587 --> 00:17:09,020
这就是为什么我现在可以提取与“礼物”关联的值并得到"True"，或者与“送货天数”关联的值并得到"2"，

155
00:17:09,020 --> 00:17:14,760
或者你还可以提取与“价格值”关联的值。

156
00:17:14,760 --> 00:17:24,800
这是一种将LLM输出解析为Python字典的巧妙方法，使输出更易于在后续处理中使用。

157
00:17:24,800 --> 00:17:29,200
我建议你暂停视频并运行代码。

158
00:17:29,200 --> 00:17:32,780
关于模型、提示和解析器就是这些了。

159
00:17:32,780 --> 00:17:37,960
有了这些工具，希望你能更轻松地重用自己的提示模板，

160
00:17:37,960 --> 00:17:42,280
与合作伙伴共享提示模板，甚至使用LangChain的内置

161
00:17:42,280 --> 00:17:51,975
提示模板，正如你刚刚看到的，通常可以与输出解析器配合使用，以便输入提示以特定格式输出

162
00:17:51,976 --> 00:18:02,280
然后解析器解析输出，将数据存储在Python字典或其他数据结构中，以便用于后续处理的。

163
00:18:02,280 --> 00:18:06,400
希望这些知识能对你有用，帮助你应用在自己的应用开发中。

164
00:18:06,400 --> 00:18:08,300
说到这里，我们接下来将继续下一个视频

165
00:18:08,301 --> 00:18:16,557
在那里我们将学习LangChain如何帮助你构建更好的聊天机器人，

166
00:18:16,558 --> 00:18:21,240
让LLM通过更好地管理历史对话，达到更好的聊天效果。
