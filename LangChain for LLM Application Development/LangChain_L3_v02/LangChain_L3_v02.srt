1
00:00:05,000 --> 00:00:11,960
In this lesson, Harrison will teach the most important key building block of LangChain, namely the chain.

2
00:00:11,960 --> 00:00:17,440
The chain usually combines an LLM, large language model, together with a prompt.

3
00:00:17,440 --> 00:00:26,560
And with this building block, you can also put a bunch of these building blocks together to carry out a sequence of operations on your text or on your other data.

4
00:00:26,560 --> 00:00:28,400
I'm excited to dive into it.

5
00:00:29,000 --> 00:00:33,680
All right, to start, we're going to load the environment variables as we have before.

6
00:00:33,680 --> 00:00:37,360
And then we're also going to load some data that we're going to use.

7
00:00:37,360 --> 00:00:44,440
So part of the power of these chains is that you can run them over many inputs at a time.

8
00:00:44,440 --> 00:00:46,720
Here, we're going to load a Pandas DataFrame.

9
00:00:46,720 --> 00:00:52,520
A Pandas DataFrame is just a data structure that contains a bunch of different elements of data.

10
00:00:52,520 --> 00:00:54,600
If you're not familiar with Pandas, don't worry about it.

11
00:00:54,600 --> 00:00:58,720
The main point here is that we're loading some data that we can then use later on.

12
00:00:58,760 --> 00:01:04,400
And so if we look inside this Pandas DataFrame, we can see that there is a product column and then a review column.

13
00:01:04,400 --> 00:01:08,680
And each of these rows is a different data point that we can start passing through our chains.

14
00:01:08,680 --> 00:01:12,280
So the first chain we're going to cover is the LLMChain.

15
00:01:12,280 --> 00:01:18,400
And this is a simple but really powerful chain that underpins a lot of the chains that we'll go over in the future.

16
00:01:18,400 --> 00:01:21,360
And so we're going to import three different things.

17
00:01:21,360 --> 00:01:25,080
We're going to import the OpenAI model, so the LLM.

18
00:01:25,080 --> 00:01:27,560
We're going to import the ChatPromptTemplate.

20
00:01:28,640 --> 00:01:30,160
And then we're going to import the LLMChain.

21
00:01:30,160 --> 00:01:36,240
And so first, what we're going to do is we're going to initialize the language model that we want to use.

22
00:01:36,240 --> 00:01:44,120
So we're going to initialize the ChatOpenAI with a high temperature so that we can get some fun descriptions.

23
00:01:44,120 --> 00:01:49,160
Now we're going to initialize a prompt, and this prompt is going to take in a variable called product.

24
00:01:49,160 --> 00:01:54,880
It's going to ask the LLM to generate what the best name is to describe a company that makes that product.

25
00:01:55,720 --> 00:01:59,280
And then finally, we're going to combine these two things into a chain.

26
00:01:59,280 --> 00:02:03,000
And so this is what we call an LLMChain, and it's quite simple.

27
00:02:03,000 --> 00:02:06,280
It's just the combination of the LLM and the prompt.

28
00:02:06,280 --> 00:02:11,560
But now this chain will let us run through the prompt and into the LLM in a sequential manner.

29
00:02:11,560 --> 00:02:17,960
And so if we have a product called "Queen Size Sheet Set", we can run this through the chain by using "chain.run".

30
00:02:17,960 --> 00:02:24,200
And what    will do is it will format the prompt under the hood, and then it will pass the whole prompt into the LLM.

31
00:02:24,600 --> 00:02:29,520
And so we can see that we get back the name of this hypothetical company called "Royal Beddings".

32
00:02:29,520 --> 00:02:37,400
so here would be a good time to pause, and you can input any product descriptions that you would want, and you can see what the chain will output as a result.

33
00:02:37,400 --> 00:02:43,840
So the LLMChain is the most basic type of chain, and that's going to be used a lot in the future.

34
00:02:43,840 --> 00:02:48,600
And so we can see how this will be used in the next type of chain, which will be "Sequential Chains".

35
00:02:48,600 --> 00:02:52,720
And so Sequential Chains run a sequence of chains one after another.

36
00:02:53,200 --> 00:02:57,040
So to start, you're going to import the SimpleSequentialChain.

37
00:02:57,040 --> 00:03:02,200
And this works well when we have sub chains that expect only one input and return only one output.

38
00:03:02,200 --> 00:03:08,360
And so here we're going to first create one chain, which uses an LLM and a prompt.

39
00:03:08,360 --> 00:03:14,840
And this prompt is going to take in the product and will return the best name to describe that company.

40
00:03:14,840 --> 00:03:16,240
So that will be the first chain.

41
00:03:16,240 --> 00:03:19,280
Then we're going to create a second chain.

42
00:03:19,760 --> 00:03:26,320
And the second chain will take in the company name and then output a 20 word description of that company.

43
00:03:26,320 --> 00:03:31,000
And so you can imagine how these chains might want to be run one after another,

44
00:03:31,000 --> 00:03:35,320
where the output of the first chain, the company name is then passed into the second chain.

45
00:03:35,320 --> 00:03:42,680
We can easily do this by creating a SimpleSequentialChain where we have the two chains described there.

46
00:03:42,680 --> 00:03:45,320
And we'll call this overall_simple_chain.

47
00:03:47,240 --> 00:03:52,240
Now, what you can do is run this chain over any product description.

48
00:03:52,240 --> 00:03:57,114
And so if we use it with the product above the "Queen Size Sheet Set",

49
00:03:57,115 --> 00:04:00,557
we can run it over and we can see that at first outputs "Royal Bedding",

50
00:04:00,558 --> 00:04:06,280
and then it passes it into the second chain and it comes up with this description of what that company could be about.

51
00:04:06,280 --> 00:04:12,840
The simple sequential chain(SimpleSequentialChain) works well when there's only a single input and a single output.

52
00:04:12,840 --> 00:04:16,680
But what about when there are multiple inputs or multiple outputs?

53
00:04:16,920 --> 00:04:20,080
And so we can do this by using just the regular SequentialChain.

54
00:04:20,080 --> 00:04:22,120
So let's import that.

55
00:04:22,120 --> 00:04:25,920
And then you're going to create a bunch of chains that we're going to use one after another.

56
00:04:25,920 --> 00:04:29,160
We're going to be using the data from above, which has a review.

57
00:04:29,160 --> 00:04:34,840
And so the first chain, we're going to take the review and translate it into English.

58
00:04:34,840 --> 00:04:41,840
With a second chain, we're going to create a summary of that review in one sentence.

59
00:04:41,840 --> 00:04:46,840
And this will use the previously generated English review.

60
00:04:47,360 --> 00:04:54,200
The third chain is going to detect what the language of the review was in the first place.

61
00:04:54,200 --> 00:05:00,280
And so if you notice, this is using the review variable that is coming from the original review.

62
00:05:00,280 --> 00:05:05,480
And finally, the fourth chain will take in multiple inputs.

63
00:05:05,480 --> 00:05:13,280
So this will take in the summary variable, which we calculated with the second chain and the language variable, which we calculated with the third chain.

64
00:05:13,760 --> 00:05:18,280
And it's going to ask for a follow up response to the summary in the specified language.

65
00:05:18,280 --> 00:05:25,960
One important thing to note about all these sub chains is that the input keys and output keys need to be pretty precise.

66
00:05:25,960 --> 00:05:28,520
So here we're taking in review.

67
00:05:28,520 --> 00:05:31,120
This is a variable that will be passed in at the start.

68
00:05:31,120 --> 00:05:35,320
We can see that we explicitly set the output key to English review.

69
00:05:35,320 --> 00:05:42,040
This is then used in the next prompt down below, where we take in English review with that same variable name.

70
00:05:42,800 --> 00:05:47,840
And we set the output key of that chain to summary, which we can see is used in the final chain.

71
00:05:47,840 --> 00:05:56,080
The third prompt takes in review, the original variable and output language, which is again used in the final prompt.

72
00:05:56,080 --> 00:06:00,760
It's really important to get these variable names lined up exactly right,

74
00:06:03,400 --> 00:06:07,200
And if you get any key errors, you should definitely check that they are lined up.

75
00:06:07,200 --> 00:06:14,680
So the Simple Sequential Chain takes in multiple chains, where each one has a single input and a single output.

76
00:06:14,680 --> 00:06:23,720
To see a visual representation of this, we can look at the slide where it has one chain feeding into the other chain, one after another.

77
00:06:23,720 --> 00:06:29,640
Here we can see a visual description of the sequential chain, comparing it to the above chain.

78
00:06:29,640 --> 00:06:34,360
You can notice that any step in the chain can take in multiple input variables.

79
00:06:34,960 --> 00:06:41,960
This is useful when you have more complicated downstream chains that need to be a composition of multiple previous chains.

80
00:06:41,960 --> 00:06:47,440
Now that we have all these chains, we can easily combine them in the SequentialChain.

81
00:06:47,440 --> 00:06:53,440
So you'll notice here that we'll pass in the four chains we created into the chains variable.

82
00:06:53,440 --> 00:06:58,440
We'll create the inputs variable with the one human input, which is the review.

83
00:06:58,440 --> 00:07:02,680
And then we want to return all of the intermediate outputs.

84
00:07:02,680 --> 00:07:05,520
So the English review, the summary, and then the follow-up message.

85
00:07:05,520 --> 00:07:10,480
Now we can run this over some of the data.

86
00:07:10,480 --> 00:07:15,280
So let's choose a review and pass it in through the overall chain.

87
00:07:15,280 --> 00:07:25,400
We can see here that the original review looks like it was in French.

88
00:07:25,400 --> 00:07:28,480
We can see the English review as a translation.

89
00:07:28,480 --> 00:07:35,080
We can see a summary of that review, and then we can see a follow-up message in the original language of French.

90
00:07:35,080 --> 00:07:39,120
You should pause the video here and try putting in different inputs.

91
00:07:39,120 --> 00:07:43,360
So far we've covered the LLMChain and then a Sequential Chain.

92
00:07:43,360 --> 00:07:46,440
But what if you want to do something more complicated?

93
00:07:46,440 --> 00:07:53,160
A pretty common but basic operation is to route an input to a chain, depending on what exactly that input is.

94
00:07:53,720 --> 00:08:03,000
A good way to imagine this is if you have multiple subchains, each of which specialized for a particular type of input, you could have a Router Chain,

95
00:08:03,000 --> 00:08:07,560
which first decides which subchain to pass it to, and then passes it to that chain.

96
00:08:07,560 --> 00:08:16,960
For a concrete example, let's look at where we are routing between different types of chains, depending on the subject that seems to come in.

97
00:08:16,960 --> 00:08:19,920
So we have here different prompts.

98
00:08:19,920 --> 00:08:22,760
One prompt is good for answering physics questions.

99
00:08:22,880 --> 00:08:28,560
The second prompt is good for answering math questions, the third for history, and then a fourth for computer science.

100
00:08:28,560 --> 00:08:31,160
Let's define all these prompt templates.

101
00:08:31,160 --> 00:08:39,040
After we have these prompt templates, we can then provide more information about them.

102
00:08:39,040 --> 00:08:42,320
We can give each one a name and then a description.

103
00:08:42,320 --> 00:08:46,640
This description for the physics one is good for answering questions about physics.

104
00:08:46,640 --> 00:08:54,080
This information is going to be passed to the router chain, so the router chain can decide when to use this subchain.

105
00:08:59,857 --> 00:09:02,840
Let's now import the other types of chains that we need.

106
00:09:02,840 --> 00:09:05,040
Here we need a MultiPromptChain.

107
00:09:05,040 --> 00:09:10,640
This is a specific type of chain that is used when routing between multiple different prompt templates.

108
00:09:10,640 --> 00:09:17,800
As you can see, all the options we have are prompt templates themselves, but this is just one type of thing that you can route between.

109
00:09:17,840 --> 00:09:20,240
You can route between any type of chain.

110
00:09:20,240 --> 00:09:24,120
The other classes that we'll import here are an LLMRouterChain.

111
00:09:24,120 --> 00:09:28,480
This uses a language model itself to route between the different subchains.

112
00:09:28,480 --> 00:09:32,040
This is where the description and the name provided above will be used.

113
00:09:32,040 --> 00:09:35,040
We'll also import a RouterOutputParser.

114
00:09:35,040 --> 00:09:44,240
This parses the LLM output into a dictionary that can be used downstream to determine which chain to use and what the input to that chain should be.

115
00:09:47,600 --> 00:09:49,040
Now we can get around to using it.

116
00:09:49,040 --> 00:09:53,720
First, let's import and define the language model that we will use.

117
00:09:53,720 --> 00:09:59,040
We now create the destination chains.

118
00:09:59,040 --> 00:10:01,880
These are the chains that will be called by the router chain.

119
00:10:01,880 --> 00:10:07,160
As you can see, each destination chain itself is a language model chain, an LLMChain.

120
00:10:07,160 --> 00:10:12,840
In addition to the destination chains, we also need a default chain.

121
00:10:12,840 --> 00:10:17,840
This is a chain that's called when the router can't decide which of the subchains to use.

122
00:10:17,840 --> 00:10:25,840
And the example above, this might be called when the input question has nothing to do with physics, math, history, or computer science.

123
00:10:25,840 --> 00:10:33,840
Now we define the template that is used by the LLM to route between the different chains.

124
00:10:33,840 --> 00:10:40,440
This has instructions of the task to be done, as well as the specific formatting that the output should be in.

125
00:10:40,440 --> 00:10:44,840
Let's put a few of these pieces together to build the router chain.

126
00:10:45,640 --> 00:10:50,480
First, we create the full router template by formatting it with the destinations that we defined above.

127
00:10:50,480 --> 00:10:54,320
This template is flexible to a bunch of different types of destinations.

128
00:10:54,320 --> 00:10:58,520
One thing you can do here is pause and add different types of destinations.

129
00:10:58,520 --> 00:11:05,000
So up here, rather than just physics, math, history, and computer science, you could add a different subject like English or Latin.

130
00:11:05,000 --> 00:11:14,240
Next, we create the prompt template from this template, and then we create the router chain by passing in the LLM and the overall router prompt.

131
00:11:15,080 --> 00:11:17,440
Note that here we have the RouterOutputParser.

132
00:11:17,440 --> 00:11:23,240
This is important as it will help this chain decide which subchains to route between.

133
00:11:25,557 --> 00:11:30,000
And finally, putting it all together, we can create the overall chain.

134
00:11:30,000 --> 00:11:33,520
This has a router chain, which is defined here.

135
00:11:33,520 --> 00:11:36,280
It has destination chains, which we pass in here.

136
00:11:36,280 --> 00:11:38,280
And then we also pass in the default chain.

137
00:11:38,280 --> 00:11:41,200
We can now use this chain.

138
00:11:41,200 --> 00:11:43,120
So let's ask it some questions.

139
00:11:43,760 --> 00:11:53,900
If we ask it a question about physics, we should hopefully see that it is routed to the physics chain with the input, "What is black body radiation?",

140
00:11:53,901 --> 00:11:56,680
and then that is passed into the chain down below.

141
00:11:56,680 --> 00:12:02,240
And we can see that the response is very detailed with lots of physics details.

142
00:12:02,240 --> 00:12:06,560
You should pause the video here and try putting in different inputs.

143
00:12:06,560 --> 00:12:12,040
You can try with all the other types of special chains that we have defined above.

144
00:12:12,640 --> 00:12:16,057
So for example, if we ask it a math question,

145
00:12:23,329 --> 00:12:27,160
we should see that it's routed to the math chain and then passed into that.

146
00:12:31,971 --> 00:12:37,560
We can also see what happens when we pass in a question that is not related to any of the subchains.

147
00:12:37,560 --> 00:12:43,160
So here we ask it a question about biology and we can see the chain that it chooses is "None".

148
00:12:43,160 --> 00:12:48,760
This means that it will be passed to the default chain, which itself is just a generic call to the language model.

149
00:12:48,760 --> 00:12:52,360
The language model luckily knows a lot about biology, so it can help us out here.

150
00:12:52,360 --> 00:13:00,200
Now that we've covered these basic building blocks types of chains, we can start to put them together to create really interesting applications.

151
00:13:00,200 --> 00:13:06,400
For example, in the next section, we're going to cover how to create a chain that can do question answering over your documents.
