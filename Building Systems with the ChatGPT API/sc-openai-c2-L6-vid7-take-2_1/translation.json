{
  "chunks": [
    {
      "items": [
        {
          "id": "1",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 5,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 10,
            "milliseconds": 200
          },
          "text": "In this video, we'll focus on checking outputs generated by the system."
        },
        {
          "id": "2",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 10,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 14,
            "milliseconds": 600
          },
          "text": "Checking outputs before showing them to users can be important for ensuring the quality,"
        },
        {
          "id": "3",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 14,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 19,
            "milliseconds": 360
          },
          "text": "relevance and safety of the responses provided to them or used in automation flows."
        },
        {
          "id": "4",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 19,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 23,
            "milliseconds": 112
          },
          "text": "We'll learn how to use the moderation API, but this time for outputs,"
        },
        {
          "id": "5",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 23,
            "milliseconds": 113
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 28,
            "milliseconds": 760
          },
          "text": "and how to use additional prompts to the model to evaluate output quality before displaying them."
        },
        {
          "id": "6",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 28,
            "milliseconds": 760
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 31,
            "milliseconds": 0
          },
          "text": "So let's dive into the examples."
        },
        {
          "id": "7",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 31,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 35,
            "milliseconds": 520
          },
          "text": "We've already discussed the moderation API in the context of evaluating inputs."
        },
        {
          "id": "8",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 35,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 39,
            "milliseconds": 880
          },
          "text": "Now let's revisit it in the context of checking outputs."
        },
        {
          "id": "9",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 39,
            "milliseconds": 880
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 45,
            "milliseconds": 360
          },
          "text": "Moderation API can also be used to filter and moderate outputs generated by the system itself."
        },
        {
          "id": "10",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 45,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 47,
            "milliseconds": 800
          },
          "text": "And so here's an example."
        }
      ],
      "source": [
        "In this video, we'll focus on checking outputs generated by the system.",
        "Checking outputs before showing them to users can be important for ensuring the quality,",
        "relevance and safety of the responses provided to them or used in automation flows.",
        "We'll learn how to use the moderation API, but this time for outputs,",
        "and how to use additional prompts to the model to evaluate output quality before displaying them.",
        "So let's dive into the examples.",
        "We've already discussed the moderation API in the context of evaluating inputs.",
        "Now let's revisit it in the context of checking outputs.",
        "Moderation API can also be used to filter and moderate outputs generated by the system itself.",
        "And so here's an example."
      ],
      "result": [
        "在这个视频中，我们将重点关注检查系统生成的输出。",
        "在向用户展示之前检查输出结果，对于确保",
        "提供给用户或在自动化流程中使用的内容的质量、相关性和安全性是很重要的。",
        "我们将学习如何使用审查API，但这次是针对输出内容，",
        "以及如何在显示之前使用额外的Prompt，让模型评估输出质量。",
        "让我们深入了解这些示例。",
        "之前我们讨论审查API的背景是检查输入内容。",
        "现在让我们在检查输出的背景下重新审视它。",
        "审查API还可以用于过滤和审查系统生成的内容。",
        "所以这里有一个例子。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "11",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 47,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 54,
            "milliseconds": 480
          },
          "text": "So here's a generated response to the user."
        },
        {
          "id": "12",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 54,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 2,
            "milliseconds": 160
          },
          "text": "And we're going to use the moderation API in the same way that we saw in the earlier video."
        },
        {
          "id": "13",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 2,
            "milliseconds": 160
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 5,
            "milliseconds": 0
          },
          "text": "So let's see if this output is flagged."
        },
        {
          "id": "14",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 5,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 12,
            "milliseconds": 520
          },
          "text": "And as you can see, this output is not flagged and has very low scores in all categories,"
        },
        {
          "id": "15",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 12,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 16,
            "milliseconds": 480
          },
          "text": "which makes sense given the response."
        },
        {
          "id": "16",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 16,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 19,
            "milliseconds": 840
          },
          "text": "In general, it can also be important to check the outputs."
        },
        {
          "id": "17",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 19,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 28,
            "milliseconds": 200
          },
          "text": "For example, if you were creating a chatbot for sensitive audiences, you could use lower thresholds for flagging outputs."
        },
        {
          "id": "18",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 28,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 31,
            "milliseconds": 554
          },
          "text": "In general, if the moderation output indicates that the content is flagged,"
        },
        {
          "id": "19",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 31,
            "milliseconds": 555
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 40,
            "milliseconds": 200
          },
          "text": "you can take appropriate action such as responding with a fallback answer or generating a new response."
        },
        {
          "id": "20",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 40,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 48,
            "milliseconds": 420
          },
          "text": "Note that as we improve the models, they also are becoming less and less likely to return some kind of harmful output."
        }
      ],
      "source": [
        "So here's a generated response to the user.",
        "And we're going to use the moderation API in the same way that we saw in the earlier video.",
        "So let's see if this output is flagged.",
        "And as you can see, this output is not flagged and has very low scores in all categories,",
        "which makes sense given the response.",
        "In general, it can also be important to check the outputs.",
        "For example, if you were creating a chatbot for sensitive audiences, you could use lower thresholds for flagging outputs.",
        "In general, if the moderation output indicates that the content is flagged,",
        "you can take appropriate action such as responding with a fallback answer or generating a new response.",
        "Note that as we improve the models, they also are becoming less and less likely to return some kind of harmful output."
      ],
      "result": [
        "这里有一个生成给用户的输出内容。",
        "使用审查API的方法跟之前视频介绍的方法一样。",
        "让我们看看这个输出是否被标记。",
        "正如您所看到的，这个输出没有被标记，并且在所有类别中得分都很低，",
        "这对于给定的回应是有道理的。",
        "通常，检查输出也很重要。",
        "例如，如果您为敏感受众创建聊天机器人，您可以使用较低的阈值来标记输出。",
        "总的来说，如果审查输出内容后，表明内容被标记，",
        "您可以采取适当的行动，比如返回一个备用答案，或重新生成一个新的结果。",
        "请注意，随着模型的改进，返回某种有害内容的概率会越来越低。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "21",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 48,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 51,
            "milliseconds": 171
          },
          "text": "Another approach for checking outputs is to ask the model itself"
        },
        {
          "id": "22",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 51,
            "milliseconds": 172
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 56,
            "milliseconds": 739
          },
          "text": "if the generated was satisfactory and if it follows a certain rubric that you define."
        },
        {
          "id": "23",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 56,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 0,
            "milliseconds": 496
          },
          "text": "This can be done by providing the generated output as part of the input to the model"
        },
        {
          "id": "24",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 0,
            "milliseconds": 497
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 5,
            "milliseconds": 320
          },
          "text": "and asking it to rate the quality of the output."
        },
        {
          "id": "25",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 5,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 7,
            "milliseconds": 80
          },
          "text": "You can do this in various different ways."
        },
        {
          "id": "26",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 7,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 9,
            "milliseconds": 960
          },
          "text": "So let's see an example."
        },
        {
          "id": "27",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 9,
            "milliseconds": 960
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 11,
            "milliseconds": 326
          },
          "text": "So our system message is,"
        },
        {
          "id": "28",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 11,
            "milliseconds": 327
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 16,
            "milliseconds": 446
          },
          "text": "you are an assistant  evaluates whether customer service agent responses sufficiently answer customer questions"
        },
        {
          "id": "29",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 16,
            "milliseconds": 447
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 25,
            "milliseconds": 260
          },
          "text": "and also validates that all the facts the assistant cites from the product information are correct."
        },
        {
          "id": "30",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 25,
            "milliseconds": 260
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 33,
            "milliseconds": 520
          },
          "text": "The product information and user and customer service agent messages will be delimited by three backticks."
        }
      ],
      "source": [
        "Another approach for checking outputs is to ask the model itself",
        "if the generated was satisfactory and if it follows a certain rubric that you define.",
        "This can be done by providing the generated output as part of the input to the model",
        "and asking it to rate the quality of the output.",
        "You can do this in various different ways.",
        "So let's see an example.",
        "So our system message is,",
        "you are an assistant  evaluates whether customer service agent responses sufficiently answer customer questions",
        "and also validates that all the facts the assistant cites from the product information are correct.",
        "The product information and user and customer service agent messages will be delimited by three backticks."
      ],
      "result": [
        "另一种检查输出的方法是直接询问模型自己",
        "对生成的是否令人满意，是否符合您定义的某种标准。",
        "实现的方式是：将模型输出的内容配合适当的Prompt提交给模型来评估，",
        "要求模型评估输出的质量。",
        "您可以用各种不同的方式来实现这一点。",
        "让我们看一个例子。",
        "我们的系统消息是：",
        "“您是一个助手，评估客户服务代表的回答是否充分解答了客户的问题",
        "并验证助手引用的所有产品信息中的事实是否正确。",
        "产品信息以及用户和客户服务代表的消息将由三个反引号进行分割。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "31",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 33,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 37,
            "milliseconds": 420
          },
          "text": "Respond with a Y or N character with no punctuation."
        },
        {
          "id": "32",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 37,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 44,
            "milliseconds": 600
          },
          "text": "Y if the output sufficiently answers the question and the response correctly uses product information and no otherwise."
        },
        {
          "id": "33",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 44,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 47,
            "milliseconds": 80
          },
          "text": "Output a single letter only."
        },
        {
          "id": "34",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 47,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 52,
            "milliseconds": 180
          },
          "text": "And you could also use a chain of thought reasoning prompt for this."
        },
        {
          "id": "35",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 52,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 55,
            "milliseconds": 200
          },
          "text": "This might be a little bit difficult for the model to validate both in one step."
        },
        {
          "id": "36",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 55,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 56,
            "milliseconds": 800
          },
          "text": "So you could play around with this."
        },
        {
          "id": "37",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 56,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 59,
            "milliseconds": 240
          },
          "text": "You could also add some other kind of guidelines."
        },
        {
          "id": "38",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 59,
            "milliseconds": 240
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 5,
            "milliseconds": 460
          },
          "text": "You could ask, give a rubric like a rubric for an exam or grading an essay."
        },
        {
          "id": "39",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 5,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 7,
            "milliseconds": 179
          },
          "text": "You could use that kind of format and say,"
        },
        {
          "id": "40",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 7,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 10,
            "milliseconds": 276
          },
          "text": "does this use a friendly tone in line with our brand guidelines"
        },
        {
          "id": "41",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 10,
            "milliseconds": 277
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 15,
            "milliseconds": 560
          },
          "text": "and maybe outline some of your brand guidelines if that's something that's very important to you."
        }
      ],
      "source": [
        "Respond with a Y or N character with no punctuation.",
        "Y if the output sufficiently answers the question and the response correctly uses product information and no otherwise.",
        "I'll put a single letter only.",
        "And you could also use a chain of thought reasoning prompt for this.",
        "This might be a little bit difficult for the model to validate both in one step.",
        "So you could play around with this.",
        "You could also add some other kind of guidelines.",
        "You could ask, give a rubric like a rubric for an exam or grading an essay.",
        "You could use that kind of format and say,",
        "does this use a friendly tone in line with our brand guidelines",
        "and maybe outline some of your brand guidelines if that's something that's very important to you."
      ],
      "result": [
        "请用Y或N字符回答，不要加标点符号。",
        "如果输出充分回答了问题，并且回应正确使用了产品信息，则为Y，否则为N。",
        "仅输出一个字母。”",
        "你还可以为此使用一种思维链推理Prompt。",
        "对于模型来说，一步验证这两个可能有点困难。",
        "你可以试着玩玩这个。",
        "你还可以添加其他类型的指南。",
        "你可以问，给一个类似于考试或评分论文的评分标准。",
        "你可以使用这种格式说：",
        "“这是否使用了符合我们品牌指南的友好语气？”",
        "如果这对你来说非常重要，也许可以概述一下你的品牌指南。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "42",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 15,
            "milliseconds": 560
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 17,
            "milliseconds": 400
          },
          "text": "So let's add our customer message."
        },
        {
          "id": "43",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 17,
            "milliseconds": 400
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 21,
            "milliseconds": 720
          },
          "text": "So this is the initial message used to generate this response."
        },
        {
          "id": "44",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 21,
            "milliseconds": 720
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 24,
            "milliseconds": 680
          },
          "text": "And then let's also paste in our product information."
        },
        {
          "id": "45",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 24,
            "milliseconds": 681
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 31,
            "milliseconds": 37
          },
          "text": "And so this is the product information we fetched in the previous step for all of the products mentioned in this message."
        },
        {
          "id": "46",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 33,
            "milliseconds": 960
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 37,
            "milliseconds": 800
          },
          "text": "And now we'll define our comparison."
        },
        {
          "id": "47",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 37,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 44,
            "milliseconds": 519
          },
          "text": "So the customer message is the customer message, the product information, and then the agent response,"
        },
        {
          "id": "48",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 45,
            "milliseconds": 377
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 51,
            "milliseconds": 840
          },
          "text": "which is the response to the customer that we have from this previous cell."
        },
        {
          "id": "49",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 51,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 59,
            "milliseconds": 320
          },
          "text": "So let's format this into a messages list and get the response from the model."
        },
        {
          "id": "50",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 59,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 5,
            "milliseconds": 840
          },
          "text": "So the model says, yes, the product information is correct and the question is answered sufficiently."
        },
        {
          "id": "51",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 5,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 8,
            "milliseconds": 667
          },
          "text": "Well, in general, for these kind of evaluation tasks,"
        },
        {
          "id": "52",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 8,
            "milliseconds": 668
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 15,
            "milliseconds": 120
          },
          "text": "I also think it is better to use a more advanced model because they're just better at reasoning."
        }
      ],
      "source": [
        "So let's add our customer message.",
        "So this is the initial message used to generate this response.",
        "And then let's also paste in our product information.",
        "And so this is the product information we fetched in the previous step for all of the products mentioned in this message.",
        "And now we'll define our comparison.",
        "So the customer message is the customer message, the product information, and then the agent response,",
        "which is the response to the customer that we have from this previous cell.",
        "So let's format this into a messages list and get the response from the model.",
        "So the model says, yes, the product information is correct and the question is answered sufficiently.",
        "Well, in general, for these kind of evaluation tasks,",
        "I also think it is better to use a more advanced model because they're just better at reasoning."
      ],
      "result": [
        "接下来让我们添加客户留言。",
        "这是用来生成这条回复的初始留言。",
        "然后让我们粘贴产品信息。",
        "这是我们在之前为了生成这条留言，获取的所有产品的产品信息。",
        "现在我们来定义对比。",
        "\"Customer Message\"是客户留言，产品信息，然后是代理返回结果，",
        "这是我们从前面的单元格得到的对客户的返回结果。",
        "让我们把这个格式化成一个消息列表，看看从模型中得到什么样的结果。",
        "模型说：“是的”。产品信息是正确的，问题已经得到了充分的回答。",
        "嗯，总的来说，对于这类评估任务，",
        "我认为使用更高级的模型会更好，因为它们在推理方面更强大。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "53",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 15,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 16,
            "milliseconds": 773
          },
          "text": "So something like GPT-4."
        },
        {
          "id": "54",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 20,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 23,
            "milliseconds": 700
          },
          "text": "Let's try another example."
        },
        {
          "id": "55",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 23,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 28,
            "milliseconds": 0
          },
          "text": "So this response is, life is like a box of chocolates."
        },
        {
          "id": "56",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 28,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 31,
            "milliseconds": 643
          },
          "text": "So let's add our message to do with the output checking."
        },
        {
          "id": "57",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 36,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 44,
            "milliseconds": 40
          },
          "text": "And the model has determined that this does not sufficiently answer the question or use the retrieved information."
        },
        {
          "id": "58",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 44,
            "milliseconds": 40
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 47,
            "milliseconds": 0
          },
          "text": "This question, does it use the retrieved information correctly?"
        },
        {
          "id": "59",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 47,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 54,
            "milliseconds": 600
          },
          "text": "This is a good prompt to use if you want to make sure that the model isn't hallucinating,"
        },
        {
          "id": "60",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 54,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 0,
            "milliseconds": 40
          },
          "text": "which is making up things that aren't true."
        },
        {
          "id": "61",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 0,
            "milliseconds": 40
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 6,
            "milliseconds": 80
          },
          "text": "And feel free to pause the video now and try some of your own customer messages, responses,"
        },
        {
          "id": "62",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 6,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 11,
            "milliseconds": 920
          },
          "text": "and adding product information to test how this works."
        }
      ],
      "source": [
        "So something like GPT-4.",
        "Let's try another example.",
        "So this response is, life is like a box of chocolates.",
        "So let's add our message to do with the output checking.",
        "And the model has determined that this does not sufficiently answer the question or use the retrieved information.",
        "This question, does it use the retrieved information correctly?",
        "This is a good prompt to use if you want to make sure that the model isn't hallucinating,",
        "which is making up things that aren't true.",
        "And feel free to pause the video now and try some of your own customer messages, responses,",
        "and adding product information to test how this works."
      ],
      "result": [
        "比如说GPT-4。",
        "我们再试一个例子。",
        "这个回答是：“生活就像一盒巧克力。”",
        "让我们把信息加入到输出检查中。",
        "模型已经判断出这个回答没有充分回答问题，或者没有使用检索到的信息。",
        "“这个问题，它是否正确使用了检索到的信息？”",
        "如果你想确保模型没有产生幻觉（Hallucination），这是一个好的Prompt，",
        "幻觉是指编造一些不真实的事情。",
        "现在可以随意暂停视频，尝试一些你自己的客户留言、回复，",
        "并添加产品信息以测试这个功能是如何工作的。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "63",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 11,
            "milliseconds": 920
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 16,
            "milliseconds": 0
          },
          "text": "So as you can see, the model can provide feedback on the quality of a generated output."
        },
        {
          "id": "64",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 16,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 21,
            "milliseconds": 240
          },
          "text": "And you can use this feedback to decide whether to present the output to the user or to generate a new response."
        },
        {
          "id": "65",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 21,
            "milliseconds": 241
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 24,
            "milliseconds": 798
          },
          "text": "You could even experiment with generating multiple model responses per user query,"
        },
        {
          "id": "66",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 24,
            "milliseconds": 799
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 28,
            "milliseconds": 40
          },
          "text": "and then having the model choose the best one to show the user."
        },
        {
          "id": "67",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 28,
            "milliseconds": 40
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 30,
            "milliseconds": 40
          },
          "text": "So there's lots of different things you could try."
        },
        {
          "id": "68",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 30,
            "milliseconds": 40
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 33,
            "milliseconds": 940
          },
          "text": "In general, checking outputs using the moderation API is good practice."
        },
        {
          "id": "69",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 33,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 39,
            "milliseconds": 0
          },
          "text": "But while asking the model to evaluate its own output might be useful for immediate feedback"
        },
        {
          "id": "70",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 39,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 43,
            "milliseconds": 633
          },
          "text": "to ensure the quality of responses in a very small number of cases,"
        },
        {
          "id": "71",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 43,
            "milliseconds": 634
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 50,
            "milliseconds": 360
          },
          "text": "I think it's probably unnecessary most of the time, especially if you're using a more advanced model like GPT-4."
        },
        {
          "id": "72",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 50,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 53,
            "milliseconds": 760
          },
          "text": "I haven't actually seen many people do something like this in production."
        }
      ],
      "source": [
        "So as you can see, the model can provide feedback on the quality of a generated output.",
        "And you can use this feedback to decide whether to present the output to the user or to generate a new response.",
        "You could even experiment with generating multiple model responses per user query,",
        "and then having the model choose the best one to show the user.",
        "So there's lots of different things you could try.",
        "In general, checking outputs using the moderation API is good practice.",
        "But while asking the model to evaluate its own output might be useful for immediate feedback",
        "to ensure the quality of responses in a very small number of cases,",
        "I think it's probably unnecessary most of the time, especially if you're using a more advanced model like GPT-4.",
        "I haven't actually seen many people do something like this in production."
      ],
      "result": [
        "如您所见，模型可以对生成输出的质量提供反馈。",
        "您可以根据这个反馈来决定是将输出展示给用户还是生成新的内容。",
        "您甚至可以尝试针对每个用户查询生成多个模型的结果，",
        "然后让模型选择最佳的一个展示给用户。",
        "有很多不同的事情可以尝试。",
        "总的来说，使用审核 API 检查输出是个好习惯。",
        "但是，虽然让模型评估自己的输出对于即时反馈可能有用，",
        "以确保在极少数情况下返回结果的质量，",
        "但我认为大多数时候这可能是不必要的，特别是如果您使用的是更先进的模型，如 GPT-4。",
        "实际上，我还没有看到多少人在正式产品中这样做。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "73",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 53,
            "milliseconds": 760
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 56,
            "milliseconds": 432
          },
          "text": "It would also increase the latency and cost of your system,"
        },
        {
          "id": "74",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 57,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 59,
            "milliseconds": 639
          },
          "text": "because you'd have to wait for an additional call for the model."
        },
        {
          "id": "75",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 59,
            "milliseconds": 640
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 0,
            "milliseconds": 960
          },
          "text": "And that's also additional tokens."
        },
        {
          "id": "76",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 0,
            "milliseconds": 960
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 7,
            "milliseconds": 990
          },
          "text": "If it's really important for your App product that your error rate is 0.0000001%,"
        },
        {
          "id": "77",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 7,
            "milliseconds": 991
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 9,
            "milliseconds": 840
          },
          "text": "then maybe you should try this approach."
        },
        {
          "id": "78",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 9,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 13,
            "milliseconds": 760
          },
          "text": "But overall, I wouldn't really recommend that you do this in practice."
        },
        {
          "id": "79",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 13,
            "milliseconds": 760
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 14,
            "milliseconds": 247
          },
          "text": "In the next video,"
        },
        {
          "id": "80",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 14,
            "milliseconds": 248
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 21,
            "milliseconds": 960
          },
          "text": "we're going to put together everything we've learned in the evaluate input section, process section, and checking output section to build an end-to-end system."
        }
      ],
      "source": [
        "It would also increase the latency and cost of your system,",
        "because you'd have to wait for an additional call for the model.",
        "And that's also additional tokens.",
        "If it's really important for your App product that your error rate is 0.0000001%,",
        "then maybe you should try this approach.",
        "But overall, I wouldn't really recommend that you do this in practice.",
        "In the next video,",
        "we're going to put together everything we've learned in the evaluate input section, process section, and checking output section to build an end-to-end system."
      ],
      "result": [
        "这也会增加系统的延迟和成本，",
        "因为您必须等待模型的额外调用。",
        "这也要消耗额外的Token。",
        "如果对于您的应用产品来说，错误率低于0.0000001%非常重要，",
        "那么您可以尝试这种方法。",
        "但总的来说，我并不建议您在实践中这样做。",
        "在下一个视频中，",
        "我们将整合在评估输入部分、处理部分和检查输出部分所学到的所有内容，来构建一个端到端的系统。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    }
  ],
  "sourcePath": "input/Building Systems with the ChatGPT API/sc-openai-c2-L6-vid7-take-2_1.srt",
  "ouputBasePath": "input/Building Systems with the ChatGPT API/sc-openai-c2-L6-vid7-take-2_1",
  "totalCost": 0.15686999999999998,
  "translationPath": "input/Building Systems with the ChatGPT API/sc-openai-c2-L6-vid7-take-2_1/translation.json"
}
