1
00:00:05,000 --> 00:00:10,200
在这个视频中，我们将重点关注检查系统生成的输出。
In this video, we'll focus on checking outputs generated by the system.

2
00:00:10,200 --> 00:00:14,600
在向用户展示之前检查输出结果，对于确保
Checking outputs before showing them to users can be important for ensuring the quality,

3
00:00:14,600 --> 00:00:19,360
提供给用户或在自动化流程中使用的内容的质量、相关性和安全性是很重要的。
relevance and safety of the responses provided to them or used in automation flows.

4
00:00:19,360 --> 00:00:23,112
我们将学习如何使用审查API，但这次是针对输出内容，
We'll learn how to use the moderation API, but this time for outputs,

5
00:00:23,113 --> 00:00:28,760
以及如何在显示之前使用额外的提示（Prompt），让模型评估输出质量。
and how to use additional prompts to the model to evaluate output quality before displaying them.

6
00:00:28,760 --> 00:00:31,000
让我们深入了解这些示例。
So let's dive into the examples.

7
00:00:31,000 --> 00:00:35,520
之前我们讨论审查API的背景是检查输入内容。
We've already discussed the moderation API in the context of evaluating inputs.

8
00:00:35,520 --> 00:00:39,880
现在让我们在检查输出的背景下重新审视它。
Now let's revisit it in the context of checking outputs.

9
00:00:39,880 --> 00:00:45,360
审查API还可以用于过滤和审查系统生成的内容。
Moderation API can also be used to filter and moderate outputs generated by the system itself.

10
00:00:45,360 --> 00:00:47,800
所以这里有一个例子。
And so here's an example.

11
00:00:47,800 --> 00:00:54,480
这里有一个生成给用户的输出内容。
So here's a generated response to the user.

12
00:00:54,480 --> 00:01:02,160
使用审查API的方法跟之前视频介绍的方法一样。
And we're going to use the moderation API in the same way that we saw in the earlier video.

13
00:01:02,160 --> 00:01:05,000
让我们看看这个输出是否被标记。
So let's see if this output is flagged.

14
00:01:05,000 --> 00:01:12,520
正如您所看到的，这个输出没有被标记，并且在所有类别中得分都很低，
And as you can see, this output is not flagged and has very low scores in all categories,

15
00:01:12,520 --> 00:01:16,480
这对于给定的回应是有道理的。
which makes sense given the response.

16
00:01:16,480 --> 00:01:19,840
通常，检查输出也很重要。
In general, it can also be important to check the outputs.

17
00:01:19,840 --> 00:01:28,200
例如，如果您为敏感受众创建聊天机器人，您可以使用较低的阈值来标记输出。
For example, if you were creating a chatbot for sensitive audiences, you could use lower thresholds for flagging outputs.

18
00:01:28,200 --> 00:01:31,554
总的来说，如果审查输出内容后，表明内容被标记，
In general, if the moderation output indicates that the content is flagged,

19
00:01:31,555 --> 00:01:40,200
您可以采取适当的行动，比如返回一个备用答案，或重新生成一个新的结果。
you can take appropriate action such as responding with a fallback answer or generating a new response.

20
00:01:40,200 --> 00:01:48,420
请注意，随着模型的改进，返回某种有害内容的概率会越来越低。
Note that as we improve the models, they also are becoming less and less likely to return some kind of harmful output.

21
00:01:48,420 --> 00:01:51,171
另一种检查输出的方法是直接询问模型自己
Another approach for checking outputs is to ask the model itself

22
00:01:51,172 --> 00:01:56,739
对生成的是否令人满意，是否符合您定义的某种标准。
if the generated was satisfactory and if it follows a certain rubric that you define.

23
00:01:56,740 --> 00:02:00,496
实现的方式是：将模型输出的内容配合适当的提示（Prompt）提交给模型来评估，
This can be done by providing the generated output as part of the input to the model

24
00:02:00,497 --> 00:02:05,320
要求模型评估输出的质量。
and asking it to rate the quality of the output.

25
00:02:05,320 --> 00:02:07,080
您可以用各种不同的方式来实现这一点。
You can do this in various different ways.

26
00:02:07,080 --> 00:02:09,960
让我们看一个例子。
So let's see an example.

27
00:02:09,960 --> 00:02:11,326
我们的系统消息是：
So our system message is,

28
00:02:11,327 --> 00:02:16,446
“您是一个助手，评估客户服务代表的回答是否充分解答了客户的问题
you are an assistant  evaluates whether customer service agent responses sufficiently answer customer questions

29
00:02:16,447 --> 00:02:25,260
并验证助手引用的所有产品信息中的事实是否正确。
and also validates that all the facts the assistant cites from the product information are correct.

30
00:02:25,260 --> 00:02:33,520
产品信息以及用户和客户服务代表的消息将由三个反引号进行分割。
The product information and user and customer service agent messages will be delimited by three backticks.

31
00:02:33,520 --> 00:02:37,420
请用Y或N字符回答，不要加标点符号。
Respond with a Y or N character with no punctuation.

32
00:02:37,420 --> 00:02:44,600
如果输出充分回答了问题，并且回应正确使用了产品信息，则为Y，否则为N。
Y if the output sufficiently answers the question and the response correctly uses product information and no otherwise.

33
00:02:44,600 --> 00:02:47,080
仅输出一个字母。”
Output a single letter only.

34
00:02:47,080 --> 00:02:52,180
你还可以为此使用一种思维链推理提示。
And you could also use a chain of thought reasoning prompt for this.

35
00:02:52,180 --> 00:02:55,200
对于模型来说，一步验证这两个可能有点困难。
This might be a little bit difficult for the model to validate both in one step.

36
00:02:55,200 --> 00:02:56,800
你可以试着玩玩这个。
So you could play around with this.

37
00:02:56,800 --> 00:02:59,240
你还可以添加其他类型的指南。
You could also add some other kind of guidelines.

38
00:02:59,240 --> 00:03:05,460
你可以问，给一个类似于考试或评分论文的评分标准。
You could ask, give a rubric like a rubric for an exam or grading an essay.

39
00:03:05,460 --> 00:03:07,179
你可以使用这种格式说：
You could use that kind of format and say,

40
00:03:07,180 --> 00:03:10,276
“这是否使用了符合我们品牌指南的友好语气？”
does this use a friendly tone in line with our brand guidelines

41
00:03:10,277 --> 00:03:15,560
如果这对你来说非常重要，也许可以概述一下你的品牌指南。
and maybe outline some of your brand guidelines if that's something that's very important to you.

42
00:03:15,560 --> 00:03:17,400
接下来让我们添加客户留言。
So let's add our customer message.

43
00:03:17,400 --> 00:03:21,720
这是用来生成这条回复的初始留言。
So this is the initial message used to generate this response.

44
00:03:21,720 --> 00:03:24,680
然后让我们粘贴产品信息。
And then let's also paste in our product information.

45
00:03:24,681 --> 00:03:31,037
这是我们在之前为了生成这条留言，获取的所有产品的产品信息。
And so this is the product information we fetched in the previous step for all of the products mentioned in this message.

46
00:03:33,960 --> 00:03:37,800
现在我们来定义对比。
And now we'll define our comparison.

47
00:03:37,800 --> 00:03:44,519
"Customer Message"是客户留言，产品信息，然后是代理返回结果，
So the customer message is the customer message, the product information, and then the agent response,

48
00:03:45,377 --> 00:03:51,840
这是我们从前面的单元格得到的对客户的返回结果。
which is the response to the customer that we have from this previous cell.

49
00:03:51,840 --> 00:03:59,320
让我们把这个格式化成一个消息列表，看看从模型中得到什么样的结果。
So let's format this into a messages list and get the response from the model.

50
00:03:59,320 --> 00:04:05,840
模型说：“是的”。产品信息是正确的，问题已经得到了充分的回答。
So the model says, yes, the product information is correct and the question is answered sufficiently.

51
00:04:05,840 --> 00:04:08,667
嗯，总的来说，对于这类评估任务，
Well, in general, for these kind of evaluation tasks,

52
00:04:08,668 --> 00:04:15,120
我认为使用更高级的模型会更好，因为它们在推理方面更强大。
I also think it is better to use a more advanced model because they're just better at reasoning.

53
00:04:15,120 --> 00:04:16,773
比如说GPT-4。
So something like GPT-4.

54
00:04:20,200 --> 00:04:23,700
我们再试一个例子。
Let's try another example.

55
00:04:23,700 --> 00:04:28,000
这个回答是：“生活就像一盒巧克力。”
So this response is, life is like a box of chocolates.

56
00:04:28,000 --> 00:04:31,643
让我们把信息加入到输出检查中。
So let's add our message to do with the output checking.

57
00:04:36,280 --> 00:04:44,040
模型已经判断出这个回答没有充分回答问题，或者没有使用检索到的信息。
And the model has determined that this does not sufficiently answer the question or use the retrieved information.

58
00:04:44,040 --> 00:04:47,000
“这个问题，它是否正确使用了检索到的信息？”
This question, does it use the retrieved information correctly?

59
00:04:47,000 --> 00:04:54,600
如果你想确保模型没有产生幻觉（Hallucination），这是一个好的提示，
This is a good prompt to use if you want to make sure that the model isn't hallucinating,

60
00:04:54,600 --> 00:05:00,040
幻觉是指编造一些不真实的事情。
which is making up things that aren't true.

61
00:05:00,040 --> 00:05:06,080
现在可以随意暂停视频，尝试一些你自己的客户留言、回复，
And feel free to pause the video now and try some of your own customer messages, responses,

62
00:05:06,080 --> 00:05:11,920
并添加产品信息以测试这个功能是如何工作的。
and adding product information to test how this works.

63
00:05:11,920 --> 00:05:16,000
如您所见，模型可以对生成输出的质量提供反馈。
So as you can see, the model can provide feedback on the quality of a generated output.

64
00:05:16,000 --> 00:05:21,240
您可以根据这个反馈来决定是将输出展示给用户还是生成新的内容。
And you can use this feedback to decide whether to present the output to the user or to generate a new response.

65
00:05:21,241 --> 00:05:24,798
您甚至可以尝试针对每个用户查询生成多个模型的结果，
You could even experiment with generating multiple model responses per user query,

66
00:05:24,799 --> 00:05:28,040
然后让模型选择最佳的一个展示给用户。
and then having the model choose the best one to show the user.

67
00:05:28,040 --> 00:05:30,040
有很多不同的事情可以尝试。
So there's lots of different things you could try.

68
00:05:30,040 --> 00:05:33,940
总的来说，使用审核 API 检查输出是个好习惯。
In general, checking outputs using the moderation API is good practice.

69
00:05:33,940 --> 00:05:39,000
但是，虽然让模型评估自己的输出对于即时反馈可能有用，
But while asking the model to evaluate its own output might be useful for immediate feedback

70
00:05:39,000 --> 00:05:43,633
以确保在极少数情况下返回结果的质量，
to ensure the quality of responses in a very small number of cases,

71
00:05:43,634 --> 00:05:50,360
但我认为大多数时候这可能是不必要的，特别是如果您使用的是更先进的模型，如 GPT-4。
I think it's probably unnecessary most of the time, especially if you're using a more advanced model like GPT-4.

72
00:05:50,360 --> 00:05:53,760
实际上，我还没有看到多少人在正式产品中这样做。
I haven't actually seen many people do something like this in production.

73
00:05:53,760 --> 00:05:56,432
这也会增加系统的延迟和成本，
It would also increase the latency and cost of your system,

74
00:05:57,480 --> 00:05:59,639
因为您必须等待模型的额外调用。
because you'd have to wait for an additional call for the model.

75
00:05:59,640 --> 00:06:00,960
这也要消耗额外的Token。
And that's also additional tokens.

76
00:06:00,960 --> 00:06:07,990
如果对于您的应用产品来说，错误率低于0.0000001%非常重要，
If it's really important for your App product that your error rate is 0.0000001%,

77
00:06:07,991 --> 00:06:09,840
那么您可以尝试这种方法。
then maybe you should try this approach.

78
00:06:09,840 --> 00:06:13,760
但总的来说，我并不建议您在实践中这样做。
But overall, I wouldn't really recommend that you do this in practice.

79
00:06:13,760 --> 00:06:14,247
在下一个视频中，
In the next video,

80
00:06:14,248 --> 00:06:21,960
我们将整合在评估输入部分、处理部分和检查输出部分所学到的所有内容，来构建一个端到端的系统。
we're going to put together everything we've learned in the evaluate input section, process section, and checking output section to build an end-to-end system.
