1
00:00:04,000 --> 00:00:07,440
In this section, we'll focus on tasks to process inputs,

2
00:00:07,440 --> 00:00:11,000
i.e. the tasks that take the input and generate a useful output,

3
00:00:11,000 --> 00:00:13,880
often through a series of steps.

4
00:00:13,880 --> 00:00:17,320
It is sometimes important for the model to reason in detail about a problem

6
00:00:19,400 --> 00:00:22,320
And if you took our previous course: "ChartGPT Prompt Engineering for

7
00:00:22,320 --> 00:00:25,720
Developers", you will have seen a number of examples of this.

8
00:00:25,720 --> 00:00:29,400
Sometimes a model might make reasoning errors by rushing to an incorrect

9
00:00:29,400 --> 00:00:33,520
conclusion, so we can reframe the query to request a series of relevant

10
00:00:33,520 --> 00:00:37,640
reasoning steps before the model provides a final answer, so that it can think

11
00:00:37,640 --> 00:00:40,560
longer and more methodically about the problem.

12
00:00:40,560 --> 00:00:43,920
And in general, we call this strategy of asking the model to reason about

14
00:00:46,920 --> 00:00:50,560
For some applications, the reasoning process that a model uses to arrive at

16
00:00:54,040 --> 00:00:58,520
For example, in tutoring applications, we may want to encourage students to work

17
00:00:58,520 --> 00:01:01,680
on their own answers, but a model's reasoning process about the student's

18
00:01:01,680 --> 00:01:04,840
solution could reveal the answer to the student.

19
00:01:04,840 --> 00:01:08,280
Inner monologue is a tactic that can be used to mitigate this.

20
00:01:08,280 --> 00:01:11,960
And this is just a fancy way of saying, hiding the model's reasoning from the user.

21
00:01:11,960 --> 00:01:17,280
The idea of inner monologue is to instruct the model to put parts of the output

22
00:01:17,280 --> 00:01:22,440
that are meant to be hidden from the user into a structured format that makes passing them easy.

24
00:01:22,440 --> 00:01:27,680
Then, before presenting the output to the user, the output is passed and only part of the output is made visible.

26
00:01:28,680 --> 00:01:32,680
So remember the classification problem from a previous video, where we asked

27
00:01:32,680 --> 00:01:37,880
the model to classify a customer query into a primary and secondary category.

28
00:01:37,880 --> 00:01:41,760
And based on that classification, we might want to take different instructions.

29
00:01:41,760 --> 00:01:46,880
Imagine the customer query had been classified into the product information category.

31
00:01:46,880 --> 00:01:48,200
In the next instructions,

32
00:01:48,200 --> 00:01:51,600
we'll want to include information about the products we have available.

33
00:01:51,600 --> 00:01:55,200
And so, in this case, the classification would have been: "Primary,

35
00:01:58,920 --> 00:02:01,200
And so let's dive into an example starting from there.

36
00:02:01,200 --> 00:02:04,160
So let's start with our usual setup.

37
00:02:04,160 --> 00:02:13,040
So for this inner monologue example,

38
00:02:13,040 --> 00:02:17,240
we'll start with our same delimiters that we've been using.

39
00:02:17,240 --> 00:02:19,400
And now let's go through our system message.

40
00:02:22,960 --> 00:02:28,560
And so what we're doing here is asking the model to reason about the answer before coming to its conclusion.

42
00:02:28,560 --> 00:02:34,560
So the instruction is: "Follow these steps to answer the customer queries.

43
00:02:34,560 --> 00:02:39,280
The customer query will be delimited with four hashtags, our delimiter."

44
00:02:39,280 --> 00:02:42,080
So then we've split this up into steps.

45
00:02:42,080 --> 00:02:45,840
So the first step is to decide whether the user is asking a question

47
00:02:48,280 --> 00:02:49,640
And a product category doesn't count.

48
00:02:50,760 --> 00:02:54,640
Step two, so if the user is asking about specific products,

49
00:02:54,640 --> 00:02:57,440
identify whether the products are in the following list.

50
00:02:57,440 --> 00:03:00,400
And now we've included a list of available products.

51
00:03:00,400 --> 00:03:09,520
So here we have five available products that all varieties of laptops and these are all made up products.

53
00:03:09,520 --> 00:03:11,440
They were actually generated by GPT-4.

54
00:03:11,440 --> 00:03:19,440
In step three, if the message contains products in the list above,

55
00:03:19,440 --> 00:03:22,480
list any assumptions that the user is making in their message.

56
00:03:22,480 --> 00:03:27,320
For example, that laptop X is bigger than laptop Y or

57
00:03:27,320 --> 00:03:30,360
that laptop Z has a two year warranty, for example.

58
00:03:30,360 --> 00:03:36,280
Step four is if the user made any assumptions,

59
00:03:36,280 --> 00:03:39,840
figure out whether the assumption is true based on your product information.

60
00:03:39,840 --> 00:03:45,840
And step five is: "First, politely correct the customer's incorrect assumptions if applicable."

62
00:03:45,840 --> 00:03:49,280
Only mention or reference products in the list of five available products.

63
00:03:49,280 --> 00:03:51,880
As these are the only five products that the store sells.

64
00:03:51,880 --> 00:03:54,520
And answer the customer in a friendly tone.

65
00:03:54,520 --> 00:04:00,680
And these kind of very pedantic instructions are probably unnecessary for a more advanced language model like GPT-4.

67
00:04:00,680 --> 00:04:05,440
And then we'll ask the model to use the following format.

68
00:04:05,440 --> 00:04:08,880
So step one, delimiter, it's reasoning.

69
00:04:08,880 --> 00:04:12,080
Step two, delimiter, reasoning, and so on.

70
00:04:12,080 --> 00:04:18,280
And using the delimiters will mean that it will be easier for us later to get just this response to the customer.

72
00:04:18,280 --> 00:04:20,040
Kind of cut off everything before.

73
00:04:20,040 --> 00:04:25,800
So now let's try an example user message.

74
00:04:25,800 --> 00:04:34,840
So our message is: "by how much is the BlueWave Chromebook more expensive than the TechPro Desktop?"

76
00:04:34,840 --> 00:04:36,720
So let's take a look at these two products.

77
00:04:36,720 --> 00:04:44,120
The BlueWave Chromebook is 249.99,

78
00:04:44,120 --> 00:04:48,360
and the TechPro Desktop is actually 999.99.

79
00:04:48,360 --> 00:04:49,440
This is not actually true.

80
00:04:49,440 --> 00:04:54,520
And so let's see how the model handles this user request.

81
00:04:54,520 --> 00:05:00,360
So we'll format into our messages array, and we'll get our response.

82
00:05:00,360 --> 00:05:09,440
And then we'll print it.

83
00:05:09,440 --> 00:05:17,200
And so what we're hoping for

84
00:05:17,200 --> 00:05:21,000
is that the model takes all of these different steps and realizes that

85
00:05:21,000 --> 00:05:23,560
the user has made an incorrect assumption, and

86
00:05:23,560 --> 00:05:27,600
then follows the final step to politely correct the user.

87
00:05:27,600 --> 00:05:33,600
And so within this one prompt, we've actually maintained

88
00:05:33,600 --> 00:05:36,680
a number of different complex states that the system could be in.

89
00:05:36,680 --> 00:05:41,160
So at any given point, there could be a different output from the previous step,

90
00:05:41,160 --> 00:05:42,880
and we would want to do something different.

91
00:05:42,880 --> 00:05:47,960
For example, if the user hadn't made any assumptions in step three,

92
00:05:47,960 --> 00:05:50,160
then in step four, we wouldn't actually have any output.

93
00:05:50,160 --> 00:05:53,280
So this is a pretty complicated instruction for the model.

94
00:05:53,280 --> 00:05:54,440
So let's see if it did it right.

95
00:05:54,440 --> 00:06:00,240
So step one, the user is asking a question about specific products.

96
00:06:00,240 --> 00:06:03,600
They're asking about the price difference between these two products.

97
00:06:03,600 --> 00:06:06,720
The user assumes that the BlueWave Chromebook is more expensive than

98
00:06:06,720 --> 00:06:10,840
the TechBook Pro, and this assumption is actually incorrect.

99
00:06:10,840 --> 00:06:14,240
It's reasoning through, taking longer to think about the problem.

100
00:06:14,240 --> 00:06:18,280
In the same way that a human would also take some time to reason about

101
00:06:18,280 --> 00:06:23,640
an answer to any given question, the model performs better if it also has time to think.

102
00:06:23,640 --> 00:06:29,800
And so the final response to the user is the BlueWave Chromebook is actually less expensive than the TechBook Pro.

104
00:06:29,800 --> 00:06:36,440
The TechBook Pro desktop costs $999.99, while the BlueWave Chromebook costs $249.99.

105
00:06:36,440 --> 00:06:42,760
And so let's see another example of a user message.

106
00:06:42,760 --> 00:06:46,440
And also at this point, feel free to pause the video and try your own messages.

107
00:06:46,440 --> 00:06:51,320
So let's format this user message.

108
00:06:51,320 --> 00:06:53,720
So the question is: "Do you sell TVs?"

109
00:06:53,720 --> 00:06:58,240
And if you remember in our product list, we've only listed different computers.

110
00:06:58,240 --> 00:06:59,960
So let's see what the model says.

111
00:06:59,960 --> 00:07:06,720
So in this case, step one, the user is asking if the store sells TVs, but

112
00:07:06,720 --> 00:07:08,680
TVs are not listed in the available products.

113
00:07:08,680 --> 00:07:12,840
So as you can see, the model then skips to the response to user step because it

114
00:07:12,840 --> 00:07:17,960
realizes that the intermediary steps are not actually necessary.

115
00:07:17,960 --> 00:07:21,000
I will say that we did ask for the output in this specific format.

116
00:07:21,000 --> 00:07:25,000
So technically, the model hasn't exactly followed our request.

117
00:07:25,000 --> 00:07:27,920
Again, more advanced models will be better at doing that.

118
00:07:27,920 --> 00:07:31,080
And so in this case, our response to the user is, I'm sorry, but

119
00:07:31,080 --> 00:07:33,320
we do not sell TVs at the store.

120
00:07:33,320 --> 00:07:35,000
And then it lists the available products.

121
00:07:35,000 --> 00:07:41,040
So again, feel free to try some of your own responses.

122
00:07:41,040 --> 00:07:45,040
And so now, we only really want this part of the response.

123
00:07:45,040 --> 00:07:47,880
We wouldn't want to show the earlier parts to the user.

124
00:07:47,880 --> 00:07:53,600
So what we can do is actually just cut the string at the last occurrence

125
00:07:53,600 --> 00:07:57,520
of this delimiter token or string of four hashtags.

126
00:07:57,520 --> 00:08:01,920
And then only print the final part of the model output.

127
00:08:01,920 --> 00:08:06,440
So let's write some code to get only the final part of this string.

128
00:08:06,440 --> 00:08:12,920
So we're going to use a try except block to gracefully handle errors in case

129
00:08:12,920 --> 00:08:15,680
the model has some kind of unpredictable output and

130
00:08:15,680 --> 00:08:19,080
doesn't actually use these characters.

131
00:08:19,080 --> 00:08:23,560
And so we're gonna say our final_response is the response.

132
00:08:23,560 --> 00:08:27,040
And then we're gonna split the string at the delimiter string.

133
00:08:27,040 --> 00:08:28,320
And because we want the final occurrence,

134
00:08:28,320 --> 00:08:32,880
we just want to get the last item in the output list.

135
00:08:32,880 --> 00:08:36,120
And then we're going to strip any white space.

136
00:08:36,120 --> 00:08:38,920
Because as you can see, there might be white space after the characters.

137
00:08:38,920 --> 00:08:42,120
Then we're going to catch any errors.

138
00:08:42,120 --> 00:08:46,560
And have a fallback response.

139
00:08:46,560 --> 00:08:52,040
Which is, sorry.

142
00:08:58,600 --> 00:09:05,200
Please try asking another question.

143
00:09:05,200 --> 00:09:09,640
And then let's print our final response.

144
00:09:21,160 --> 00:09:26,840
And so as you can see, we just cut the string to get this final output.

145
00:09:26,840 --> 00:09:30,440
And so this is what we would show to the user if we were building this into an application.

147
00:09:30,440 --> 00:09:34,360
And overall, I just want to call out,

148
00:09:34,360 --> 00:09:38,360
this prompt might be slightly convoluted for this task.

149
00:09:38,360 --> 00:09:41,480
You might not actually need all of these intermediate steps.

150
00:09:41,480 --> 00:09:47,520
And so why don't you try and see if you can find an easier way to do the same task in your own prompt.

152
00:09:50,000 --> 00:09:55,120
And in general, finding the optimal trade-off in prompt complexity requires some experimentation.

154
00:09:55,120 --> 00:09:59,000
So definitely good to try a number of different prompts before deciding to use one.

156
00:09:59,000 --> 00:10:03,720
And in the next video, we'll learn another strategy to handle complex tasks

157
00:10:03,720 --> 00:10:08,000
by splitting these complex tasks into a series of simpler subtasks,

158
00:10:08,000 --> 00:10:10,440
rather than trying to do the whole task in one prompt.
