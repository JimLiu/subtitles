1
00:00:05,000 --> 00:00:10,200
In this video, we'll focus on checking outputs generated by the system.

2
00:00:10,200 --> 00:00:14,600
Checking outputs before showing them to users can be important for ensuring the quality,

3
00:00:14,600 --> 00:00:19,360
relevance and safety of the responses provided to them or used in automation flows.

4
00:00:19,360 --> 00:00:23,112
We'll learn how to use the moderation API, but this time for outputs, 

5
00:00:23,113 --> 00:00:28,760
and how to use additional prompts to the model to evaluate output quality before displaying them.

6
00:00:28,760 --> 00:00:31,000
So let's dive into the examples.

7
00:00:31,000 --> 00:00:35,520
We've already discussed the moderation API in the context of evaluating inputs.

8
00:00:35,520 --> 00:00:39,880
Now let's revisit it in the context of checking outputs.

9
00:00:39,880 --> 00:00:45,360
Moderation API can also be used to filter and moderate outputs generated by the system itself.

10
00:00:45,360 --> 00:00:47,800
And so here's an example.

11
00:00:47,800 --> 00:00:54,480
So here's a generated response to the user.

12
00:00:54,480 --> 00:01:02,160
And we're going to use the moderation API in the same way that we saw in the earlier video.

13
00:01:02,160 --> 00:01:05,000
So let's see if this output is flagged.

14
00:01:05,000 --> 00:01:12,520
And as you can see, this output is not flagged and has very low scores in all categories,

15
00:01:12,520 --> 00:01:16,480
which makes sense given the response.

16
00:01:16,480 --> 00:01:19,840
In general, it can also be important to check the outputs.

17
00:01:19,840 --> 00:01:28,200
For example, if you were creating a chatbot for sensitive audiences, you could use lower thresholds for flagging outputs.

18
00:01:28,200 --> 00:01:31,554
In general, if the moderation output indicates that the content is flagged,

19
00:01:31,555 --> 00:01:40,200
 you can take appropriate action such as responding with a fallback answer or generating a new response.

20
00:01:40,200 --> 00:01:48,420
Note that as we improve the models, they also are becoming less and less likely to return some kind of harmful output.

21
00:01:48,420 --> 00:01:51,171
Another approach for checking outputs is to ask the model itself 

22
00:01:51,172 --> 00:01:56,739
if the generated was satisfactory and if it follows a certain rubric that you define.

23
00:01:56,740 --> 00:02:00,496
This can be done by providing the generated output as part of the input to the model

24
00:02:00,497 --> 00:02:05,320
 and asking it to rate the quality of the output.

25
00:02:05,320 --> 00:02:07,080
You can do this in various different ways.

26
00:02:07,080 --> 00:02:09,960
So let's see an example.

27
00:02:09,960 --> 00:02:11,326
So our system message is, 

28
00:02:11,327 --> 00:02:16,446
you are an assistant  evaluates whether customer service agent responses sufficiently answer customer questions 

29
00:02:16,447 --> 00:02:25,260
and also validates that all the facts the assistant cites from the product information are correct.

30
00:02:25,260 --> 00:02:33,520
The product information and user and customer service agent messages will be deliberated by three backticks.

31
00:02:33,520 --> 00:02:37,420
Respond with a Y or N character with no punctuation.

32
00:02:37,420 --> 00:02:44,600
Y if the output sufficiently answers the question and the response correctly uses product information and no otherwise.

33
00:02:44,600 --> 00:02:47,080
I'll put a single letter only.

34
00:02:47,080 --> 00:02:52,180
And you could also use a chain of thought reasoning prompt for this.

35
00:02:52,180 --> 00:02:55,200
This might be a little bit difficult for the model to validate both in one step.

36
00:02:55,200 --> 00:02:56,800
So you could play around with this.

37
00:02:56,800 --> 00:02:59,240
You could also add some other kind of guidelines.

38
00:02:59,240 --> 00:03:05,460
You could ask, give a rubric like a rubric for an exam or grading an essay.

39
00:03:05,460 --> 00:03:07,179
You could use that kind of format and say, 

40
00:03:07,180 --> 00:03:10,276
does this use a friendly tone in line with our brand guidelines 

41
00:03:10,277 --> 00:03:15,560
and maybe outline some of your brand guidelines if that's something that's very important to you.

42
00:03:15,560 --> 00:03:17,400
So let's add our customer message.

43
00:03:17,400 --> 00:03:21,720
So this is the initial message used to generate this response.

44
00:03:21,720 --> 00:03:24,680
And then let's also paste in our product information.

45
00:03:24,681 --> 00:03:31,037
And so this is the product information we fetched in the previous step for all of the products mentioned in this message.

46
00:03:33,960 --> 00:03:37,800
And now we'll define our comparison.

47
00:03:37,800 --> 00:03:44,519
So the customer message is the customer message, the product information, and then the agent response, 

48
00:03:45,377 --> 00:03:51,840
which is the response to the customer that we have from this previous cell.

49
00:03:51,840 --> 00:03:59,320
So let's format this into a messages list and get the response from the model.

50
00:03:59,320 --> 00:04:05,840
So the model says, yes, the product information is correct and the question is answered sufficiently.

51
00:04:05,840 --> 00:04:08,667
Well, in general, for these kind of evaluation tasks, 

52
00:04:08,668 --> 00:04:15,120
I also think it is better to use a more advanced model because they're just better at reasoning.

53
00:04:15,120 --> 00:04:16,773
So something like GPT-4.

54
00:04:20,200 --> 00:04:23,700
Let's try another example.

55
00:04:23,700 --> 00:04:28,000
So this response is, life is like a box of chocolates.

56
00:04:28,000 --> 00:04:31,643
So let's add our message to do with the output checking.

57
00:04:36,280 --> 00:04:44,040
And the model has determined that this does not sufficiently answer the question or use the retrieved information.

58
00:04:44,040 --> 00:04:47,000
This question, does it use the retrieved information correctly?

59
00:04:47,000 --> 00:04:54,600
This is a good prompt to use if you want to make sure that the model isn't hallucinating,

60
00:04:54,600 --> 00:05:00,040
which is making up things that aren't true.

61
00:05:00,040 --> 00:05:06,080
And feel free to pause the video now and try some of your own customer messages, responses,

62
00:05:06,080 --> 00:05:11,920
and adding product information to test how this works.

63
00:05:11,920 --> 00:05:16,000
So as you can see, the model can provide feedback on the quality of a generated output.

64
00:05:16,000 --> 00:05:21,240
And you can use this feedback to decide whether to present the output to the user or to generate a new response.

65
00:05:21,241 --> 00:05:24,798
You could even experiment with generating multiple model responses per user query, 

66
00:05:24,799 --> 00:05:28,040
and then having the model choose the best one to show the user.

67
00:05:28,040 --> 00:05:30,040
So there's lots of different things you could try.

68
00:05:30,040 --> 00:05:33,940
In general, checking outputs using the moderation API is good practice.

69
00:05:33,940 --> 00:05:39,000
But while asking the model to evaluate its own output might be useful for immediate feedback

70
00:05:39,000 --> 00:05:43,633
to ensure the quality of responses in a very small number of cases, 

71
00:05:43,634 --> 00:05:50,360
I think it's probably unnecessary most of the time, especially if you're using a more advanced model like GPT-4.

72
00:05:50,360 --> 00:05:53,760
I haven't actually seen many people do something like this in production.

73
00:05:53,760 --> 00:05:56,432
It would also increase the latency and cost of your system, 

74
00:05:57,480 --> 00:05:57,481
because you'd have to wait for an additional call for the model.

75
00:05:59,640 --> 00:06:00,960
And that's also additional tokens.

76
00:06:00,960 --> 00:06:07,990
If it's really important for your Apple product that your error rate is 0.0000001%,

77
00:06:07,991 --> 00:06:09,840
 then maybe you should try this approach.

78
00:06:09,840 --> 00:06:13,760
But overall, I wouldn't really recommend that you do this in practice.

79
00:06:13,760 --> 00:06:14,247
In the next video, 

80
00:06:14,248 --> 00:06:21,960
we're going to put together everything we've learned in the evaluate input section, process section, and checking output section to build an end-to-end system.

