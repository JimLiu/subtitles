在这第一个视频中，我想和大家分享一下大型语言模型（LLM）的概述，它们是如何工作的。

我们将深入了解它们的训练过程，以及诸如分词器之类的细节，以及这些细节如何影响
在提示LLM时的输出结果。
我们还将了解LLM的聊天格式，这是一种既可以指定系统消息，
也可以指定用户消息的方法，了解您可以利用这种功能做什么。
让我们来看看。
首先，大型语言模型是如何工作的？
您可能已经熟悉了文本生成过程，您可以给出一个提示，比如“我喜欢吃”，
然后让LLM填充在这个提示下可能的补全内容。
它可能会说“百吉饼加奶油奶酪”或“我妈妈做的肉饼”或“和朋友一起在外面（吃）”。
但是模型是如何学会这个的呢？
实际上，训练LLM的主要工具是监督学习。
在监督学习中，计算机使用带标签的训练数据学习输入/输出或X/Y映射。

所以，例如，如果你使用监督学习来学习对餐厅评价
进行好评/差评分类，你可能会收集这样的训练集，其中像
“熏牛肉三明治很棒”被标记为好评，依此类推。
而“服务慢，食物一般”是差评，“伯爵灰茶非常棒”
带有正面标签。
顺便说一下，Isa和我都出生在英国，所以我们都喜欢我们的伯爵茶。
因此，监督学习的过程通常是获得带标签的数据，然后
在数据上训练一个模型，训练完成后，您可以部署并调用该模型，
给它一个新的餐厅评论，比如"我吃过的最好的披萨"。
希望您能输出这是一个积极的情感。
事实证明，监督学习是训练大型语言的核心构建模块模型。

具体来说，可以通过使用监督学习来反复
预测下一个单词来构建大型语言模型。
假设在您的训练集中有很多文本数据，您必须将句子"我最喜欢的
食物是百吉饼配上奶油奶酪和熏鲑鱼"。
那么这个句子就会变成一个训练示例序列，给定一个句子
片段"我最喜欢的食物是"，如果你想预测下一个单词，这种情况下是
"百吉饼"，或者给定句子片段或句子前缀"我最喜欢的食物是百吉饼"，
接下来的单词就是"配上"，依此类推。
而且，给定一个包含数千亿甚至更多单词的大型训练集，
你就可以创建一个庞大的训练集，从一句话的一部分开始
或者一段文字的一部分，反复让语言模型学会预测
下一个单词是什么。
所以今天有两种主要类型的大型语言模型。
第一种是基础LLM，第二种是越来越多地被使用的指令调优LLM（Instruction Tuned LLM）。

所以基础LLM会根据文本训练数据反复预测下一个单词。
因此，如果我给它一个提示“从前有一个独角兽”，那么它可能会通过反复地
一次预测一个单词，编写一个关于独角兽的故事，
讲述独角兽与所有独角兽朋友一起生活在一个神奇的森林里。
现在的一个缺点是，如果你给它一个提示“法国的首都是什么？”

在互联网上很有可能存在关于法国的一系列测验问题。
所以它可能会用“法国最大的城市是什么？”来完成这个问题，
“法国的人口是多少？”等等。
但是你真正想要的是让它告诉你法国的首都是什么，
而不是列出所有这些问题。
所以，指令调优LLM尝试遵循指令，并希望能正确回答出，
法国的首都是巴黎。
如何从基础LLM转变为指令调优LLM？
这就是训练一个类似ChatGPT的指令调优LLM的过程。
首先，你需要在大量数据上训练一个基础LLM，可能是数千亿甚至
更多的词汇，这个过程可能需要在大型超级计算系统上进行数月。
在训练了基础LLM之后，你可以通过在一小部分的例子上微调模型
来进一步训练它，这些例子的输出遵循输入的指令。
所以，例如，你可以请负责数据标注的承包商帮助你编写很多指令的示例，
以及如何对这些指令高质量的回应，这样就形成了一套训练集，可以进行
额外的微调，使其在尝试遵循指令的情况下，学会预测下一个词是什么。

在此之后，为了提高LLM输出质量的常见方法是获得人类
对许多不同LLM输出质量的评分，例如输出是否
有帮助、诚实和无害，然后您可以进一步调整LLM以提高
生成更高评分输出的概率。
最常用的技术是RLHF，即来自人类反馈的强化学习。

而训练基础LLM可能需要几个月的时间，从基础LLM
到指令调优LLM的过程可能只需要几天时间，数据集规模
和计算资源都要小得多。
所以这就是你如何使用LLM的方法。
我将导入一些库。
我将在这里加载我的OpenAI密钥。
稍后在这个视频中，我会更详细地介绍这个。
这里有一个辅助函数，用于根据提示获取补全（completion）。
如果您还没有在计算机上安装OpenAI软件包，您可能需要运行pip
安装OpenAI，但我已经在这里安装了，所以我不会运行那个。
让我按shift enter运行这些，现在我可以设置response=get_completion
“法国的首都是什么？”，希望它能给我一个好结果。
现在关于大型语言模型的描述，到目前为止，我谈论的是
一次预测一个单词，但实际上还有一个更重要的技术细节。
如果你让它“把单词lollipop中的字母倒过来”。
这看起来像是一个简单的任务，也许一个四岁的孩子就能完成这个任务，但如果你
让ChatGPT去做这个，它实际上输出的是一种有点乱七八糟的东西。
这不是L-O-L-L-I-P-O-P，这不是lollipop的字母倒过来。
那么为什么ChatGPT无法完成看似相对简单的任务呢。
事实证明，大型语言模型的工作方式还有一个更重要的细节，
那就是它实际上不是反复预测下一个单词，而是反复预测
下一个标记（Token），而一个LLM实际上会做的是，它会接收一系列字符，比如
“learning new things is fun”，并将字符组合在一起形成代表常见
字符序列的标记。
所以在这里“learning new things is fun”，每个都是相当常见的词，所以每个标记
对应一个词或一个词的空格或感叹号。
但是，如果你给它一些不太常用的词作为输入，比如“Prompting
is a powerful developer tool.”对于开发者来说，Prompting这个词在英语中还不是那么常见
但肯定越来越受欢迎，所以“Prompting”实际上被分解成三个
标记，分别是"prompt"、"pt"和"ing"，因为这三个是常见的字母序列
如果你给它一个“棒棒糖（lollipop）”这个词，分词器实际上把这个
分成三个标记"l"、"o"和"ipop"，因为ChatGPT没有看到单独的
字母，而是看到了这三个标记，所以要正确地按相反的顺序打印
出这些字母就更困难了。
所以这里有一个技巧，如果我在这些字母之间加上破折号，
空格也可以，或者其他东西也可以，然后把字母和棒棒糖拿过来
反过来，它实际上做得更好，这个LOLLIPOP，原因是
如果你用破折号把lollipop的字母隔开，它会把每一个
这些字符分成一个个的标记，让它更容易看到单独的
字母，然后按相反的顺序打印出来。
所以如果你想用ChatGPT玩像wordle或scrap这样的单词游戏，
这个巧妙的技巧有助于更好地看到单词的各个字母。
对于英语，一个标记大致平均对应四个字符，
或者大约三分之二个单词，所以不同的大型语言模型通常会有不同的
关于它可以接受的输入加输出标记的数量限制。
输入通常被称为上下文（context），输出通常被称为补全（completion）
例如，最常用的ChatGPT模型GPT-3.5 Turbo在输入和输出中的限制
大约是4000个标记。
所以，如果你尝试输入一个超过这个长度的上下文，它实际上会抛出
一个异常或产生一个错误。
接下来，我想和你分享另一种使用LLM API的强大方法，它涉及指定
独立的系统（system）、用户（user）和助手（assistant）消息。
让我给你展示一个例子，然后我们可以更详细地解释它实际上在做什么。
这里有一个新的辅助函数，叫做从消息中获取补全，当我们提示这个LLM时
我们将给它提供多条消息。
这是一个你可以做的例子。
首先，我将以系统的角色指定一条信息，以便这个助手信息
系统信息的内容是，你是一个以苏斯博士的风格回应的助手。

然后我将指定一个用户信息，所以第二条信息的角色是用户，
而这个内容是“给我写一首关于快乐胡萝卜的非常短的诗。”
所以让我们运行这个，温度（Temperature）参数设置为1，我实际上永远不知道会出现什么
但好吧，这是一首很酷的诗。
“哦，我看到的这根胡萝卜是多么快乐”，而且它实际上运行得相当好。
好吧，干得好ChatGPT。
所以在这个例子中，系统消息指定了你想要的
大语言模型的整体语言风格，而用户消息是一个具体的指令，
你希望在系统中执行这个更高级别的行为消息。

这里有一个说明它是如何工作的例子。
所以这就是聊天格式的工作原理。
系统消息设定了大型语言模型或
助手的整体行为风格，然后当你给出用户消息，比如说“给我
讲个笑话或者写首诗”，它会根据你在用户消息中要求的内容，
以及在系统消息中设定的整体行为风格，输出一个合适的回应。

顺便说一下，虽然我没有在这里展示，但如果你想在多轮对话中
使用这个功能，你也可以用这种消息格式输入助手消息，让ChatGPT
了解它之前说过什么，如果你想根据之前的对话继续对话的话。

但是这里有更多的例子。
如果你想设置语言风格，告诉它输出一句话，那么在
系统消息中，我可以说你的所有回答都必须是一句话长，当我执行
这个操作时，它输出的一句话不再是诗歌，也不是苏斯博士的风格，但这
是一句关于快乐胡萝卜的故事。
如果我们想同时指定风格和长度，那么我可以使用系统消息，
在系统回应中说，以苏斯博士的风格，你的所有句子都必须是一句话长，
现在这生成了一个很好的一句话诗歌，总是微笑，从不可怕。
我喜欢这是一首非常快乐的诗。
然后最后，只是为了好玩，如果你在使用LLM，想知道有多少个tokens
你在这里使用了一个稍微复杂一点的辅助函数。
它从OpenAI API获取响应，然后使用响应中的其他值
告诉你在你的API调用中使用了多少“prompt tokens”、“completion tokens”和“total tokens”。

让我定义一下，如果我现在运行这个，这是响应，这是一个关于我们使用了多少个
tokens的计数。
所以这个输出有55个tokens，而提示输入有37个tokens，所以这个
一共使用了92个tokens。
当我在实践中使用LLM模型时，我实际上并不太担心我使用的tokens数量。

也许在一个情况下，检查tokens数量是值得的，那就是如果你担心
用户可能给你太长的输入，超过了4000个左右的tokens
ChatGPT的限制，在这种情况下，你可以仔细检查一下tokens数量并截断
它以确保你在大型语言模型的输入tokens限制范围内。
现在我想和你分享如何使用大型语言模型的另一个技巧。
调用OpenAI API需要使用与免费或付费账户绑定的API密钥，
因此许多开发者会像这样将API密钥以纯文本形式写入他们的
Jupyter Notebook，这是一种使用API密钥的不太安全的方式，我不建议
你使用，因为这样太容易与他人共享这个Notebook或将其检查到
GitHub或其他地方，从而泄露你的API密钥给其他人。
相比之下，你在 Jupyter Notebook中看到我做的是这段代码，我使用
一个库 dotenv，然后运行这个命令 load dotenv find dotenv 来读取一个本地
文件，叫做 .env，里面包含了我的密钥。
所以通过这段代码片段，我在本地存储了一个名为 .env 的文件，其中包含
我的 API 密钥，然后将其加载到操作系统的环境变量中，然后 os.getenv，
OPENAI_API_KEY将其存储到这个变量中，在整个过程中，我不需要将
API 密钥以明文形式输入到我的 Jupyter Notebook中。
所以这是一个相对更安全、更好的访问 API 密钥的方法，实际上
这是一种用于存储来自许多不同在线服务的不同 API 密钥的通用方法
你可能想要使用并从你的 Jupyter Notebook中调用。
我认为，提示（prompting）正在革新AI应用开发的程度，仍然被低估了。

在传统的监督式机器学习工作流中，就像我刚才提到的餐厅评论好评/差评分类
的例子，如果你想建立一个分类器来
分类餐厅评论的正面或负面情感，你首先需要获得一堆标签数据，
也许是几百个例子，这可能需要几周，也许一个月。然后，
你会在数据上训练一个模型，获取一个合适的开源模型，
对模型进行调优，评估模型，这可能需要几天、几周甚至几个月的时间。接下来，
您可能需要找到一个云服务来部署它，然后将模型上传到云端，
然后运行模型，最后才能调用你的模型。再说，这种情况并不少见，
这可能需要一个团队几个月的时间才能完成。
与基于提示的机器学习相比，当你有一个文本应用程序时，你可以指定
一个提示，这可能需要几分钟甚至几个小时，如果你需要迭代几次才能得到
一个有效的提示，然后在几个小时甚至最多几天内，但坦率地说，更多的是几个小时
你可以使用API调用来运行这个程序，并开始调用模型，一旦
你完成了这个过程，可能只需要几分钟或几个小时，你就可以开始调用模型并
开始进行推断，所以有些应用程序过去可能需要我花费六个月甚至一
年的时间来构建，现在你可以在几分钟或几小时内，甚至很少的几天内
使用提示来构建，这正在彻底改变可以快速构建的AI应用程序。
一个重要的注意事项是，这适用于许多非结构化数据应用，包括特别是
文本应用程序，也许越来越多的视觉应用程序，尽管视觉技术
目前还不够成熟，但它正在朝这个方向发展。
这个方法对于结构化数据应用（即机器学习）并不十分适用，
在Excel表格中有大量数值的表格数据应用上，
但对于适用的应用来说，AI组件可以快速构建的事实，
正在改变整个系统可能构建的工作流程。
构建整个系统可能仍然需要几天或几周的时间，但至少这部分
可以更快地完成，所以让我们继续下一个视频，Isa将展示
如何使用这些组件来评估客户服务助手的输入，
这将是一个更大示例的一部分，您将在本课程中看到
如何为在线零售商构建一个客户服务助手。