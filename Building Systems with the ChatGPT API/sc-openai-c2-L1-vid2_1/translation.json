{
  "chunks": [
    {
      "items": [
        {
          "id": "1",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 0,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 10,
            "milliseconds": 80
          },
          "text": "In this first video, I'd like to share with you an overview of how LLMs, large language"
        },
        {
          "id": "2",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 10,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 11,
            "milliseconds": 80
          },
          "text": "models work."
        },
        {
          "id": "3",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 11,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 16,
            "milliseconds": 480
          },
          "text": "We'll go into how they are trained, as well as details like the tokenIsa and how that"
        },
        {
          "id": "4",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 16,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 20,
            "milliseconds": 80
          },
          "text": "can affect the output of when you prompt an LLM."
        },
        {
          "id": "5",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 20,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 25,
            "milliseconds": 800
          },
          "text": "And we'll also take a look at the chat format for LLMs, which is a way of specifying both"
        },
        {
          "id": "6",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 25,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 31,
            "milliseconds": 360
          },
          "text": "system as well as user messages and understand what you can do with that capability."
        },
        {
          "id": "7",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 31,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 32,
            "milliseconds": 680
          },
          "text": "Let's take a look."
        },
        {
          "id": "8",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 32,
            "milliseconds": 680
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 36,
            "milliseconds": 280
          },
          "text": "First, how does a large language model work?"
        },
        {
          "id": "9",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 36,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 41,
            "milliseconds": 80
          },
          "text": "You're probably familiar with the text generation process where you can give a prompt, \"I love"
        },
        {
          "id": "10",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 41,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 47,
            "milliseconds": 360
          },
          "text": "eating\" and ask an LLM to fill in what the things are likely completions given this prompt."
        }
      ],
      "source": [
        "In this first video, I'd like to share with you an overview of how LLMs, large language",
        "models work.",
        "We'll go into how they are trained, as well as details like the tokenIsa and how that",
        "can affect the output of when you prompt an LLM.",
        "And we'll also take a look at the chat format for LLMs, which is a way of specifying both",
        "system as well as user messages and understand what you can do with that capability.",
        "Let's take a look.",
        "First, how does a large language model work?",
        "You're probably familiar with the text generation process where you can give a prompt, \"I love",
        "eating\" and ask an LLM to fill in what the things are likely completions given this prompt."
      ],
      "result": [
        "在这第一个视频中，我想和大家分享一下大型语言模型（LLM）的概述，它们是如何工作的。",
        "",
        "我们将深入了解它们的训练过程，以及诸如分词器之类的细节，以及这些细节如何影响",
        "在提示LLM时的输出结果。",
        "我们还将了解LLM的聊天格式，这是一种既可以指定系统消息，",
        "也可以指定用户消息的方法，了解您可以利用这种功能做什么。",
        "让我们来看看。",
        "首先，大型语言模型是如何工作的？",
        "您可能已经熟悉了文本生成过程，您可以给出一个提示，比如“我喜欢吃”，",
        "然后让LLM填充在这个提示下可能的补全内容。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "11",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 47,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 52,
            "milliseconds": 560
          },
          "text": "And it may say \"bagels with cream cheese\" or \"my mother's meatloaf\" or \"out with friends\"."
        },
        {
          "id": "12",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 52,
            "milliseconds": 560
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 55,
            "milliseconds": 320
          },
          "text": "But how did the model learn to do this?"
        },
        {
          "id": "13",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 55,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 0,
            "milliseconds": 800
          },
          "text": "The main tool used to train an LLM is actually supervised learning."
        },
        {
          "id": "14",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 0,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 6,
            "milliseconds": 320
          },
          "text": "In supervised learning, a computer learns an input/output or X/Y mapping using labeled"
        },
        {
          "id": "15",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 6,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 7,
            "milliseconds": 320
          },
          "text": "training data."
        },
        {
          "id": "16",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 7,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 12,
            "milliseconds": 480
          },
          "text": "So, for example, if you're using supervised learning to learn to classify the sentiment"
        },
        {
          "id": "17",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 12,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 17,
            "milliseconds": 0
          },
          "text": "of restaurant reviews, you might collect a training set like this, where a review like"
        },
        {
          "id": "18",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 17,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 23,
            "milliseconds": 320
          },
          "text": "\"the pastrami sandwich was great\" is labeled as a positive sentiment review and so on."
        },
        {
          "id": "19",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 23,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 28,
            "milliseconds": 320
          },
          "text": "And \"service was slow, the food was so-so\" is negative and \"the earl grey tea was fantastic\""
        },
        {
          "id": "20",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 28,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 30,
            "milliseconds": 440
          },
          "text": "has a positive label."
        }
      ],
      "source": [
        "And it may say \"bagels with cream cheese\" or \"my mother's meatloaf\" or \"out with friends\".",
        "But how did the model learn to do this?",
        "The main tool used to train an LLM is actually supervised learning.",
        "In supervised learning, a computer learns an input/output or X/Y mapping using labeled",
        "training data.",
        "So, for example, if you're using supervised learning to learn to classify the sentiment",
        "of restaurant reviews, you might collect a training set like this, where a review like",
        "\"the pastrami sandwich was great\" is labeled as a positive sentiment review and so on.",
        "And \"service was slow, the food was so-so\" is negative and \"the earl grey tea was fantastic\"",
        "has a positive label."
      ],
      "result": [
        "它可能会说“百吉饼加奶油奶酪”或“我妈妈做的肉饼”或“和朋友一起在外面（吃）”。",
        "但是模型是如何学会这个的呢？",
        "实际上，训练LLM的主要工具是监督学习。",
        "在监督学习中，计算机使用带标签的训练数据学习输入/输出或X/Y映射。",
        "",
        "所以，例如，如果你使用监督学习来学习对餐厅评价",
        "进行好评/差评分类，你可能会收集这样的训练集，其中像",
        "“熏牛肉三明治很棒”被标记为好评，依此类推。",
        "而“服务慢，食物一般”是差评，“伯爵灰茶非常棒”",
        "带有正面标签。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "21",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 30,
            "milliseconds": 440
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 35,
            "milliseconds": 960
          },
          "text": "By the way, both Isa and I were born in the UK and so both of us like our earl grey tea."
        },
        {
          "id": "22",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 35,
            "milliseconds": 960
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 41,
            "milliseconds": 740
          },
          "text": "And so the process for supervised learning is typically to get labeled data and then"
        },
        {
          "id": "23",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 41,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 47,
            "milliseconds": 240
          },
          "text": "train a model on data and after training, you can then deploy and call the model and"
        },
        {
          "id": "24",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 47,
            "milliseconds": 240
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 50,
            "milliseconds": 920
          },
          "text": "give it a new restaurant review like \"best pizza I've ever had\"."
        },
        {
          "id": "25",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 50,
            "milliseconds": 920
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 54,
            "milliseconds": 320
          },
          "text": "You hopefully output that that has a positive sentiment."
        },
        {
          "id": "26",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 54,
            "milliseconds": 320
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 59,
            "milliseconds": 280
          },
          "text": "It turns out that supervised learning is a core building block for training large language"
        },
        {
          "id": "27",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 59,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 0,
            "milliseconds": 280
          },
          "text": "models."
        },
        {
          "id": "28",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 0,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 5,
            "milliseconds": 840
          },
          "text": "Specifically, a large language model can be built by using supervised learning to repeatedly"
        },
        {
          "id": "29",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 5,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 8,
            "milliseconds": 160
          },
          "text": "predict the next word."
        },
        {
          "id": "30",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 8,
            "milliseconds": 160
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 14,
            "milliseconds": 740
          },
          "text": "Let's say that in your training set of a lot of text data, you have to sentence \"my favorite"
        },
        {
          "id": "31",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 14,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 17,
            "milliseconds": 480
          },
          "text": "food is a bagel with cream cheese and mozz\"."
        }
      ],
      "source": [
        "By the way, both Isa and I were born in the UK and so both of us like our earl grey tea.",
        "And so the process for supervised learning is typically to get labeled data and then",
        "train a model on data and after training, you can then deploy and call the model and",
        "give it a new restaurant review like \"best pizza I've ever had\".",
        "You hopefully output that that has a positive sentiment.",
        "It turns out that supervised learning is a core building block for training large language",
        "models.",
        "Specifically, a large language model can be built by using supervised learning to repeatedly",
        "predict the next word.",
        "Let's say that in your training set of a lot of text data, you have to sentence \"my favorite",
        "food is a bagel with cream cheese and lox\"."
      ],
      "result": [
        "顺便说一下，Isa和我都出生在英国，所以我们都喜欢我们的伯爵茶。",
        "因此，监督学习的过程通常是获得带标签的数据，然后",
        "在数据上训练一个模型，训练完成后，您可以部署并调用该模型，",
        "给它一个新的餐厅评论，比如\"我吃过的最好的披萨\"。",
        "希望您能输出这是一个积极的情感。",
        "事实证明，监督学习是训练大型语言的核心构建模块模型。",
        "",
        "具体来说，可以通过使用监督学习来反复",
        "预测下一个单词来构建大型语言模型。",
        "假设在您的训练集中有很多文本数据，您必须将句子\"我最喜欢的",
        "食物是百吉饼配上奶油奶酪和熏鲑鱼\"。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "32",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 17,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 23,
            "milliseconds": 480
          },
          "text": "Then this sentence is turned into a sequence of training examples where given a sentence"
        },
        {
          "id": "33",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 23,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 28,
            "milliseconds": 800
          },
          "text": "fragment \"my favorite food is a\" if you want to predict the next word in this case was"
        },
        {
          "id": "34",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 28,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 36,
            "milliseconds": 520
          },
          "text": "\"bagel\" or given the sentence fragment or sentence prefix \"my favorite food is a bagel\","
        },
        {
          "id": "35",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 36,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 41,
            "milliseconds": 120
          },
          "text": "the next word in this case would be \"with\" and so on."
        },
        {
          "id": "36",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 41,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 45,
            "milliseconds": 600
          },
          "text": "And given a large training set of hundreds of billions or sometimes even more words,"
        },
        {
          "id": "37",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 45,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 51,
            "milliseconds": 520
          },
          "text": "you can then create a massive training set where you can start off with part of a sentence"
        },
        {
          "id": "38",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 51,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 56,
            "milliseconds": 600
          },
          "text": "or part of a piece of text and repeatedly ask the language model to learn to predict"
        },
        {
          "id": "39",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 56,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 58,
            "milliseconds": 440
          },
          "text": "what is the next word."
        },
        {
          "id": "40",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 58,
            "milliseconds": 440
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 4,
            "milliseconds": 820
          },
          "text": "So today there are broadly two major types of large language models."
        },
        {
          "id": "41",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 4,
            "milliseconds": 820
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 10,
            "milliseconds": 720
          },
          "text": "The first is a base LLM and the second which is what is increasingly used is the instruction"
        },
        {
          "id": "42",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 10,
            "milliseconds": 720
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 12,
            "milliseconds": 520
          },
          "text": "Tuned LLM."
        }
      ],
      "source": [
        "Then this sentence is turned into a sequence of training examples where given a sentence",
        "fragment \"my favorite food is a\" if you want to predict the next word in this case was",
        "\"bagel\" or given the sentence fragment or sentence prefix \"my favorite food is a bagel\",",
        "the next word in this case would be \"with\" and so on.",
        "And given a large training set of hundreds of billions or sometimes even more words,",
        "you can then create a massive training set where you can start off with part of a sentence",
        "or part of a piece of text and repeatedly ask the language model to learn to predict",
        "what is the next word.",
        "So today there are broadly two major types of large language models.",
        "The first is a base LLM and the second which is what is increasingly used is the instruction",
        "Tuned LLM."
      ],
      "result": [
        "那么这个句子就会变成一个训练示例序列，给定一个句子",
        "片段\"我最喜欢的食物是\"，如果你想预测下一个单词，这种情况下是",
        "\"百吉饼\"，或者给定句子片段或句子前缀\"我最喜欢的食物是百吉饼\"，",
        "接下来的单词就是\"配上\"，依此类推。",
        "而且，给定一个包含数千亿甚至更多单词的大型训练集，",
        "你就可以创建一个庞大的训练集，从一句话的一部分开始",
        "或者一段文字的一部分，反复让语言模型学会预测",
        "下一个单词是什么。",
        "所以今天有两种主要类型的大型语言模型。",
        "第一种是基础LLM，第二种是越来越多地被使用的指令调优LLM（Instruction Tuned LLM）。",
        ""
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "43",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 12,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 18,
            "milliseconds": 200
          },
          "text": "So the base LLM repeatedly predicts the next word based on text training data."
        },
        {
          "id": "44",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 18,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 22,
            "milliseconds": 720
          },
          "text": "And so if I give it a prompt \"once upon a time there was a unicorn\" then it may by repeatedly"
        },
        {
          "id": "45",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 22,
            "milliseconds": 720
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 27,
            "milliseconds": 200
          },
          "text": "predicting one word at a time come up with a completion that tells a story about a unicorn"
        },
        {
          "id": "46",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 27,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 30,
            "milliseconds": 480
          },
          "text": "living in a magical forest with all unicorn friends."
        },
        {
          "id": "47",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 30,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 35,
            "milliseconds": 600
          },
          "text": "Now a downside of this is that if you were to prompt it with \"what is the capital of"
        },
        {
          "id": "48",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 35,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 36,
            "milliseconds": 600
          },
          "text": "France?\""
        },
        {
          "id": "49",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 36,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 40,
            "milliseconds": 600
          },
          "text": "quite plausible that on the internet there might be a list of quiz questions about France."
        },
        {
          "id": "50",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 40,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 42,
            "milliseconds": 920
          },
          "text": "So it may complete this with \"what is France's largest city?\""
        },
        {
          "id": "51",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 42,
            "milliseconds": 920
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 46,
            "milliseconds": 400
          },
          "text": "\"what is France's population?\" and so on."
        },
        {
          "id": "52",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 46,
            "milliseconds": 400
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 50,
            "milliseconds": 880
          },
          "text": "But what you really want is you want it to tell you what is the capital of France probably"
        },
        {
          "id": "53",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 50,
            "milliseconds": 880
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 54,
            "milliseconds": 360
          },
          "text": "rather than list all these questions."
        }
      ],
      "source": [
        "So the base LLM repeatedly predicts the next word based on text training data.",
        "And so if I give it a prompt \"once upon a time there was a unicorn\" then it may by repeatedly",
        "predicting one word at a time come up with a completion that tells a story about a unicorn",
        "living in a magical forest with all unicorn friends.",
        "Now a downside of this is that if you were to prompt it with \"what is the capital of",
        "France?\"",
        "quite plausible that on the internet there might be a list of quiz questions about France.",
        "So it may complete this with \"what is France's largest city?\"",
        "\"what is France's population?\" and so on.",
        "But what you really want is you want it to tell you what is the capital of France probably",
        "rather than list all these questions."
      ],
      "result": [
        "所以基础LLM会根据文本训练数据反复预测下一个单词。",
        "因此，如果我给它一个提示“从前有一个独角兽”，那么它可能会通过反复地",
        "一次预测一个单词，编写一个关于独角兽的故事，",
        "讲述独角兽与所有独角兽朋友一起生活在一个神奇的森林里。",
        "现在的一个缺点是，如果你给它一个提示“法国的首都是什么？”",
        "",
        "在互联网上很有可能存在关于法国的一系列测验问题。",
        "所以它可能会用“法国最大的城市是什么？”来完成这个问题，",
        "“法国的人口是多少？”等等。",
        "但是你真正想要的是让它告诉你法国的首都是什么，",
        "而不是列出所有这些问题。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "54",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 54,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 58,
            "milliseconds": 800
          },
          "text": "So the Instruction Tuned LLM instead tries to follow instructions and will hopefully"
        },
        {
          "id": "55",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 58,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 2,
            "milliseconds": 160
          },
          "text": "say the capital of France is Paris."
        },
        {
          "id": "56",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 2,
            "milliseconds": 160
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 6,
            "milliseconds": 120
          },
          "text": "How do you go from a base LLM to an Instruction Tuned LLM?"
        },
        {
          "id": "57",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 6,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 11,
            "milliseconds": 760
          },
          "text": "This is what the process of training an Instruction Tuned LLM like ChatGPT looks like."
        },
        {
          "id": "58",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 11,
            "milliseconds": 760
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 16,
            "milliseconds": 80
          },
          "text": "You first train a base LLM on a lot of data so hundreds of billions of words maybe even"
        },
        {
          "id": "59",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 16,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 22,
            "milliseconds": 80
          },
          "text": "more and this is a process that can take months on a large supercomputing system."
        },
        {
          "id": "60",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 22,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 28,
            "milliseconds": 480
          },
          "text": "After you've trained the base LLM you would then further train the model by fine tuning"
        },
        {
          "id": "61",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 28,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 35,
            "milliseconds": 820
          },
          "text": "it on a smaller set of examples where the output follows an input instruction."
        },
        {
          "id": "62",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 35,
            "milliseconds": 820
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 42,
            "milliseconds": 600
          },
          "text": "And so for example you may have contractors help you write a lot of examples of an instruction"
        },
        {
          "id": "63",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 42,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 48,
            "milliseconds": 40
          },
          "text": "and then a good response to an instruction and that creates a training set to carry out"
        },
        {
          "id": "64",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 48,
            "milliseconds": 40
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 51,
            "milliseconds": 920
          },
          "text": "this additional fine tuning so that it learns to predict what is the next word if it's trying"
        },
        {
          "id": "65",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 51,
            "milliseconds": 920
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 55,
            "milliseconds": 80
          },
          "text": "to follow an instruction."
        }
      ],
      "source": [
        "So the Instruction Tuned LLM instead tries to follow instructions and will hopefully",
        "say the capital of France is Paris.",
        "How do you go from a base LLM to an Instruction Tuned LLM?",
        "This is what the process of training an Instruction Tuned LLM like ChatGPT looks like.",
        "You first train a base LLM on a lot of data so hundreds of billions of words maybe even",
        "more and this is a process that can take months on a large supercomputing system.",
        "After you've trained the base LLM you would then further train the model by fine tuning",
        "it on a smaller set of examples where the output follows an input instruction.",
        "And so for example you may have contractors help you write a lot of examples of an instruction",
        "and then a good response to an instruction and that creates a training set to carry out",
        "this additional fine tuning so that it learns to predict what is the next word if it's trying",
        "to follow an instruction."
      ],
      "result": [
        "所以，指令调优LLM尝试遵循指令，并希望能正确回答出，",
        "法国的首都是巴黎。",
        "如何从基础LLM转变为指令调优LLM？",
        "这就是训练一个类似ChatGPT的指令调优LLM的过程。",
        "首先，你需要在大量数据上训练一个基础LLM，可能是数千亿甚至",
        "更多的词汇，这个过程可能需要在大型超级计算系统上进行数月。",
        "在训练了基础LLM之后，你可以通过在一小部分的例子上微调模型",
        "来进一步训练它，这些例子的输出遵循输入的指令。",
        "所以，例如，你可以请负责数据标注的承包商帮助你编写很多指令的示例，",
        "以及如何对这些指令高质量的回应，这样就形成了一套训练集，可以进行",
        "额外的微调，使其在尝试遵循指令的情况下，学会预测下一个词是什么。",
        ""
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "66",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 55,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 1,
            "milliseconds": 520
          },
          "text": "After that to improve the quality of the LLM's output a common process now is to obtain human"
        },
        {
          "id": "67",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 1,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 7,
            "milliseconds": 520
          },
          "text": "ratings of the quality of many different LLM outputs on criteria such as whether the output"
        },
        {
          "id": "68",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 7,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 14,
            "milliseconds": 120
          },
          "text": "is helpful, honest, and harmless and you can then further tune the LLM to increase the"
        },
        {
          "id": "69",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 14,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 18,
            "milliseconds": 0
          },
          "text": "probability of its generating the more highly rated outputs."
        },
        {
          "id": "70",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 18,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 22,
            "milliseconds": 80
          },
          "text": "And the most common technique to do this is RLHF which stands for reinforcement learning"
        },
        {
          "id": "71",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 22,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 24,
            "milliseconds": 600
          },
          "text": "from human feedback."
        },
        {
          "id": "72",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 24,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 29,
            "milliseconds": 800
          },
          "text": "And whereas training the base LLM can take months the process of going from the base"
        },
        {
          "id": "73",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 29,
            "milliseconds": 800
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 36,
            "milliseconds": 680
          },
          "text": "LLM to the instruction tune LLM can be done in maybe days on a much more modest size data"
        },
        {
          "id": "74",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 36,
            "milliseconds": 680
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 40,
            "milliseconds": 360
          },
          "text": "set and much more modest size computational resources."
        },
        {
          "id": "75",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 40,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 42,
            "milliseconds": 560
          },
          "text": "So this is how you would use an LLM."
        }
      ],
      "source": [
        "After that to improve the quality of the LLM's output a common process now is to obtain human",
        "ratings of the quality of many different LLM outputs on criteria such as whether the output",
        "is helpful, honest, and harmless and you can then further tune the LLM to increase the",
        "probability of its generating the more highly rated outputs.",
        "And the most common technique to do this is RLHF which stands for reinforcement learning",
        "from human feedback.",
        "And whereas training the base LLM can take months the process of going from the base",
        "LLM to the Instruction Tune LLM can be done in maybe days on a much more modest size data",
        "set and much more modest size computational resources.",
        "So this is how you would use an LLM."
      ],
      "result": [
        "在此之后，为了提高LLM输出质量的常见方法是获得人类",
        "对许多不同LLM输出质量的评分，例如输出是否",
        "有帮助、诚实和无害，然后您可以进一步调整LLM以提高",
        "生成更高评分输出的概率。",
        "最常用的技术是RLHF，即来自人类反馈的强化学习。",
        "",
        "而训练基础LLM可能需要几个月的时间，从基础LLM",
        "到指令调优LLM的过程可能只需要几天时间，数据集规模",
        "和计算资源都要小得多。",
        "所以这就是你如何使用LLM的方法。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "76",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 42,
            "milliseconds": 560
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 45,
            "milliseconds": 560
          },
          "text": "I'm going to import a few libraries."
        },
        {
          "id": "77",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 45,
            "milliseconds": 560
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 48,
            "milliseconds": 840
          },
          "text": "I'm going to load my OpenAI key here."
        },
        {
          "id": "78",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 48,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 52,
            "milliseconds": 620
          },
          "text": "I'll say a little bit more about this later in this video."
        },
        {
          "id": "79",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 52,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 57,
            "milliseconds": 580
          },
          "text": "And here's a helper function to get a completion given a prompt."
        },
        {
          "id": "80",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 57,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 4,
            "milliseconds": 640
          },
          "text": "If you have not yet installed the OpenAI package on your computer you might have to run pip"
        },
        {
          "id": "81",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 4,
            "milliseconds": 640
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 9,
            "milliseconds": 960
          },
          "text": "install OpenAI but I already have it installed here so I won't run that."
        },
        {
          "id": "82",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 9,
            "milliseconds": 960
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 20,
            "milliseconds": 280
          },
          "text": "And let me hit shift enter to run these and now I can set response equals get completion"
        },
        {
          "id": "83",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 20,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 34,
            "milliseconds": 820
          },
          "text": "\"what is the capital of France?\" and hopefully it will give me a good result."
        },
        {
          "id": "84",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 34,
            "milliseconds": 820
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 42,
            "milliseconds": 620
          },
          "text": "Now about now in the description of the large language model so far I talked about it as"
        },
        {
          "id": "85",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 42,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 47,
            "milliseconds": 940
          },
          "text": "predicting one word at a time but there's actually one more important technical detail."
        }
      ],
      "source": [
        "I'm going to import a few libraries.",
        "I'm going to load my OpenAI key here.",
        "I'll say a little bit more about this later in this video.",
        "And here's a helper function to get a completion given a prompt.",
        "If you have not yet installed the OpenAI package on your computer you might have to run pip",
        "install OpenAI but I already have it installed here so I won't run that.",
        "And let me hit shift enter to run these and now I can set response=get_completion",
        "\"what is the capital of France?\" and hopefully it will give me a good result.",
        "Now about now in the description of the large language model so far I talked about it as",
        "predicting one word at a time but there's actually one more important technical detail."
      ],
      "result": [
        "我将导入一些库。",
        "我将在这里加载我的OpenAI密钥。",
        "稍后在这个视频中，我会更详细地介绍这个。",
        "这里有一个辅助函数，用于根据提示获取补全（completion）。",
        "如果您还没有在计算机上安装OpenAI软件包，您可能需要运行pip",
        "安装OpenAI，但我已经在这里安装了，所以我不会运行那个。",
        "让我按shift enter运行这些，现在我可以设置response=get_completion",
        "“法国的首都是什么？”，希望它能给我一个好结果。",
        "现在关于大型语言模型的描述，到目前为止，我谈论的是",
        "一次预测一个单词，但实际上还有一个更重要的技术细节。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "86",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 47,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 54,
            "milliseconds": 980
          },
          "text": "If you were to tell it \"Take the letters in the word lollipop and reverse them\"."
        },
        {
          "id": "87",
          "startTime": {
            "hours": 0,
            "minutes": 6,
            "seconds": 54,
            "milliseconds": 980
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 0,
            "milliseconds": 380
          },
          "text": "This seems like an easy task maybe like a four year old could do this task but if you"
        },
        {
          "id": "88",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 0,
            "milliseconds": 380
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 9,
            "milliseconds": 120
          },
          "text": "were to ask ChatGPT to do this it actually outputs a somewhat garbled whatever this is."
        },
        {
          "id": "89",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 9,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 14,
            "milliseconds": 100
          },
          "text": "This is not L-O-L-L-I-P-O-P this is not lollipop's letters reversed."
        },
        {
          "id": "90",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 14,
            "milliseconds": 100
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 19,
            "milliseconds": 620
          },
          "text": "So why is ChatGPT unable to do what seems like a relatively simple task."
        },
        {
          "id": "91",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 19,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 24,
            "milliseconds": 300
          },
          "text": "It turns out that there's one more important detail for how a large language model works"
        },
        {
          "id": "92",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 24,
            "milliseconds": 300
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 30,
            "milliseconds": 220
          },
          "text": "which is it doesn't actually repeatedly predict the next word it instead repeatedly predicts"
        },
        {
          "id": "93",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 30,
            "milliseconds": 220
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 36,
            "milliseconds": 720
          },
          "text": "the next token and what an LLM actually does is it will take a sequence of characters like"
        },
        {
          "id": "94",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 36,
            "milliseconds": 720
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 43,
            "milliseconds": 260
          },
          "text": "\"learning new things is fun\" and group the characters together to form tokens that comprise commonly"
        },
        {
          "id": "95",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 43,
            "milliseconds": 260
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 46,
            "milliseconds": 580
          },
          "text": "occurring sequences of characters."
        }
      ],
      "source": [
        "If you were to tell it \"Take the letters in the word lollipop and reverse them\".",
        "This seems like an easy task maybe like a four year old could do this task but if you",
        "were to ask ChatGPT to do this it actually outputs a somewhat garbled whatever this is.",
        "This is not L-O-L-L-I-P-O-P this is not lollipop's letters reversed.",
        "So why is ChatGPT unable to do what seems like a relatively simple task.",
        "It turns out that there's one more important detail for how a large language model works",
        "which is it doesn't actually repeatedly predict the next word it instead repeatedly predicts",
        "the next token and what an LLM actually does is it will take a sequence of characters like",
        "\"learning new things is fun\" and group the characters together to form tokens that comprise commonly",
        "occurring sequences of characters."
      ],
      "result": [
        "如果你让它“把单词lollipop中的字母倒过来”。",
        "这看起来像是一个简单的任务，也许一个四岁的孩子就能完成这个任务，但如果你",
        "让ChatGPT去做这个，它实际上输出的是一种有点乱七八糟的东西。",
        "这不是L-O-L-L-I-P-O-P，这不是lollipop的字母倒过来。",
        "那么为什么ChatGPT无法完成看似相对简单的任务呢。",
        "事实证明，大型语言模型的工作方式还有一个更重要的细节，",
        "那就是它实际上不是反复预测下一个单词，而是反复预测",
        "下一个标记（Token），而一个LLM实际上会做的是，它会接收一系列字符，比如",
        "“learning new things is fun”，并将字符组合在一起形成代表常见",
        "字符序列的标记。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "96",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 46,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 52,
            "milliseconds": 660
          },
          "text": "So here \"learning new things is fun\" each of them is a fairly common word and so each token"
        },
        {
          "id": "97",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 52,
            "milliseconds": 660
          },
          "endTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 57,
            "milliseconds": 980
          },
          "text": "corresponds to one word or one word in a space or an exclamation mark."
        },
        {
          "id": "98",
          "startTime": {
            "hours": 0,
            "minutes": 7,
            "seconds": 57,
            "milliseconds": 980
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 3,
            "milliseconds": 540
          },
          "text": "But if you were to give it input with some somewhat less frequently used words like \"Prompting"
        },
        {
          "id": "99",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 3,
            "milliseconds": 540
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 10,
            "milliseconds": 340
          },
          "text": "is powerful developer tool.\" the word \"Prompting\" is still not that common in the English language"
        },
        {
          "id": "100",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 10,
            "milliseconds": 340
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 14,
            "milliseconds": 900
          },
          "text": "but certainly gaining in popularity and so \"Prompting\" is actually broken down to three"
        },
        {
          "id": "101",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 14,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 21,
            "milliseconds": 340
          },
          "text": "tokens with prompt, pt and ing because those three are commonly occurring sequences of"
        },
        {
          "id": "102",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 21,
            "milliseconds": 340
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 27,
            "milliseconds": 220
          },
          "text": "letters and if you were to give it the word lollipop the tokenIsa actually breaks this"
        },
        {
          "id": "103",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 27,
            "milliseconds": 220
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 34,
            "milliseconds": 300
          },
          "text": "down into three tokens \"l\" and \"o\" and \"ipop\" and because ChatGPT isn't seeing the individual"
        },
        {
          "id": "104",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 34,
            "milliseconds": 300
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 40,
            "milliseconds": 200
          },
          "text": "letters is instead seeing these three tokens it's more difficult for it to correctly print"
        },
        {
          "id": "105",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 40,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 43,
            "milliseconds": 420
          },
          "text": "out these letters in reverse order."
        }
      ],
      "source": [
        "So here \"learning new things is fun\" each of them is a fairly common word and so each token",
        "corresponds to one word or one word in a space or an exclamation mark.",
        "But if you were to give it input with some somewhat less frequently used words like \"Prompting",
        "is a powerful developer tool.\", the word \"Prompting\" is still not that common in the English language",
        "but certainly gaining in popularity and so \"Prompting\" is actually broken down to three",
        "tokens with prompt, pt and ing because those three are commonly occurring sequences of",
        "letters and if you were to give it the word \"lollipop\" the tokenIsa actually breaks this",
        "down into three tokens \"l\" and \"o\" and \"ipop\" and because ChatGPT isn't seeing the individual",
        "letters is instead seeing these three tokens it's more difficult for it to correctly print",
        "out these letters in reverse order."
      ],
      "result": [
        "所以在这里“learning new things is fun”，每个都是相当常见的词，所以每个标记",
        "对应一个词或一个词的空格或感叹号。",
        "但是，如果你给它一些不太常用的词作为输入，比如“Prompting",
        "is a powerful developer tool.”对于开发者来说，Prompting这个词在英语中还不是那么常见",
        "但肯定越来越受欢迎，所以“Prompting”实际上被分解成三个",
        "标记，分别是\"prompt\"、\"pt\"和\"ing\"，因为这三个是常见的字母序列",
        "如果你给它一个“棒棒糖（lollipop）”这个词，分词器实际上把这个",
        "分成三个标记\"l\"、\"o\"和\"ipop\"，因为ChatGPT没有看到单独的",
        "字母，而是看到了这三个标记，所以要正确地按相反的顺序打印",
        "出这些字母就更困难了。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "106",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 43,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 52,
            "milliseconds": 540
          },
          "text": "So here's a trick you can use to fix this if I were to add dashes between these letters"
        },
        {
          "id": "107",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 52,
            "milliseconds": 540
          },
          "endTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 56,
            "milliseconds": 780
          },
          "text": "and spaces would work too or other things would work too and take the letters and lollipop"
        },
        {
          "id": "108",
          "startTime": {
            "hours": 0,
            "minutes": 8,
            "seconds": 56,
            "milliseconds": 780
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 3,
            "milliseconds": 100
          },
          "text": "and reverse them then it actually does a much better job this LOLLIPOP and the reason for"
        },
        {
          "id": "109",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 3,
            "milliseconds": 100
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 8,
            "milliseconds": 740
          },
          "text": "that is if you pass it lollipop with dashes in between the letters it tokenizes each of"
        },
        {
          "id": "110",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 8,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 14,
            "milliseconds": 140
          },
          "text": "these characters into an individual token making it easier for it to see the individual"
        },
        {
          "id": "111",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 14,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 17,
            "milliseconds": 140
          },
          "text": "letters and print them out in reverse order."
        },
        {
          "id": "112",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 17,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 23,
            "milliseconds": 180
          },
          "text": "So if you ever want to use ChatGPT to play a word game like wordle or scrap or something"
        },
        {
          "id": "113",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 23,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 29,
            "milliseconds": 460
          },
          "text": "this nifty trick helps it to better see the individual letters of the words."
        },
        {
          "id": "114",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 29,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 34,
            "milliseconds": 700
          },
          "text": "For the English language one token roughly on average corresponds to about four characters"
        },
        {
          "id": "115",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 34,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 40,
            "milliseconds": 980
          },
          "text": "or about three quarters of a word and so different large language models will often have different"
        },
        {
          "id": "116",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 40,
            "milliseconds": 980
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 45,
            "milliseconds": 780
          },
          "text": "limits on the number of input plus output tokens it can accept."
        }
      ],
      "source": [
        "So here's a trick you can use to fix this if I were to add dashes between these letters",
        "and spaces would work too or other things would work too and take the letters and lollipop",
        "and reverse them then it actually does a much better job this LOLLIPOP and the reason for",
        "that is if you pass it lollipop with dashes in between the letters it tokenizes each of",
        "these characters into an individual token making it easier for it to see the individual",
        "letters and print them out in reverse order.",
        "So if you ever want to use ChatGPT to play a word game like wordle or scrap or something",
        "this nifty trick helps it to better see the individual letters of the words.",
        "For the English language one token roughly on average corresponds to about four characters",
        "or about three quarters of a word and so different large language models will often have different",
        "limits on the number of input plus output tokens it can accept."
      ],
      "result": [
        "所以这里有一个技巧，如果我在这些字母之间加上破折号，",
        "空格也可以，或者其他东西也可以，然后把字母和棒棒糖拿过来",
        "反过来，它实际上做得更好，这个LOLLIPOP，原因是",
        "如果你用破折号把lollipop的字母隔开，它会把每一个",
        "这些字符分成一个个的标记，让它更容易看到单独的",
        "字母，然后按相反的顺序打印出来。",
        "所以如果你想用ChatGPT玩像wordle或scrap这样的单词游戏，",
        "这个巧妙的技巧有助于更好地看到单词的各个字母。",
        "对于英语，一个标记大致平均对应四个字符，",
        "或者大约三分之二个单词，所以不同的大型语言模型通常会有不同的",
        "关于它可以接受的输入加输出标记的数量限制。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "117",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 45,
            "milliseconds": 780
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 50,
            "milliseconds": 700
          },
          "text": "The input is often called the context and the output is often called the completion"
        },
        {
          "id": "118",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 50,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 56,
            "milliseconds": 700
          },
          "text": "and the model GPT 3.5 turbo for example the most commonly used ChatGPT model has a limit"
        },
        {
          "id": "119",
          "startTime": {
            "hours": 0,
            "minutes": 9,
            "seconds": 56,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 1,
            "milliseconds": 700
          },
          "text": "of roughly 4000 tokens in the input plus output."
        },
        {
          "id": "120",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 1,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 5,
            "milliseconds": 660
          },
          "text": "So if you try to feed it an input context that's much longer than this so actually throw"
        },
        {
          "id": "121",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 5,
            "milliseconds": 660
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 8,
            "milliseconds": 540
          },
          "text": "an exception or generate an error."
        },
        {
          "id": "122",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 8,
            "milliseconds": 540
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 17,
            "milliseconds": 460
          },
          "text": "Next I want to share with you another powerful way to use an LLM API which involves specifying"
        },
        {
          "id": "123",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 17,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 22,
            "milliseconds": 580
          },
          "text": "separate system user and assistant messages."
        },
        {
          "id": "124",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 22,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 29,
            "milliseconds": 900
          },
          "text": "Let me show you an example then we can explain in more detail what it's actually doing."
        },
        {
          "id": "125",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 29,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 35,
            "milliseconds": 660
          },
          "text": "Here's a new helper function called get completion from messages and when we prompt this LLM"
        },
        {
          "id": "126",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 35,
            "milliseconds": 660
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 39,
            "milliseconds": 460
          },
          "text": "we are going to give it multiple messages."
        }
      ],
      "source": [
        "The input is often called the context and the output is often called the completion",
        "and the model GPT 3.5 turbo for example the most commonly used ChatGPT model has a limit",
        "of roughly 4000 tokens in the input plus output.",
        "So if you try to feed it an input context that's much longer than this so actually throw",
        "an exception or generate an error.",
        "Next I want to share with you another powerful way to use an LLM API which involves specifying",
        "separate system user and assistant messages.",
        "Let me show you an example then we can explain in more detail what it's actually doing.",
        "Here's a new helper function called get completion from messages and when we prompt this LLM",
        "we are going to give it multiple messages."
      ],
      "result": [
        "输入通常被称为上下文（context），输出通常被称为补全（completion）",
        "例如，最常用的ChatGPT模型GPT-3.5 Turbo在输入和输出中的限制",
        "大约是4000个标记。",
        "所以，如果你尝试输入一个超过这个长度的上下文，它实际上会抛出",
        "一个异常或产生一个错误。",
        "接下来，我想和你分享另一种使用LLM API的强大方法，它涉及指定",
        "独立的系统（system）、用户（user）和助手（assistant）消息。",
        "让我给你展示一个例子，然后我们可以更详细地解释它实际上在做什么。",
        "这里有一个新的辅助函数，叫做从消息中获取补全，当我们提示这个LLM时",
        "我们将给它提供多条消息。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "127",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 39,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 42,
            "milliseconds": 500
          },
          "text": "Here's an example of what you can do."
        },
        {
          "id": "128",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 42,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 49,
            "milliseconds": 860
          },
          "text": "I'm going to specify first a message in the role of a system so this assistant message"
        },
        {
          "id": "129",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 49,
            "milliseconds": 860
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 54,
            "milliseconds": 500
          },
          "text": "and the content of the system message is you're an assistant who responds in the style of"
        },
        {
          "id": "130",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 54,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 55,
            "milliseconds": 500
          },
          "text": "Dr. Seuss."
        },
        {
          "id": "131",
          "startTime": {
            "hours": 0,
            "minutes": 10,
            "seconds": 56,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 0,
            "milliseconds": 700
          },
          "text": "Then I'm going to specify a user message so the role of the second message is role"
        },
        {
          "id": "132",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 0,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 7,
            "milliseconds": 180
          },
          "text": "user and the content of this is write me a very short poem about a happy carrot."
        },
        {
          "id": "133",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 7,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 12,
            "milliseconds": 340
          },
          "text": "And so let's run that and with temperature equals one I actually never know what's going"
        },
        {
          "id": "134",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 12,
            "milliseconds": 340
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 14,
            "milliseconds": 740
          },
          "text": "to come out but okay that's a cool poem."
        },
        {
          "id": "135",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 14,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 19,
            "milliseconds": 580
          },
          "text": "\"Oh how jolly is this carrot that I see\" and it actually runs pretty well."
        },
        {
          "id": "136",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 19,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 22,
            "milliseconds": 420
          },
          "text": "All right well done ChatGPT."
        }
      ],
      "source": [
        "Here's an example of what you can do.",
        "I'm going to specify first a message in the role of a system so this assistant message",
        "and the content of the system message is you're an assistant who responds in the style of",
        "Dr. Seuss.",
        "Then I'm going to specify a user message so the role of the second message is role",
        "user and the content of this is \"write me a very short poem about a happy carrot.\"",
        "And so let's run that and with temperature equals one I actually never know what's going",
        "to come out but okay that's a cool poem.",
        "\"Oh how jolly is this carrot that I see\" and it actually runs pretty well.",
        "All right well done ChatGPT."
      ],
      "result": [
        "这是一个你可以做的例子。",
        "首先，我将以系统的角色指定一条信息，以便这个助手信息",
        "系统信息的内容是，你是一个以苏斯博士的风格回应的助手。",
        "",
        "然后我将指定一个用户信息，所以第二条信息的角色是用户，",
        "而这个内容是“给我写一首关于快乐胡萝卜的非常短的诗。”",
        "所以让我们运行这个，温度（Temperature）参数设置为1，我实际上永远不知道会出现什么",
        "但好吧，这是一首很酷的诗。",
        "“哦，我看到的这根胡萝卜是多么快乐”，而且它实际上运行得相当好。",
        "好吧，干得好ChatGPT。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "137",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 22,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 30,
            "milliseconds": 380
          },
          "text": "And so in this example the system message specifies the overall tone of what you want"
        },
        {
          "id": "138",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 30,
            "milliseconds": 380
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 35,
            "milliseconds": 500
          },
          "text": "the large language model to do and the user message is a specific instruction that you"
        },
        {
          "id": "139",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 35,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 40,
            "milliseconds": 900
          },
          "text": "wanted to carry out given this higher level behavior that was specified in the system"
        },
        {
          "id": "140",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 40,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 41,
            "milliseconds": 900
          },
          "text": "message."
        },
        {
          "id": "141",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 41,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 46,
            "milliseconds": 120
          },
          "text": "Here's an illustration of how it all works."
        },
        {
          "id": "142",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 46,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 51,
            "milliseconds": 700
          },
          "text": "So this is how the chat format works."
        },
        {
          "id": "143",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 51,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 57,
            "milliseconds": 100
          },
          "text": "The system message sets the overall tone of behavior of the large language model or the"
        },
        {
          "id": "144",
          "startTime": {
            "hours": 0,
            "minutes": 11,
            "seconds": 57,
            "milliseconds": 100
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 3,
            "milliseconds": 140
          },
          "text": "assistant and then when you give the user message such as maybe such as a tell me a"
        },
        {
          "id": "145",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 3,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 10,
            "milliseconds": 860
          },
          "text": "joke or write me a poem it will then output an appropriate response following what you"
        },
        {
          "id": "146",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 10,
            "milliseconds": 860
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 16,
            "milliseconds": 540
          },
          "text": "asked for in the user message and consistent with the overall behavior set in the system"
        },
        {
          "id": "147",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 16,
            "milliseconds": 540
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 19,
            "milliseconds": 220
          },
          "text": "message."
        }
      ],
      "source": [
        "And so in this example the system message specifies the overall tone of what you want",
        "the large language model to do and the user message is a specific instruction that you",
        "wanted to carry out given this higher level behavior that was specified in the system",
        "message.",
        "Here's an illustration of how it all works.",
        "So this is how the chat format works.",
        "The system message sets the overall tone of behavior of the large language model or the",
        "assistant and then when you give the user message such as maybe such as a tell me a",
        "joke or write me a poem it will then output an appropriate response following what you",
        "asked for in the user message and consistent with the overall behavior set in the system",
        "message."
      ],
      "result": [
        "所以在这个例子中，系统消息指定了你想要的",
        "大语言模型的整体语言风格，而用户消息是一个具体的指令，",
        "你希望在系统中执行这个更高级别的行为消息。",
        "",
        "这里有一个说明它是如何工作的例子。",
        "所以这就是聊天格式的工作原理。",
        "系统消息设定了大型语言模型或",
        "助手的整体行为风格，然后当你给出用户消息，比如说“给我",
        "讲个笑话或者写首诗”，它会根据你在用户消息中要求的内容，",
        "以及在系统消息中设定的整体行为风格，输出一个合适的回应。",
        ""
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "148",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 19,
            "milliseconds": 220
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 24,
            "milliseconds": 500
          },
          "text": "And by the way although I'm not illustrating it here if you want to use this in a multi-term"
        },
        {
          "id": "149",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 24,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 33,
            "milliseconds": 140
          },
          "text": "conversation you can also input assistant messages in this messages format to let ChatGPT"
        },
        {
          "id": "150",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 33,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 38,
            "milliseconds": 860
          },
          "text": "know what it had previously said if you wanted to continue the conversation based on things"
        },
        {
          "id": "151",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 38,
            "milliseconds": 860
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 41,
            "milliseconds": 820
          },
          "text": "that had previously said as well."
        },
        {
          "id": "152",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 41,
            "milliseconds": 820
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 45,
            "milliseconds": 180
          },
          "text": "But here are a few more examples."
        },
        {
          "id": "153",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 45,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 52,
            "milliseconds": 340
          },
          "text": "If you want to set the tone to tell it to have a one sentence long output then in the"
        },
        {
          "id": "154",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 52,
            "milliseconds": 340
          },
          "endTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 58,
            "milliseconds": 460
          },
          "text": "system message I can say all your responses must be one sentence long and when I execute"
        },
        {
          "id": "155",
          "startTime": {
            "hours": 0,
            "minutes": 12,
            "seconds": 58,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 3,
            "milliseconds": 540
          },
          "text": "this it outputs a single sentence is no longer a poem not in the style of Dr. Seuss but this"
        },
        {
          "id": "156",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 3,
            "milliseconds": 540
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 10,
            "milliseconds": 60
          },
          "text": "is a single sentence that's a story about the happy carrot."
        },
        {
          "id": "157",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 10,
            "milliseconds": 60
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 17,
            "milliseconds": 620
          },
          "text": "And if we want to combine both specify the style and the length then I can use the system"
        },
        {
          "id": "158",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 17,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 22,
            "milliseconds": 20
          },
          "text": "message to say in the system response to style Dr. Seuss all your sentences must be one sentence"
        },
        {
          "id": "159",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 22,
            "milliseconds": 20
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 32,
            "milliseconds": 860
          },
          "text": "long and now this generates a nice one sentence poem that was always smiling and never scary."
        }
      ],
      "source": [
        "And by the way although I'm not illustrating it here if you want to use this in a multi-term",
        "conversation you can also input assistant messages in this messages format to let ChatGPT",
        "know what it had previously said if you wanted to continue the conversation based on things",
        "that had previously said as well.",
        "But here are a few more examples.",
        "If you want to set the tone to tell it to have a one sentence long output then in the",
        "system message I can say all your responses must be one sentence long and when I execute",
        "this it outputs a single sentence is no longer a poem not in the style of Dr. Seuss but this",
        "is a single sentence that's a story about the happy carrot.",
        "And if we want to combine both specify the style and the length then I can use the system",
        "message to say in the system response to style Dr. Seuss all your sentences must be one sentence",
        "long and now this generates a nice one sentence poem that was always smiling and never scary."
      ],
      "result": [
        "顺便说一下，虽然我没有在这里展示，但如果你想在多轮对话中",
        "使用这个功能，你也可以用这种消息格式输入助手消息，让ChatGPT",
        "了解它之前说过什么，如果你想根据之前的对话继续对话的话。",
        "",
        "但是这里有更多的例子。",
        "如果你想设置语言风格，告诉它输出一句话，那么在",
        "系统消息中，我可以说你的所有回答都必须是一句话长，当我执行",
        "这个操作时，它输出的一句话不再是诗歌，也不是苏斯博士的风格，但这",
        "是一句关于快乐胡萝卜的故事。",
        "如果我们想同时指定风格和长度，那么我可以使用系统消息，",
        "在系统回应中说，以苏斯博士的风格，你的所有句子都必须是一句话长，",
        "现在这生成了一个很好的一句话诗歌，总是微笑，从不可怕。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "160",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 32,
            "milliseconds": 860
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 35,
            "milliseconds": 740
          },
          "text": "I like that that's a very happy poem."
        },
        {
          "id": "161",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 35,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 42,
            "milliseconds": 780
          },
          "text": "And then lastly just for fun if you are using an LLM and you want to know how many tokens"
        },
        {
          "id": "162",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 42,
            "milliseconds": 780
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 49,
            "milliseconds": 20
          },
          "text": "are you using here's a helper function that is a little bit more sophisticated in that"
        },
        {
          "id": "163",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 49,
            "milliseconds": 20
          },
          "endTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 57,
            "milliseconds": 500
          },
          "text": "it gets a response from the OpenAI API endpoint and then it uses other values in the response"
        },
        {
          "id": "164",
          "startTime": {
            "hours": 0,
            "minutes": 13,
            "seconds": 57,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 3,
            "milliseconds": 260
          },
          "text": "to tell you how many prompt tokens completion tokens and total tokens were used in your"
        },
        {
          "id": "165",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 3,
            "milliseconds": 260
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 5,
            "milliseconds": 60
          },
          "text": "API call."
        },
        {
          "id": "166",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 5,
            "milliseconds": 60
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 19,
            "milliseconds": 260
          },
          "text": "Let me define that and if I run this now here's the response and here is a count of how many"
        },
        {
          "id": "167",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 19,
            "milliseconds": 260
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 20,
            "milliseconds": 620
          },
          "text": "tokens we use."
        },
        {
          "id": "168",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 20,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 27,
            "milliseconds": 980
          },
          "text": "So this output which had 55 tokens whereas the prompt input had 37 tokens so this used"
        },
        {
          "id": "169",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 27,
            "milliseconds": 980
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 31,
            "milliseconds": 740
          },
          "text": "up 92 tokens altogether."
        }
      ],
      "source": [
        "I like that that's a very happy poem.",
        "And then lastly just for fun if you are using an LLM and you want to know how many tokens",
        "are you using here's a helper function that is a little bit more sophisticated in that",
        "it gets a response from the OpenAI API endpoint and then it uses other values in the response",
        "to tell you how many prompt tokens completion tokens and total tokens were used in your",
        "API call.",
        "Let me define that and if I run this now here's the response and here is a count of how many",
        "tokens we use.",
        "So this output which had 55 tokens whereas the prompt input had 37 tokens so this used",
        "up 92 tokens altogether."
      ],
      "result": [
        "我喜欢这是一首非常快乐的诗。",
        "然后最后，只是为了好玩，如果你在使用LLM，想知道有多少个tokens",
        "你在这里使用了一个稍微复杂一点的辅助函数。",
        "它从OpenAI API获取响应，然后使用响应中的其他值",
        "告诉你在你的API调用中使用了多少“prompt tokens”、“completion tokens”和“total tokens”。",
        "",
        "让我定义一下，如果我现在运行这个，这是响应，这是一个关于我们使用了多少个",
        "tokens的计数。",
        "所以这个输出有55个tokens，而提示输入有37个tokens，所以这个",
        "一共使用了92个tokens。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "170",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 31,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 36,
            "milliseconds": 260
          },
          "text": "When I'm using LLM models in practice I don't worry that much frankly about the number of"
        },
        {
          "id": "171",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 36,
            "milliseconds": 260
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 38,
            "milliseconds": 740
          },
          "text": "tokens I'm using."
        },
        {
          "id": "172",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 38,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 42,
            "milliseconds": 420
          },
          "text": "Maybe one case where it might be worth checking the number of tokens is if you're worried"
        },
        {
          "id": "173",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 42,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 48,
            "milliseconds": 100
          },
          "text": "that the user might have given you too long an input that exceeds the 4000 or so token"
        },
        {
          "id": "174",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 48,
            "milliseconds": 100
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 52,
            "milliseconds": 940
          },
          "text": "limits of ChatGPT in which case you could double check how many tokens it was and truncate"
        },
        {
          "id": "175",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 52,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 58,
            "milliseconds": 380
          },
          "text": "it to make sure you're staying within the input token limits of the large language model."
        },
        {
          "id": "176",
          "startTime": {
            "hours": 0,
            "minutes": 14,
            "seconds": 58,
            "milliseconds": 380
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 4,
            "milliseconds": 780
          },
          "text": "Now I want to share with you one more tip for how to use a large language model."
        },
        {
          "id": "177",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 4,
            "milliseconds": 780
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 10,
            "milliseconds": 900
          },
          "text": "Calling the OpenAI API requires using an API key that's tied to either a free or a"
        },
        {
          "id": "178",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 10,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 17,
            "milliseconds": 940
          },
          "text": "paid account and so many developers will write the API key in plain text like this into their"
        },
        {
          "id": "179",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 17,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 26,
            "milliseconds": 460
          },
          "text": "Jupyter notebook and this is a less secure way of using API keys that I would not recommend"
        },
        {
          "id": "180",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 26,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 32,
            "milliseconds": 580
          },
          "text": "you use because it's just too easy to share this notebook with someone else or check this"
        },
        {
          "id": "181",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 32,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 38,
            "milliseconds": 700
          },
          "text": "into GitHub or something and thus end up leaking your API key to someone else."
        }
      ],
      "source": [
        "When I'm using LLM models in practice I don't worry that much frankly about the number of",
        "tokens I'm using.",
        "Maybe one case where it might be worth checking the number of tokens is if you're worried",
        "that the user might have given you too long an input that exceeds the 4000 or so token",
        "limits of ChatGPT in which case you could double check how many tokens it was and truncate",
        "it to make sure you're staying within the input token limits of the large language model.",
        "Now I want to share with you one more tip for how to use a large language model.",
        "Calling the OpenAI API requires using an API key that's tied to either a free or a",
        "paid account and so many developers will write the API key in plain text like this into their",
        "Jupyter Notebook and this is a less secure way of using API keys that I would not recommend",
        "you use because it's just too easy to share this notebook with someone else or check this",
        "into GitHub or something and thus end up leaking your API key to someone else."
      ],
      "result": [
        "当我在实践中使用LLM模型时，我实际上并不太担心我使用的tokens数量。",
        "",
        "也许在一个情况下，检查tokens数量是值得的，那就是如果你担心",
        "用户可能给你太长的输入，超过了4000个左右的tokens",
        "ChatGPT的限制，在这种情况下，你可以仔细检查一下tokens数量并截断",
        "它以确保你在大型语言模型的输入tokens限制范围内。",
        "现在我想和你分享如何使用大型语言模型的另一个技巧。",
        "调用OpenAI API需要使用与免费或付费账户绑定的API密钥，",
        "因此许多开发者会像这样将API密钥以纯文本形式写入他们的",
        "Jupyter Notebook，这是一种使用API密钥的不太安全的方式，我不建议",
        "你使用，因为这样太容易与他人共享这个Notebook或将其检查到",
        "GitHub或其他地方，从而泄露你的API密钥给其他人。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "182",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 38,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 46,
            "milliseconds": 140
          },
          "text": "In contrast what you saw me do in the Jupyter notebook was this piece of code where I use"
        },
        {
          "id": "183",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 46,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 52,
            "milliseconds": 900
          },
          "text": "a library dotenv and then run this command load dotenv find dotenv to read a local"
        },
        {
          "id": "184",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 52,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 58,
            "milliseconds": 660
          },
          "text": "file which is called dotenv that contains my secret key."
        },
        {
          "id": "185",
          "startTime": {
            "hours": 0,
            "minutes": 15,
            "seconds": 58,
            "milliseconds": 660
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 4,
            "milliseconds": 420
          },
          "text": "And so with this code snippet I have locally stored a file called dotenv that contains"
        },
        {
          "id": "186",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 4,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 13,
            "milliseconds": 140
          },
          "text": "my API key and this loads it into the operating systems environmental variable and then os.get"
        },
        {
          "id": "187",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 13,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 21,
            "milliseconds": 180
          },
          "text": "env, OpenAI API key stores it into this variable and in this whole process I don't ever have"
        },
        {
          "id": "188",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 21,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 27,
            "milliseconds": 20
          },
          "text": "to enter the API key in plain text in unencrypted plain text into my Jupyter notebook."
        },
        {
          "id": "189",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 27,
            "milliseconds": 20
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 33,
            "milliseconds": 380
          },
          "text": "So this is a relatively more secure and a better way to access the API key and in fact"
        },
        {
          "id": "190",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 33,
            "milliseconds": 380
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 39,
            "milliseconds": 420
          },
          "text": "this is a general method for storing different API keys from lots of different online services"
        },
        {
          "id": "191",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 39,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 44,
            "milliseconds": 180
          },
          "text": "that you might want to use and call from your Jupyter notebook."
        }
      ],
      "source": [
        "In contrast what you saw me do in the Jupyter notebook was this piece of code where I use",
        "a library dotenv and then run this command load dotenv find dotenv to read a local",
        "file which is called dotenv that contains my secret key.",
        "And so with this code snippet I have locally stored a file called .env that contains",
        "my API key and this loads it into the operating systems environmental variable and then os.getenv,",
        "OPENAI_API_KEY stores it into this variable and in this whole process I don't ever have",
        "to enter the API key in plain text in unencrypted plain text into my Jupyter notebook.",
        "So this is a relatively more secure and a better way to access the API key and in fact",
        "this is a general method for storing different API keys from lots of different online services",
        "that you might want to use and call from your Jupyter notebook."
      ],
      "result": [
        "相比之下，你在 Jupyter Notebook中看到我做的是这段代码，我使用",
        "一个库 dotenv，然后运行这个命令 load dotenv find dotenv 来读取一个本地",
        "文件，叫做 .env，里面包含了我的密钥。",
        "所以通过这段代码片段，我在本地存储了一个名为 .env 的文件，其中包含",
        "我的 API 密钥，然后将其加载到操作系统的环境变量中，然后 os.getenv，",
        "OPENAI_API_KEY将其存储到这个变量中，在整个过程中，我不需要将",
        "API 密钥以明文形式输入到我的 Jupyter Notebook中。",
        "所以这是一个相对更安全、更好的访问 API 密钥的方法，实际上",
        "这是一种用于存储来自许多不同在线服务的不同 API 密钥的通用方法",
        "你可能想要使用并从你的 Jupyter Notebook中调用。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "192",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 44,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 51,
            "milliseconds": 580
          },
          "text": "The- I think the degree to which prompting is revolutionizing AI application development"
        },
        {
          "id": "193",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 51,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 54,
            "milliseconds": 220
          },
          "text": "is still underappreciated."
        },
        {
          "id": "194",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 54,
            "milliseconds": 220
          },
          "endTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 58,
            "milliseconds": 900
          },
          "text": "In the traditional supervised machine learning workflow like the restaurant review sentiment"
        },
        {
          "id": "195",
          "startTime": {
            "hours": 0,
            "minutes": 16,
            "seconds": 58,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 3,
            "milliseconds": 340
          },
          "text": "classification example that I touched on just now, if you want to build a classifier to"
        },
        {
          "id": "196",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 3,
            "milliseconds": 340
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 7,
            "milliseconds": 900
          },
          "text": "classify restaurant review positive or negative sentiments you at first get a bunch of label"
        },
        {
          "id": "197",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 7,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 13,
            "milliseconds": 200
          },
          "text": "data maybe hundreds of examples this might take I don't know weeks maybe a month then"
        },
        {
          "id": "198",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 13,
            "milliseconds": 200
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 18,
            "milliseconds": 620
          },
          "text": "you would train a model on data and getting an appropriate open source model tuning on"
        },
        {
          "id": "199",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 18,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 25,
            "milliseconds": 540
          },
          "text": "the model evaluating it that might take days weeks maybe even a few months and then you"
        },
        {
          "id": "200",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 25,
            "milliseconds": 540
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 31,
            "milliseconds": 140
          },
          "text": "might have to find a cloud service to deploy it and then get your model uploaded to the"
        },
        {
          "id": "201",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 31,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 34,
            "milliseconds": 940
          },
          "text": "cloud and then run the model and finally be able to call your model and again not"
        },
        {
          "id": "202",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 34,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 39,
            "milliseconds": 820
          },
          "text": "uncommon for this to take a team a few months to get working."
        }
      ],
      "source": [
        "The- I think the degree to which prompting is revolutionizing AI application development",
        "is still underappreciated.",
        "In the traditional supervised machine learning workflow like the restaurant review sentiment",
        "classification example that I touched on just now, if you want to build a classifier to",
        "classify restaurant review positive or negative sentiments you at first get a bunch of label",
        "data maybe hundreds of examples this might take I don't know weeks maybe a month then",
        "you would train a model on data and getting an appropriate open source model tuning on",
        "the model evaluating it that might take days weeks maybe even a few months and then you",
        "might have to find a cloud service to deploy it and then get your model uploaded to the",
        "cloud and then run the model and finally be able to call your model and again it's not",
        "uncommon for this to take a team a few months to get working."
      ],
      "result": [
        "我认为，提示（prompting）正在革新AI应用开发的程度，仍然被低估了。",
        "",
        "在传统的监督式机器学习工作流中，就像我刚才提到的餐厅评论好评/差评分类",
        "的例子，如果你想建立一个分类器来",
        "分类餐厅评论的正面或负面情感，你首先需要获得一堆标签数据，",
        "也许是几百个例子，这可能需要几周，也许一个月。然后，",
        "你会在数据上训练一个模型，获取一个合适的开源模型，",
        "对模型进行调优，评估模型，这可能需要几天、几周甚至几个月的时间。接下来，",
        "您可能需要找到一个云服务来部署它，然后将模型上传到云端，",
        "然后运行模型，最后才能调用你的模型。再说，这种情况并不少见，",
        "这可能需要一个团队几个月的时间才能完成。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "203",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 39,
            "milliseconds": 820
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 46,
            "milliseconds": 900
          },
          "text": "In contrast with prompting based machine learning when you have a text application you can specify"
        },
        {
          "id": "204",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 46,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 51,
            "milliseconds": 780
          },
          "text": "a prompt this can take minutes maybe hours if you need to iterate a few times to get"
        },
        {
          "id": "205",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 51,
            "milliseconds": 780
          },
          "endTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 59,
            "milliseconds": 880
          },
          "text": "an effective prompt and then in hours maybe at most days but frankly more often hours"
        },
        {
          "id": "206",
          "startTime": {
            "hours": 0,
            "minutes": 17,
            "seconds": 59,
            "milliseconds": 880
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 5,
            "milliseconds": 880
          },
          "text": "you can have this running using API calls and start making calls to the model and once"
        },
        {
          "id": "207",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 5,
            "milliseconds": 880
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 11,
            "milliseconds": 480
          },
          "text": "you've done that in just again maybe minutes or hours you can start calling the model and"
        },
        {
          "id": "208",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 11,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 17,
            "milliseconds": 280
          },
          "text": "start making inferences and so there are applications that used to take me maybe six months or a"
        },
        {
          "id": "209",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 17,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 22,
            "milliseconds": 840
          },
          "text": "year to build that you can now build in minutes or hours maybe very small numbers of days"
        },
        {
          "id": "210",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 22,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 29,
            "milliseconds": 120
          },
          "text": "using prompting and this is revolutionizing what AI applications can be built quickly."
        },
        {
          "id": "211",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 29,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 34,
            "milliseconds": 680
          },
          "text": "One important caveat this applies to many unstructured data applications including specifically"
        },
        {
          "id": "212",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 34,
            "milliseconds": 680
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 40,
            "milliseconds": 600
          },
          "text": "text applications and maybe increasingly vision applications although the vision technology"
        },
        {
          "id": "213",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 40,
            "milliseconds": 600
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 44,
            "milliseconds": 520
          },
          "text": "is much less mature right now but it's kind of getting there."
        }
      ],
      "source": [
        "In contrast with prompting based machine learning when you have a text application you can specify",
        "a prompt this can take minutes maybe hours if you need to iterate a few times to get",
        "an effective prompt and then in hours maybe at most days but frankly more often hours",
        "you can have this running using API calls and start making calls to the model and once",
        "you've done that in just again maybe minutes or hours you can start calling the model and",
        "start making inferences and so there are applications that used to take me maybe six months or a",
        "year to build that you can now build in minutes or hours maybe very small numbers of days",
        "using prompting and this is revolutionizing what AI applications can be built quickly.",
        "One important caveat this applies to many unstructured data applications including specifically",
        "text applications and maybe increasingly vision applications although the vision technology",
        "is much less mature right now but it's kind of getting there."
      ],
      "result": [
        "与基于提示的机器学习相比，当你有一个文本应用程序时，你可以指定",
        "一个提示，这可能需要几分钟甚至几个小时，如果你需要迭代几次才能得到",
        "一个有效的提示，然后在几个小时甚至最多几天内，但坦率地说，更多的是几个小时",
        "你可以使用API调用来运行这个程序，并开始调用模型，一旦",
        "你完成了这个过程，可能只需要几分钟或几个小时，你就可以开始调用模型并",
        "开始进行推断，所以有些应用程序过去可能需要我花费六个月甚至一",
        "年的时间来构建，现在你可以在几分钟或几小时内，甚至很少的几天内",
        "使用提示来构建，这正在彻底改变可以快速构建的AI应用程序。",
        "一个重要的注意事项是，这适用于许多非结构化数据应用，包括特别是",
        "文本应用程序，也许越来越多的视觉应用程序，尽管视觉技术",
        "目前还不够成熟，但它正在朝这个方向发展。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "214",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 44,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 49,
            "milliseconds": 520
          },
          "text": "This recipe doesn't really work for structured data applications meaning machine learning"
        },
        {
          "id": "215",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 49,
            "milliseconds": 520
          },
          "endTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 54,
            "milliseconds": 840
          },
          "text": "applications on tabular data with lots of numerical values in the Excel spreadsheet"
        },
        {
          "id": "216",
          "startTime": {
            "hours": 0,
            "minutes": 18,
            "seconds": 54,
            "milliseconds": 840
          },
          "endTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 1,
            "milliseconds": 120
          },
          "text": "say but for applications to which this does apply the fact that AI components can be built"
        },
        {
          "id": "217",
          "startTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 1,
            "milliseconds": 120
          },
          "endTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 7,
            "milliseconds": 480
          },
          "text": "so quickly is changing the workflow of how the entire system might be built."
        },
        {
          "id": "218",
          "startTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 7,
            "milliseconds": 480
          },
          "endTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 11,
            "milliseconds": 80
          },
          "text": "Building entire system might still take days or weeks or something but at least this piece"
        },
        {
          "id": "219",
          "startTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 11,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 16,
            "milliseconds": 880
          },
          "text": "of it can be done much faster and so with that let's go on to the next video where Isa"
        },
        {
          "id": "220",
          "startTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 16,
            "milliseconds": 880
          },
          "endTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 24,
            "milliseconds": 400
          },
          "text": "will show how to use these components to evaluate the input to a customer service assistant"
        },
        {
          "id": "221",
          "startTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 24,
            "milliseconds": 400
          },
          "endTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 29,
            "milliseconds": 40
          },
          "text": "and this will be part of a bigger example that you see developed through this course"
        },
        {
          "id": "222",
          "startTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 29,
            "milliseconds": 40
          },
          "endTime": {
            "hours": 0,
            "minutes": 19,
            "seconds": 33,
            "milliseconds": 760
          },
          "text": "for building a customer service assistant for an online retailer."
        }
      ],
      "source": [
        "This recipe doesn't really work for structured data applications meaning machine learning",
        "applications on tabular data with lots of numerical values in the Excel spreadsheet",
        "say but for applications to which this does apply the fact that AI components can be built",
        "so quickly is changing the workflow of how the entire system might be built.",
        "Building entire system might still take days or weeks or something but at least this piece",
        "of it can be done much faster and so with that let's go on to the next video where Isa",
        "will show how to use these components to evaluate the input to a customer service assistant",
        "and this will be part of a bigger example that you see developed through this course",
        "for building a customer service assistant for an online retailer."
      ],
      "result": [
        "这个方法对于结构化数据应用（即机器学习）并不十分适用，",
        "在Excel表格中有大量数值的表格数据应用上，",
        "但对于适用的应用来说，AI组件可以快速构建的事实，",
        "正在改变整个系统可能构建的工作流程。",
        "构建整个系统可能仍然需要几天或几周的时间，但至少这部分",
        "可以更快地完成，所以让我们继续下一个视频，Isa将展示",
        "如何使用这些组件来评估客户服务助手的输入，",
        "这将是一个更大示例的一部分，您将在本课程中看到",
        "如何为在线零售商构建一个客户服务助手。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    }
  ],
  "sourcePath": "input/Building Systems with the ChatGPT API/sc-openai-c2-L1-vid2_1.srt",
  "ouputBasePath": "input/Building Systems with the ChatGPT API/sc-openai-c2-L1-vid2_1",
  "totalCost": 0.48411000000000004,
  "translationPath": "input/Building Systems with the ChatGPT API/sc-openai-c2-L1-vid2_1/translation.json"
}
