嗨，我叫Kyle Steckler，我是Google Cloud高级解决方案实验室团队的机器学习工程师。
在这次演讲中，我们将深入介绍图像生成的入门知识。
具体来说，我将介绍扩散模型，
这是近期在图像生成领域表现出巨大潜力的一类模型。
话虽如此，图像生成一直是一个颇受关注的领域，
你可能听说过许多有趣的方法。
现在，虽然已经实施了许多图像生成的方法，
但随着时间的推移，最有前景的一些方法已经被模型家族所采用，比如变分自编码器，
它们将图像编码到一个压缩的大小，
然后解码回原始大小，同时学习数据本身的分布。
生成对抗模型，或者说GANs，也非常受欢迎。
这些模型真的很有趣。
它们实际上是让两个神经网络相互对抗。
一个神经网络（生成器）创建图像，
另一个神经网络（鉴别器）预测图像是真是假。
随着时间的推移，鉴别器在区分真假方面越来越好，
生成器在创造逼真的假图像方面也越来越好。
你可能听说过“深度伪造(Deepfake)”这个术语。
最后，自回归模型。
这些模型将图像视为像素序列来生成。
现代的自回归模型实际上从大型语言模型(LLMs)处理文本的方式中汲取了大量灵感。

非常有趣。
在这次讲座中，这就是我们真正要关注的内容。
这是较新的图像生成模型家族之一。
那就是扩散模型。
扩散模型的灵感来源于物理学，特别是热力学。
虽然它们最初是在2015年为图像生成引入的，
但这个想法真正流行起来还是花了好几年时间。
然而，在过去的几年里，从2020年到现在，
我们在研究领域和现今的工业领域，都看到了扩散模型的大量增长。

可能你熟悉的许多最先进的图像生成系统都是由扩散模型支持的。
扩散模型在许多不同的使用场景中都展现出了潜力。
无条件的扩散模型，即模型没有额外的输入或指令，
可以从特定事物的图像中进行训练，比如你可以在这里的幻灯片中看到的脸，
它将学习生成新的图像。
无条件生成的另一个例子是超分辨率，
它在提高低质量图像的清晰度方面非常强大。
还有条件生成模型，
这些模型为我们提供了像从文本提示（Prompt）生成图像的文本到图像，
还有其他像图像修复和文本引导的图像到图像等功能，我们可以在图像上删除或添加内容。
我们可以编辑图像本身。
现在，让我们更深入地探讨一下扩散模型，看看这些东西到底是如何工作的。
如幻灯片上所示，
基本的思想是通过迭代的前向扩散过程，系统地、慢慢地破坏数据分布中的结构。
实际上，这将是对图像进行迭代噪声添加。
然后我们学习一个反向扩散过程，恢复数据中的结构，
产生一个高度灵活且易于处理的数据生成模型。
换句话说，我们可以迭代地向图像添加噪声，
然后我们可以训练一个模型，学习如何去噪图像，从而生成新的图像。
因此，我们的目标是让这个模型学会去噪，去除噪声。
那么从这个角度来看，我们可以从幻灯片的左边开始，从纯粹的噪声开始，
从这个纯粹的噪声中，我们可以有一个模型能够合成一个新的图像。
我知道这个幻灯片上有一些数学符号，所以让我稍微解释一下。
我们从一个大型的图像数据集开始。
但是让我们只选取一个图像，就像这里右边显示的那样。
好的，我们可以开始这个前向扩散过程，我们可以从x0（初始图像）到x1（加入一点噪声的初始图像）。
我们可以一次又一次地做这个过程，反复向初始图像添加更多的噪声。
我们称这个分布为q，它只依赖于前一步。
所以如果我们一次又一次地加入更多的噪声，我们需要思考我们要执行多少次这个操作。
而最初的研究论文做了1000次。
理想情况下，如果这个数字足够高，比如1000，到最后，我们应该达到纯噪声的状态。
到这个时候，初始图像中的所有结构都完全消失了。
我们只看到纯噪声。
显然，这是相对容易的部分。
执行q并不太困难，
只是逐步增加更多的噪声，
困难的部分是我们如何从一个噪声图像转变为一个稍微噪声较少的图像。
我们将这个过程称为反向扩散过程。
在这个阶段，我们每一步都要添加噪声，我们也都要学习反向扩散过程。
也就是说，我们训练一个机器学习模型，输入噪声图像，
并预测已经加入到图像中的噪声。
现在让我们从一个稍微不同的角度来看待这个问题。
我们可以在这里可视化模型的单个训练步骤。
所以我们在左边有初始图像x，并且在一个时间步骤中生成一个噪声图像。
然后我们将其输入我们的去噪模型，目标是预测噪声。
所以模型的输出就是预测的噪声。
但我们刚刚向这个图像添加了噪声。
我们知道它是什么。
我们实际上可以比较一下。
我们可以看看模型预测的噪声和我们实际添加的噪声之间的区别。
这个模型的训练方式类似于你可能熟悉的大多数机器学习模型，目标是最小化那个差异。
随着时间的推移，看过足够多的例子后，这个模型在去除图像噪声方面变得非常非常好。
现在来到有趣的部分。
这是真正酷的地方，我们需要思考一旦我们训练了这个模型，
我们如何用它生成图像？
实际上，这是非常直观的。
我们可以从纯粹的绝对噪声开始，然后将这个噪声送入我们训练过的模型。
然后我们取出输出，预测的噪声，并从初始噪声中减去它。
如果我们一次又一次地这样做，我们最终会得到一个生成的图像。
另一种思考方式是，
模型能够学习到它所看到的图像的真实数据分布，
然后从那个学习到的分布中采样，创建新的、独特的图像。
非常酷！
我相信我们都知道，在过去的几年里，这个领域有了许多进展。
尽管在 Vertex AI 中，许多令人兴奋的新图像生成技术都是以扩散模型为基础，
但我们已经做了大量的工作，使得图像生成更快，控制更精确。
希望现在，经过简单了解扩散模型如何工作的介绍后，
你对这些真正新颖、创新的模型类型有更好的理解。
我们也看到，将扩散模型的力量与大型语言模型（LLM）的力量相结合，可以带来出色的结果，
真正让我们能够根据文本提示（Prompt）生成具有上下文感知的、照片级真实的图像。
Google Research 的 Imagen 就是一个很好的例子。
虽然这比我们在这个环节中讨论的内容要复杂一些，
但你可以看到，它的核心是一个大型语言模型和几个基于扩散的模型的组合。
这是一个非常令人兴奋的领域，
我很高兴看到这项出色的技术正在被整合进 Vertex AI 的企业级产品中。
感谢你的聆听！