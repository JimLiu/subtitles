大家好。
我是谷歌高级解决方案实验室的机器学习工程师Takumi。

目前很多人都在谈论生成式AI及其新进展，

正如你们中的一些人可能知道的那样，谷歌和谷歌云也发布了很多与生成式AI相关的新产品和功能。


但在这个视频系列中，我们的目标不是创建我们的生成式AI的状态，也不是介绍谷歌云的新产品。


相反，我们将解释这背后有哪些技术。
特别是在这个视频中，我将讨论如何实际创建一个非常简单的生成模型，

使用诸如编码器解码器注意力机制和一点Transformer的技术来创建图像说明文字模型。

如果你对这些概念不是很熟悉，我建议在此之前查看其他关于它们的视频。


好的，
那么如果你准备好了，让我们来谈谈图像说明文字任务和数据集，
首先，我们将使用这种类型的数据集。
如你所见，这里有很多图像和文本数据配对，我们的目标是构建和训练一个模型，可以根据图像生成这种类型的说明文字。


我们将通过构建这种模型来实现这一目标。
如你所见，这是一种编码器解码器模型，但在这种情况下，编码器和解码器处理不同类型的数据，即图像和文本。

因此，我们首先将图像传递给编码器，它从图像中提取信息并创建一些特征向量。

然后，将向量传递给解码器，逐个生成字来构建说明文字。

这个编码器部分很简单。
你可以使用任何类型的图像骨干网络，如ResNet、EfficientNet或Vision Transformer。

我们想要做的是使用这些骨干网络来提取特征。
因此，代码也非常简单，在代码方面，我们将在下一个视频中查看整个笔记本示例。

所以在这里，让我们只关注一些重要的行。

如你所见，我们在这里使用了经典的InceptionResNetV2，来自Carousel应用程序。

但是，这可以是任何图像骨干网络。
接下来的部分有点复杂，让我们仔细看看。

这是解码器的整个架构。
它逐个获取，并将编码器输出中的词和图像信息进行组合，尝试预测下一个词。



解码器本身是一种迭代操作。
通过反复调用或回归，最终可以生成六条说明文字。

有很多这种解码器设计的变体，但在这里我们构建了类似于Transformer的架构，尽管我们仍然使用RNN GRU。


让我们放大每个组件。
第一个嵌入层创建了单词嵌入，这在其他视频中已经讨论过了，我们将其传递给GUR层。


如果你忘记了你猜的是什么。
这是一种循环神经网络的变体，或者你可以称之为RNN，RNN接收输入并更新其内部状态并生成输出。



所以通过传递序列数据，如文本数据，它可以保持序列依赖性。

这些来自以前的输入，比如之前的词，那个GRU的输出进入了注意力层，它混合了文本和图像的信息。


在TensorFlow Keras中，我们可以像使用其他层一样使用预定义的层。

有多种实现，但是我们在这里简单地使用了tf.keras.layers.Attention。

但是，如果你想使用更像Transformer的架构，你可以了解tf.keras.layers.MultiHeadAttention，它使用多个注意力头。


你可以简单地切换并以几乎相同的方式使用它。
在我们的注意力层中，你可能已经在关于注意力机制的另一个视频中看到了这个。

但这里独特的是，它通过处理文本数据关注图像特征，这样，它可以通过混合两种信息来计算注意力分数。



回到代码，你可以看到这个注意力层接受两个输入，gru_ouput和encoder_output。


在内部，GRU的输出用作注意力查询和键，编码器输出用作值。

最后的组件是Add层和LayerNormalization层。

Add层只是添加两个相同的移位向量。

如你所见，GRU的输出被传递给我们讨论过的注意力层以及直接传递给这个Add层，这两个流最终在这个Add层中合并。



这种架构被称为跳跃连接（Skip Connection），自Resonant以来一直非常受欢迎的深度神经网络设计模式。


因此，它也被称为残差连接（Residual Connection）。
这种跳跃连接非常有用，尤其是当你想设计一个非常深的神经网络时，它还用于Transformer。


有了这个，我们现在可以构建一个完整的解码器，因此我们准备使用说明文字数据集训练编码器解码器图像说明文字模型。


我们将在下一个视频中看到它是如何工作的。
但在继续下一个之前，我想多解释一下关于推理阶段的内容，在这个阶段我们实际上可以为图像生成说明文字，因为这个过程可能看起来有点复杂。




在这里，我们可以看到三个步骤，我们将在一个自定义推理函数中实现这些步骤，

第一，生成初始状态并创建一个起始Token，在训练阶段。


TensorFlow Chorus可以自动处理每个序列的状态，

但在这个推理阶段，由于我们设计了自己的自定义函数，我们需要明确地编写处理它的逻辑。

因此，在每个说明文字的开始，我们明确地用某个值初始化GRU状态，


同时记住我们的解码器是一个自回归函数。

但是由于我们在推理开始时还没有得到任何预测，所以我们从一个特殊的开始Token开始。

这意味着一个句子的开始，
第二，将图像输入到编码器，并按照我们讨论的进行特征向量的提取，

第三，将向量传递给这个时间解码器，在for循环中生成一个说明文字的单词，直到它返回一个结束Token，或者达到最大说明文字长度，这只是一个指定一些数字的超参数，比如264。




在这个完整的循环中，我们定义了所有说明文字通过反复调用解码器生成的过程，结束Token也是一个特殊的Token，意味着序列的结束。



因此，当我们的解码器生成这个Token时，我们可以完成这个完整的循环，或者当说明文字的长度达到某个最大长度时，可以跳出循环。



让我们逐一看一下代码。
在第一步中，我们初始化了两个东西：GRU状态和起始Token。

在这种情况下，GRU的状态只是用零向量初始化，而起始Token作为解码器的第一个输入词。


关于这里使用的word_to_index函数，我将在下一个视频中解释，但它基本上只是将词汇分词为我们的Token，这是标准的文本预处理技术。


在下一步中，我们预处理输入的图像，并将其传递给我们训练的编码器。


在图像预处理方面，它首先读取并解码JPEG，然后将其从任意分辨率调整为特定分辨率，



接着在第三行将比例从0到255更改为0到1，

最后是解码器循环。
这有点复杂。
因此，我将在下一个视频中更详细地解释实际代码。
但这里的主要内容是通过传递三个事物来调用解码器。

解码输入意味着解码器输入，它应该有一个在上一次迭代中预测的词Token。

正如我们所说，如果这是第一次迭代，那么这将是开始Token，GRU状态是我们讨论过的当前状态。


请注意记录器的这个输出，更新了GRU的状态。

最后但同样重要的是特征，
这是我们用编码器提取的图像特征。
通过传递它们，我们可以得到实际的下一个变量预测。
这是一个非常简单的从图像生成文本的模型，
但这种迭代在很大的语言生成模型中也非常相似，

就像Google Board， 他们基本上也是以这种方式预测下一个词，以自回归的方式，

一个接一个地基于一些信息和学习到的知识，这些知识都嵌入在大量的参数中。

在下一个视频中，我将带你浏览整个Notebook，
然后我们将检查这个模型可以生成哪些说明文字。

非常感谢你的观看，我们下一个视频见。