大家好，欢迎来到《负责任的人工智能入门》。
这门课程将帮助你：
了解为什么谷歌制定了AI原则。
认识到一个组织内负责任AI实践的必要性。
意识到项目各个阶段的决策对负责任AI的影响。
并且，认识到组织可以根据自己的业务需求和价值观设计AI。
我们中的许多人已经与人工智能（或AI）进行了日常互动，
从交通和天气的预测，到可能喜欢观看的电视节目的推荐。
随着AI变得越来越普遍，许多没集成AI的技术可能开始显得不够好。
现在，AI系统使计算机能够以前所未有的方式看到、理解和与世界互动。

这些系统正在以惊人的速度发展。
尽管有这些显著的进步，但AI并非万无一失。
负责任的AI开发需要了解可能的问题、局限性或意外后果。
技术是社会现象的反映，没有良好的实践，
AI可能复制现有的问题或偏见，并放大它们。
但是，并没有一个关于“负责任的AI”的通用定义，也没有一个简单的
清单或公式来定义如何实施负责任的AI实践。
相反，各个组织正在制定自己的AI原则，反映了他们的使命和价值观。
虽然这些原则因组织而异，但如果寻找共同点，
你会发现透明度、公平性、问责制和隐私方面有一致的观念。
在谷歌，我们负责任的AI方法植根于致力于为每个人构建AI的承诺，
它要有责任感、安全，尊重隐私，并以科学卓越为驱动。
我们制定了自己的AI原则、实践、治理流程和工具，\N共同体现了我们的价值观，指导我们负责任地使用AI。
我们将责任设计融入了产品，更重要的是，融入了我们的组织。
像许多公司一样，我们使用AI原则作为指导负责任决策的框架。
我们都在负责任地应用AI方面有作用。
无论您参与AI过程的哪个阶段，从设计\N到部署或应用，您所做的决策都会产生影响。
因此，您也需要有明确且可重复的负责任使用AI的流程。
关于人工智能的一个普遍误解是，机器在决策中起着核心作用。
实际上，设计和构建这些机器以及决定如何使用它们的是人。
人们参与到AI开发的每个方面。他们收集或创建模型训练所需的数据。
他们控制AI的部署以及在特定场景中的应用。
从本质上讲，人类决策贯穿于我们的技术产品中。
每当一个人做出决策时，他们实际上是根据自己的价值观做出选择。
无论是决定使用生成式AI来解决问题，
还是在整个机器学习生命周期中的\N其他方法，那个人都会引入自己的价值观。
这意味着每个决策点都需要考虑和评估，以确保
从概念到部署和维护，选择都是负责任的。
因为这些技术有可能影响到社会的许多领域，更不用说\N人们的日常生活了，所以在开发这些技术时要牢记道德。
负责任的AI并不意味着只关注明显有争议的用例。
没有负责任的AI实践，即使看似无害的AI\N应用案例，或者那些出于好意的案例，仍然可能导致\N道德问题或意外后果，或者没有达到它们可能的最大效益。
道德和责任很重要，不仅因为它们代表了正确的事情，\N而且因为它们可以指导AI设计，使人们的生活更有益。
在谷歌，我们了解到，在任何AI部署中建立责任感\N可以使模型更好，并与我们的客户和客户的客户建立信任。
如果在任何时候信任破裂，我们就有可能使AI部署停滞不前，
不成功，或者在最坏的情况下，对受影响的利益相关者造成伤害。
这都符合我们在谷歌的信念，即负责任的AI等于成功的AI。
我们通过一系列评估和审查来做出关于AI的产品和业务决策。
这些评估和审查确保了我们在产品领域\N和地理区域的方法的严谨性和一致性。
这些评估和审查从确保任何项目与我们的AI原则保持一致开始。
虽然AI原则有助于团队在共同承诺方面保持一致，\N但并非每个人都会同意关于如何负责任地设计产品的每个决策。
这就是为什么我们要建立可靠的流程让人们信任，\N即使他们不同意最终决定，也会信任作出决定的过程。
2018年6月，我们公布了七项AI原则来指导我们的工作。
这些具体标准积极地指导我们的研究\N和产品开发，并影响我们的业务决策。
以下是每个原则的概述：
1. AI应具有社会效益。
任何项目都应考虑广泛的社会和经济因素，只有在我们认为总体\N可能的收益明显超过可预见的风险和缺点时，才会继续进行。
2. AI应避免产生或加强不公平的偏见。
我们努力避免对人们产生不公正的影响，\N特别是与种族、民族、性别、国籍、收入、性取向、\N能力以及政治或宗教信仰等敏感特征相关的影响。
3. AI应该在安全方面进行构建和测试。

我们将继续发展并应用强大的安全保障措施，\N以避免产生可能导致伤害的意外结果。
4. AI应对人类负责。
我们将设计提供适当反馈、相关解释和申诉机会的AI系统。
5. AI应融入隐私设计原则。
我们将提供通知和同意的机会，鼓励具有隐私保护的架构，
并在数据使用方面提供适当的透明度和控制。
6. AI应维护高科学水平。
我们将与各方利益相关者合作，推动这一领域的深思熟虑的领导力，
运用科学严谨和多学科方法。
我们将负责任地分享AI知识，发布教育材料、\N最佳实践和研究，使更多人能够开发有用的AI应用。
7. AI应遵循这些原则进行开发。
许多技术有多种用途，我们将努力限制可能有害或滥用的应用。
除了这七个原则外，我们还有一些AI应用不会开发。
我们不会设计或部署以下四个应用领域的AI：\N可能导致或很可能导致整体伤害的技术。
主要目的或实施是导致或直接促成人员受伤的武器或其他技术。
收集或使用违反国际公认准则的监控信息的技术。
以及违反国际法和人权广泛接受原则的技术。
制定原则是一个起点，而不是终点。
我们的AI原则很少能直接回答我们关于如何构建产品的问题。
它们不会（也不应该）让我们回避艰难的对话。
它们是我们立场、我们构建的基础，
以及为什么我们要构建它，它们是我们企业AI产品成功的核心。