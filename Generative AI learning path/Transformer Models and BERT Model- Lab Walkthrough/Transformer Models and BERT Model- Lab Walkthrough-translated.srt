1
00:00:00,100 --> 00:00:05,100
嗨，我是Sanjana Reddy，一名在谷歌高级解决方案实验室的机器学习工程师。

3
00:00:06,865 --> 00:00:11,499
欢迎来到Transformer模型和BERT模型的实验室演示。

4
00:00:12,599 --> 00:00:18,131
在这个实验室演示中，我们将通过使用预训练的Bert模型进行分类。

6
00:00:18,666 --> 00:00:21,766
您可以在我们的GitHub仓库中找到设置说明。

7
00:00:22,666 --> 00:00:24,466
让我们开始吧。

8
00:00:24,500 --> 00:00:32,699
为了在这个Notebook上工作，您需要登录谷歌云，进入Vertex AI，然后点击Workbench。

10
00:00:33,732 --> 00:00:38,265
确保在Notebook实例创建后，您已经创建了一个Notebook。

12
00:00:38,265 --> 00:00:41,664
点击打开Jupyter Lab。

13
00:00:41,665 --> 00:00:47,864
按照我们GitHub仓库中的说明操作后，导航到使用Bert对文本进行分类。

15
00:00:48,832 --> 00:00:59,832
在这个Notebook中，我们将学习如何从TensorFlow Hub加载一个预训练的Bert模型，并使用预训练的Bert模型构建我们自己的分类。

18
00:00:59,832 --> 00:01:03,032
我们将学习如何通过微调来训练Bert模型。

19
00:01:05,099 --> 00:01:13,932
在开始之前，请注意，这个Notebook需要一个GPU，因为训练确实需要相当长的时间。

22
00:01:14,433 --> 00:01:23,432
当你打开这个Notebook时，有一个设置说明，以便设置一个bert_kernel来安装这个Notebook所需的所有库。

25
00:01:24,799 --> 00:01:35,066
对于这个Notebook，我们将使用TensorFlow和TensorFlow Hub TensorFlow Text，这是为BERT模型预处理输入所必需的。

28
00:01:36,632 --> 00:01:42,932
你可以看到我在检查是否有GPU连接，我发现这个Notebook有一个GPU连接。

30
00:01:43,599 --> 00:02:02,233
在这个Notebook中，我们将训练一个情感分析模型，根据评论的文本将电影评论分类为正面或负面，我们将使用IMDB数据集，你可以从这个URL下载。

35
00:02:03,933 --> 00:02:09,498
一旦我们下载了数据集，我们可以查看数据以了解其中的内容。

37
00:02:10,066 --> 00:02:24,300
我们看到我们有25,000个文件，分为正面和负面两个类别，我们将使用20,000个文件进行训练，剩下的5000个文件进行测试。

40
00:02:24,300 --> 00:02:31,532
这个数据集的一个样本向您展示了电影评论和相关标签。

42
00:02:31,532 --> 00:02:42,433
所以对于这里的一个，我们看到关联的标签是负面的，而下面这个是正面的。

44
00:02:42,966 --> 00:02:50,032
一旦我们检查了数据集并对其感到满意，我们将从TensorFlow Hub加载一个预训练的BERT模型。

46
00:02:51,233 --> 00:02:57,564
TensorFlow Hub提供了多种不同大小的BERT模型。

48
00:02:58,099 --> 00:03:02,499
在今天的Notebook中，我们将使用一个小型BERT。

49
00:03:02,500 --> 00:03:06,065
这个Bert模型有四个不同的层。

50
00:03:06,432 --> 00:03:11,664
它有512个隐藏单元，有8个注意力头。

51
00:03:11,665 --> 00:03:19,633
对于我们从TensorFlow Hub加载的每一个BERT模型，它都有一个相应的预处理模型。

53
00:03:20,432 --> 00:03:28,398
您也可以在TensorFlow Hub上找到相应的预处理模型。

55
00:03:28,400 --> 00:03:30,599
我们将研究预处理模型。

56
00:03:30,599 --> 00:03:38,299
我们将加载预处理模型，就像在前面的步骤中看到的那样，并在这里传递一个示例文本。

58
00:03:38,300 --> 00:03:39,233
我们刚刚通过了。

59
00:03:39,233 --> 00:03:42,600
这是一部很棒的电影，我们将检查输出。

60
00:03:43,265 --> 00:03:47,164
预处理模型给我们提供了多个输出。

61
00:03:47,400 --> 00:03:49,900
第一个是输入单词ID。

62
00:03:50,400 --> 00:03:56,332
输入单词ID是被分词的句子（Tokenized Sentence）中单词的ID。

64
00:03:56,332 --> 00:04:02,032
预处理模型还为每个单词提供了掩码（Masking）。

66
00:04:02,800 --> 00:04:14,066
每个句子都被转换成固定长度的输入，屏蔽掉无效的词语。

68
00:04:14,066 --> 00:04:20,532
所以一旦我们预处理了输入文本，就可以在这个特定的单元格中使用从TensorFlow Hub加载的Bert模型。

70
00:04:21,632 --> 00:04:26,899
这没有什么意义，因为我们还没有训练模型。

72
00:04:26,899 --> 00:04:30,198
这只是一个随机的数字列表。

73
00:04:30,632 --> 00:04:41,332
但是一旦你把预处理的文本传递给这个Bert模型，你就会得到一些嵌入（Embedding）。

75
00:04:41,333 --> 00:04:47,399
所以为了定义我们的分类模型，我们从一个输入层开始。

77
00:04:47,399 --> 00:04:59,699
输入层接收原始文本作为输入，将其传递给处理层进行预处理，将其转换为Token ID、Bert ID 和 Mask ID。

80
00:04:59,699 --> 00:05:04,165
预处理后的单词然后传递给预训练模型。

81
00:05:05,699 --> 00:05:07,832
这里有一个名为trainable（可训练）的参数。

82
00:05:08,399 --> 00:05:16,266
可训练在这里决定了您是否希望使用您正在训练的新数据对预训练模型进行微调。

84
00:05:16,665 --> 00:05:24,932
在我们的例子中，我们将trainable设置为True，这意味着我们将更新预训练模型的初始权重。

87
00:05:26,065 --> 00:05:36,599
您将此设置为True或False的决定取决于两件事：你是否想更新权重，以及你的数据集的大小。

91
00:05:37,199 --> 00:05:46,566
如果您有一个相对较小的数据集，建议将此设置为False，以免在预训练权重中引入噪声。

93
00:05:47,065 --> 00:05:50,665
但是，如果您有足够大的数据集，可以将其设置为True。

94
00:05:52,199 --> 00:06:02,432
一旦我们有了预训练模型，我们将其通过一个密集层，以获得每个类别的概率。

96
00:06:02,432 --> 00:06:05,032
这就是模型输出的样子。

97
00:06:05,033 --> 00:06:15,565
输出将是这个特定句子是真实的、正面的还是负面的概率。

99
00:06:15,565 --> 00:06:26,831
因为我们正在处理一个二分类问题，所以我们将使用BinaryCrossentropy作为损失函数，优化的指标将是BinaryAccuracy，

102
00:06:28,565 --> 00:06:33,032
通过定义优化器，我们开始初始化我们的训练。

104
00:06:33,033 --> 00:06:39,998
在我们的例子中，我们使用的是Adam，这是神经网络模型的热门选择。

106
00:06:40,899 --> 00:06:45,698
一旦我们初始化训练，我们可以开始使用model.fit进行训练。

108
00:06:46,100 --> 00:06:55,199
我们可以传递训练数据集和验证数据集以及我们想要训练的周期数。

110
00:06:55,199 --> 00:06:59,532
一旦模型训练完成，让我们评估模型的性能。

111
00:06:59,565 --> 00:07:08,700
在我们的例子中，我们看到模型达到了85%的准确率，考虑到我们只训练了五个周期，这是相当不错的。

113
00:07:09,899 --> 00:07:16,665
您可以潜在地阻止准确性和损失随时间变化，以便可视化模型的性能。

115
00:07:17,766 --> 00:07:24,866
我们看到训练损失正在减少，我们可以稍微改进一下验证损失。

117
00:07:25,266 --> 00:07:31,499
但是为了演示，我们只训练了五个周期。

119
00:07:31,500 --> 00:07:42,864
一旦你对你训练的模型感到满意，你可以使用model.save EXPORT_PATH保存模型，将TensorFlow模型保存到本地路径。

122
00:07:43,432 --> 00:07:51,665
因此，这行中的EXPORT_PATH将是您Notebook实例中的一部分。

124
00:07:51,665 --> 00:07:55,298
保存模型后，您可以加载它以获得预测。

125
00:07:55,600 --> 00:07:59,766
在这个例子中，我们有这是一部令人惊叹的电影。

126
00:07:59,766 --> 00:08:01,333
这部电影很棒。

127
00:08:01,333 --> 00:08:04,466
电影还可以，电影很糟糕。

128
00:08:04,932 --> 00:08:09,865
我们根据训练的模型得到每个句子的预测。

130
00:08:11,665 --> 00:08:23,332
如果您想进一步部署您的模型到 Vertex AI 以获得在线预测，您可以将本地保存的模型导出到 Vertex AI。

133
00:08:25,733 --> 00:08:31,800
为了做到这一点，您需要检查模型的签名，以了解如何将预测传递给模型。

135
00:08:32,566 --> 00:08:40,365
模型的签名会告诉您哪个是接收输入的第一层。

137
00:08:40,365 --> 00:08:52,799
所以一旦我们有了本地保存的模型，我们将使用这些命令将模型推送到 Vertex 的模型注册表。

140
00:08:52,799 --> 00:08:59,033
要将模型放入Vertex的模型注册表中，您需要确保拥有一个Google Cloud存储桶。

142
00:08:59,432 --> 00:09:02,499
这些代码行可以让您创建一个存储桶。

143
00:09:02,500 --> 00:09:10,199
如果它还不存在，我们将使用gsutils cp复制本地保存的模型，

146
00:09:10,700 --> 00:09:16,564
它从EXPORT_PATH中获取本地保存的模型，并将其放入Google Cloud存储桶中。

148
00:09:17,865 --> 00:09:24,065
一旦模型在Google Cloud存储桶中，我们将把它上传到Vertex AI的模型注册表中。

150
00:09:24,799 --> 00:09:27,964
在这个例子中，我们使用Python SDK。

151
00:09:28,133 --> 00:09:36,964
我们有aiplatform.model.upload，它从Google Cloud存储桶获取模型并将其放入模型注册表中。

153
00:09:38,732 --> 00:09:47,332
一旦模型上传完毕，我们就可以在Vertex上部署模型并获得在线预测。

156
00:09:47,332 --> 00:09:56,732
为了实现这一点，我们可以再次使用Python SDK，使用已上传的模型进行部署，这是一个将执行两个操作的函数。

159
00:09:56,732 --> 00:10:04,666
首先，它将创建一个端点（Endpoint），其次，它将把模型上传到这个特定的端点。

161
00:10:05,466 --> 00:10:11,065
如您所见，这里创建了端点，并提供了端点位置。

163
00:10:11,066 --> 00:10:15,633
一旦端点创建完成，模型就会部署到这个端点。

165
00:10:16,566 --> 00:10:20,066
这个步骤大约需要5到10分钟。

166
00:10:20,066 --> 00:10:24,466
当您在Notebook中运行时，如果花费时间较长，请不要担心。

168
00:10:25,365 --> 00:10:35,199
一旦模型部署到端点，您就可以从这个端点获取预测，然后创建一个实例对象。

171
00:10:35,966 --> 00:10:41,665
根据模型的签名，我们知道第一个输入层的名称是"text"。

173
00:10:42,100 --> 00:10:47,233
我们将把评论文本传递给这个特定的键。

174
00:10:48,299 --> 00:10:53,533
我们创建这个实例对象，它将被传递给endpoint.predict函数。

176
00:10:54,232 --> 00:11:00,332
endpoint.predict函数将接收这个实例，并给我们预测结果。

178
00:11:00,332 --> 00:11:04,498
我们可以看到，对于我们的第一个实例，我喜欢这部电影并强烈推荐它。

179
00:11:04,799 --> 00:11:08,364
我们有一个0.99的预测。

180
00:11:08,365 --> 00:11:10,099
对于这是一部还可以的电影，这是我的看法。

181
00:11:10,100 --> 00:11:16,333
我们有84%，而对于我讨厌这部电影，我们有2%，这意味着这是一种负面情绪。

183
00:11:17,232 --> 00:11:27,699
所以这就是如何从一个预先训练的BERT模型创建一个分类模型，然后将其部署到Vertex上以获得在线预测。
