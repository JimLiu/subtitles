1
00:00:00,600 --> 00:00:05,432
大家好！我是Google Advanced Solutions Lab的机器学习工程师Benoit Dherin。

4
00:00:05,766 --> 00:00:12,266
如果你想了解更多关于Advanced Solutions Lab的信息，请点击描述框下方的链接。

6
00:00:13,233 --> 00:00:23,266
围绕着生成性AI和相关的新技术取得了令人兴奋的进展，例如像新的Vertex AI特性如GenAI Studio，Model Garden，GenAI API等。

9
00:00:24,199 --> 00:00:31,798
在这个简短的课程中，我们的目标是帮助你了解一些生成式AI的基本概念。

11
00:00:32,200 --> 00:00:39,432
今天，我将讲解与同一系列的“编码器-解码器架构概述”课程相辅助的代码。

13
00:00:39,432 --> 00:00:46,066
我们将一起学习如何从头开始使用编码器-解码器架构建立一个诗歌生成器，

16
00:00:46,799 --> 00:00:49,964
你可以在我们的GitHub Repo找到设置指南。

17
00:00:50,566 --> 00:00:52,766
好的，现在让我们看一下代码。

18
00:00:53,365 --> 00:00:58,831
要访问我们的Lab，请进入asl-ml-immersion文件夹。

19
00:00:58,865 --> 00:01:01,065
然后是notebooks文件夹。

20
00:01:02,332 --> 00:01:04,432
然后是text_models文件夹。

21
00:01:05,000 --> 00:01:10,466
在solutions文件夹里你会找到text_generation的Notebook，

22
00:01:10,965 --> 00:01:16,332
这就是我们今天要讲的实验。

23
00:01:17,165 --> 00:01:24,100
在这个实验中，我们将基于编码器解码器架构实现一个基于字符的文本生成器。

25
00:01:24,865 --> 00:01:32,664
基于字符意味着网络消耗和生成的Token是字符而不是单词。

27
00:01:33,900 --> 00:01:36,965
我们将使用剧本作为数据集。

28
00:01:38,332 --> 00:01:45,132
它们有特殊的结构，就像人们在彼此对话。

30
00:01:45,299 --> 00:01:53,066
你在这里看到的是一个由训练过的神经网络生成的文本示例，

32
00:01:53,766 --> 00:01:56,500
即使这些句子没有必然的意义，

33
00:01:56,500 --> 00:01:58,500
也不一定符合语法规则，

34
00:01:58,500 --> 00:02:00,965
但仍然有很多值得注意的地方。

35
00:02:00,965 --> 00:02:03,665
首先，记住，它是基于字符的。

36
00:02:03,665 --> 00:02:07,799
所以它只学习预测最可能的字符。

37
00:02:08,332 --> 00:02:11,065
尽管如此，它还是学得很好

38
00:02:11,066 --> 00:02:14,133
像单词被空格分开的概念，

39
00:02:14,432 --> 00:02:19,965
以及剧本的基本结构，角色彼此对话。

40
00:02:21,032 --> 00:02:21,432
所以继续

41
00:02:21,432 --> 00:02:32,733
你将看到的这个非常小的网络是基于RNN 0架构的，并且只在Vertex AIr工作台上训练了30个周期，这是一个非常快的训练时间。

44
00:02:33,900 --> 00:02:37,033
那么现在我们来看看代码。

45
00:02:42,099 --> 00:02:47,365
首先要导入我们需要的库。

46
00:02:47,665 --> 00:02:56,132
特别是，我们可以使用TensorFlow Keras来导入编码器解码器架构。

48
00:02:57,000 --> 00:02:59,299
然后我们下载数据集

49
00:02:59,300 --> 00:03:02,099
使用tf.keras.utils.get_file。

50
00:03:02,832 --> 00:03:10,498
现在数据集已经在磁盘上，我们只需要将其加载到变量text中。

51
00:03:10,500 --> 00:03:18,665
这个text变量现在包含了代表整个莎士比亚剧本数据集的整个字符串。

53
00:03:19,733 --> 00:03:23,066
我可以快速看看它是什么吗？

54
00:03:23,066 --> 00:03:27,399
你会看到，如果我们打印出前250个字符，

55
00:03:27,900 --> 00:03:38,233
有第一位公民对所有人说话，然后所有人对第一位公民说话。

58
00:03:38,699 --> 00:03:52,064
这个单元计算我们在文本数据集中有多少唯一的字符，我们看到我们有65个唯一的字符，对吧？

61
00:03:52,199 --> 00:04:01,199
这些字符将是神经网络在训练和生成过程中将消耗的Token。

63
00:04:02,066 --> 00:04:06,899
现在的第一步是对文本进行向量化。

65
00:04:07,233 --> 00:04:08,932
向量化是什么意思呢？

66
00:04:08,932 --> 00:04:17,365
这意味着我们首先需要从实际的字符串序列中提取出字符序列，

68
00:04:17,365 --> 00:04:26,198
我们可以用TensorFlow的tf.strings.unicode_split来做到这一点。

70
00:04:26,899 --> 00:04:37,531
以现在，例如，文本在这里被转换成了字符序列的列表。

73
00:04:39,365 --> 00:04:44,898
神经网络不能直接消耗字符，我们需要将它转换成数字。

76
00:04:45,300 --> 00:04:49,399
所以我们需要简单地将每个字符映射到一个给定的id。

77
00:04:50,365 --> 00:05:04,499
为此我们有tf.keras.layers.StringLookup，你只需要将你的词汇表列表传给它。

81
00:05:04,500 --> 00:05:17,532
我们在语料库中有的65个唯一字符，然后我们生成一个层，当传入字符时，它会产生相应的id。

84
00:05:18,333 --> 00:05:25,932
在那个层中，你有一个已经生成的字符和id之间的映射。

86
00:05:27,899 --> 00:05:40,300
要获得反向映射，你使用相同的字符串查找层，使用从第一层获取的相同的词汇表。

90
00:05:41,165 --> 00:05:45,299
但你将参数设置为真，invert等于True，

91
00:05:45,600 --> 00:05:54,699
那将计算反向映射，即从id到字符的映射。

94
00:05:54,699 --> 00:06:07,465
实际上，如果你传递一系列ID给这个映射，它会给你返回对应的字符，

98
00:06:07,632 --> 00:06:10,599
使用在这个层的内存中存储的映射。

99
00:06:11,733 --> 00:06:14,233
就是这样。

100
00:06:15,165 --> 00:06:15,899
好的。

101
00:06:15,899 --> 00:06:20,631
现在我们来准备我们将用来训练神经网络的数据集。

102
00:06:20,932 --> 00:06:34,799
我们使用了tf.data.Dataset API，它有一个很好的方法叫做“from_tensor_slices”，

107
00:06:34,800 --> 00:06:43,965
它将把一个实例数组，代表我们的整个剧本文本语料库的id，转化为一个TF data数据集。

109
00:06:44,565 --> 00:06:52,600
此刻，这些数据集的元素仅仅是单个字符。

111
00:06:52,600 --> 00:06:53,899
这对我们来说并不理想。

112
00:06:53,899 --> 00:07:01,499
我们想要给我们的神经网络提供的是等长的序列，而不仅仅是一个字符。

114
00:07:01,565 --> 00:07:03,432
我们需要预测下一个字符。

115
00:07:05,432 --> 00:07:06,764
但幸运的是，

116
00:07:06,766 --> 00:07:11,266
数据集API有一个很好的功能叫做“batch”，它能完美地为我们做到这一点。

117
00:07:11,266 --> 00:07:17,700
所以如果我们在我们的ID数据集上调用“batch”方法，

119
00:07:18,300 --> 00:07:26,399
并传递一个给定的序列长度（这里我们设定为100），

121
00:07:27,000 --> 00:07:37,665
那么存储在我们的数据集中的数据点就不再是字符，而是100个字符的序列。

124
00:07:37,665 --> 00:07:40,564
这里有一个例子。

125
00:07:40,565 --> 00:07:47,733
如果我们只取一个元素，那么它们不再是字符，而是百位的字符ID序列，

127
00:07:47,800 --> 00:07:50,100
你需要的不是字符，而是字符ID。

128
00:07:52,365 --> 00:07:57,698
好的，我们还没完全完成。

130
00:07:58,199 --> 00:08:08,832
我们仍然需要创建我们将传给解码器的输入序列，以及我们想要预测的序列。

133
00:08:08,932 --> 00:08:09,599
对吧？

134
00:08:09,600 --> 00:08:15,565
那么，这些序列是什么呢？它们只是输入序列中下一个字符的序列。

136
00:08:15,565 --> 00:08:19,065
例如，如果我们有序列TensorFlow

137
00:08:20,865 --> 00:08:23,398
并且在开始时有序列TensorFlow，

138
00:08:24,432 --> 00:08:32,364
在序列的开头，我们能从中得到的输入序列是"Tens-or-flow"（省略了最后一个W），

140
00:08:33,066 --> 00:08:39,066
我们想要预测的目标序列是相同的序列，但是向右移动一位，

142
00:08:39,932 --> 00:08:42,932
所以是"ensor-flow"，

143
00:08:42,932 --> 00:08:52,699
你可以看到E是T的下一个字符，N是E的下一个字符，等等。

145
00:08:53,100 --> 00:08:55,366
基本上，这个小函数就是实现这一功能的，

146
00:08:55,700 --> 00:09:15,133
它接受一个原始序列，通过截断这个序列（去掉最后一个字符）创建一个输入序列，目标序列则是从第一个字符开始创建的。

150
00:09:15,899 --> 00:09:23,331
我们怎么做呢？我们只需将这个分割输入目标函数映射到我们的序列数据集即可。

152
00:09:24,666 --> 00:09:25,400
好的。

153
00:09:26,466 --> 00:09:27,599
这样就完成了。

154
00:09:27,600 --> 00:09:29,166
现在让我们看看如何构建模型。

155
00:09:30,600 --> 00:09:34,399
首先，我们设置一些变量：

156
00:09:36,332 --> 00:09:46,066
词汇表大小，我们希望表示字符的向量的大小（我认为应该是256），

158
00:09:46,399 --> 00:09:49,732
以及我们的循环层的神经元数量。

159
00:09:51,765 --> 00:09:52,799
对于模型本身。

160
00:09:52,799 --> 00:09:54,831
这是一个相对简单的模型。

161
00:09:55,666 --> 00:10:01,499
我们通过使用Keras子类API来创建它。

162
00:10:01,500 --> 00:10:08,731
我们创建了一个新的叫做"MyModel"的类，并从tf.keras.Model中子类化。

165
00:10:08,732 --> 00:10:17,233
当你这样做的时候，你只需要覆盖两个函数，构造函数和调用函数。

167
00:10:17,533 --> 00:10:20,865
那么让我们看看这两个函数分别做什么。

168
00:10:20,865 --> 00:10:26,132
第一个函数主要接收模型的超参数，

169
00:10:26,133 --> 00:10:33,299
即词汇表大小，嵌入维度，神经元数量，

171
00:10:33,832 --> 00:10:45,864
然后它只是构建你需要的层并将它们存储为类的变量。

173
00:10:45,865 --> 00:10:46,565
好的。

174
00:10:47,399 --> 00:10:51,931
而这些层是如何连接的，

176
00:10:51,932 --> 00:10:57,700
所有这些都在调用函数中指定，也就是你的网络架构。

178
00:10:57,700 --> 00:11:00,799
如果你想的话。

179
00:11:00,799 --> 00:11:02,499
让我们看看这个函数主要做什么。

180
00:11:02,500 --> 00:11:07,766
它接收输入，也就是代表字符的id序列。

181
00:11:08,533 --> 00:11:19,032
我们有一个第一层，它会为每一个输入创建一个代表那个输入的向量，也就是训练层。

184
00:11:19,033 --> 00:11:27,199
随着训练的进行，这些代表字符的向量将开始变得越来越有意义，

186
00:11:27,666 --> 00:11:29,699
至少这是我们的想法。

187
00:11:29,700 --> 00:11:39,898
然后，这些静态的字符表示被传递给循环层，它会根据之前看到的内容的上下文来修改这些表示，

190
00:11:39,899 --> 00:11:52,032
并生成一个代表之前看到的内容的状态，这将在下一步被重用。

193
00:11:52,700 --> 00:12:03,600
最后，我们将循环层的输出传递给一个密集层，它将输出与我们的词汇表中的数量相同的数，

196
00:12:04,000 --> 00:12:20,265
也就是每一个可能的65个字符的一个分数，这个分数代表字符是下一个字符的概率。

201
00:12:20,265 --> 00:12:22,765
这就是模型做的所有事情。

202
00:12:23,299 --> 00:12:29,398
首先，我们实例化了模型。

203
00:12:29,399 --> 00:12:33,132
有了模型后，我们可以通过使用模型摘要来查看模型的结构。

204
00:12:33,133 --> 00:12:44,631
你会看到我们刚刚在模型中实现的嵌入层、循环层和密集层。

207
00:12:47,365 --> 00:12:48,232
就是这样。

208
00:12:48,232 --> 00:12:49,865
接下来，我们要训练模型。

209
00:12:49,865 --> 00:12:53,631
在训练模型之前，我们需要一个损失函数，

210
00:12:53,633 --> 00:12:58,232
我们将用它来比较模型的输出和真实结果。

211
00:12:58,832 --> 00:13:03,332
由于我们的问题本质上是一个多类分类问题，

212
00:13:04,365 --> 00:13:14,065
类别就是可能的下一个字符，所以我们会使用损失函数SparseCategoricalCrossentropy。

215
00:13:14,832 --> 00:13:24,065
由于神经网络的输出（对数）并不直接对应概率，

217
00:13:24,066 --> 00:13:30,299
我们将损失函数配置为从对数分数而不是概率分数计算。

219
00:13:31,299 --> 00:13:31,999
好的，

220
00:13:32,332 --> 00:13:36,299
有了损失函数后，我们可以编译模型，

221
00:13:36,299 --> 00:13:41,731
也就是为模型附加损失函数和优化器。

222
00:13:41,899 --> 00:13:47,699
优化器将在训练过程中更新权重，尽可能地减少损失。

224
00:13:48,466 --> 00:14:01,865
此外，我们还设置了一个在训练过程中保存权重的回调函数，这是一个很有用的工具。

229
00:14:01,865 --> 00:14:04,565
至此，我们已经准备好开始训练了。

230
00:14:04,566 --> 00:14:13,833
我们对数据集执行model.fit，选择想要训练的轮次。

232
00:14:14,399 --> 00:14:18,599
一轮是对数据集的一次完整遍历。

233
00:14:18,600 --> 00:14:26,999
在这里，我们将数据集遍历了十次，

235
00:14:27,832 --> 00:14:35,032
并在训练过程中使用回调函数确保权重被保存。

237
00:14:36,466 --> 00:14:37,066
就是这样。

238
00:14:37,066 --> 00:14:39,765
这个过程相对简单。我们用数据训练模型，

239
00:14:39,765 --> 00:14:42,499
现在我们有了训练好的模型，接下来我们该怎么做呢？

240
00:14:42,765 --> 00:15:02,098
在编码器-解码器架构中，你不能直接使用你的模型，你需要编写一个解码函数来一步步解码生成的文本。

246
00:15:03,533 --> 00:15:03,865
好的。

247
00:15:03,865 --> 00:15:12,500
在这个例子中，我们选择将解码函数作为一个Keras模型实现。

250
00:15:12,500 --> 00:15:15,966
我们从tf.keras.Model子类化。

251
00:15:15,966 --> 00:15:21,733
模型中的主要方法是生成一步。

253
00:15:22,232 --> 00:15:40,265
这个方法接收输入，即你希望编码器-解码器模型完成、预测、生成新字符的初始字符序列。

258
00:15:41,100 --> 00:15:50,999
然后，它将这段文本转换为一串字符，然后再转换为一串id。

261
00:15:51,100 --> 00:15:53,100
使用了ids_from_chars方法。

262
00:15:53,100 --> 00:15:57,465
这里我们之前有一个设置，然后我们调用我们的模型

263
00:15:57,600 --> 00:16:00,866
或者之前训练过的编码器-解码器模型。

264
00:16:01,799 --> 00:16:02,699
它做什么呢？

265
00:16:02,700 --> 00:16:09,965
它会接收id输入并输出预测的对数。

267
00:16:09,966 --> 00:16:14,400
这个对数对应了最可能的Token，也就是最可能的字符，

268
00:16:14,600 --> 00:16:18,100
以及一个总结前面看到的内容的状态。

269
00:16:20,432 --> 00:16:30,499
从预测的对数中，我们可以选择最可能的Token或字符。

271
00:16:30,666 --> 00:16:34,199
在做这之前，有一个小技巧，

272
00:16:34,600 --> 00:16:38,965
就是我们会将对数除以一个温度(temperature)值。

273
00:16:39,533 --> 00:16:43,699
基本上，如果温度是1，就没有任何变化。

274
00:16:43,700 --> 00:17:00,632
如果温度很高，它会使得所有Token的得分变得接近于0，

278
00:17:02,299 --> 00:17:09,164
这意味着这个Token更有可能被选中。

280
00:17:09,299 --> 00:17:16,365
所以，如果温度更高，会有更多的多样性，

282
00:17:16,365 --> 00:17:20,765
更多的内容可以被预测，这会使得模型变得更有创造性。

283
00:17:20,766 --> 00:17:25,299
如果温度太高，神经网络只会预测出无意义的东西。

284
00:17:26,099 --> 00:17:28,164
好的。

285
00:17:28,165 --> 00:17:34,200
如果温度非常低，最高的概率得分会被乘以一个非常大的数，

287
00:17:34,665 --> 00:17:39,565
因为它被一个小数除，这是一个介于0和1之间的数字，

288
00:17:40,099 --> 00:17:56,264
这会使得最高得分的Token有更大的被选中的概率，也就是说，模型的行为会更加确定。

292
00:17:56,266 --> 00:17:57,399
好的，这就是温度。

293
00:17:57,400 --> 00:18:00,100
所以，温度是这种架构中一个重要的参数。

294
00:18:01,532 --> 00:18:01,832
好的。

295
00:18:01,833 --> 00:18:03,232
这就是它的功能。

296
00:18:03,799 --> 00:18:04,399
好的。

297
00:18:04,400 --> 00:18:18,131
有了预测的对数后，我们使用tf.random.categorical从这些概率分数中随机选择下一个最可能的id，

300
00:18:18,865 --> 00:18:22,764
然后将它转换回一个字符，这就是我们返回的结果。

301
00:18:23,700 --> 00:18:30,133
好的，这就是解码函数的主要工作，大多数解码函数都是这样的结构。

303
00:18:30,133 --> 00:18:38,800
这个设置“温度”参数的技巧，你也可以应用在大语言模型中。

306
00:18:41,299 --> 00:18:44,432
好的，接下来，我们要使用解码函数。

307
00:18:44,432 --> 00:18:46,598
通常，你会在一个循环中使用它。

308
00:18:46,599 --> 00:18:56,598
在这里，我们将通过反复调用解码函数生成1000个字符。

310
00:18:57,066 --> 00:19:07,399
你将前一次预测的结果和总结前一次发生的状态一起输入到解码函数中，

313
00:19:07,799 --> 00:19:11,231
它会预测下一个字符和一个新的状态，

314
00:19:11,700 --> 00:19:13,700
然后我们就可以开始这个过程了。

315
00:19:13,700 --> 00:19:17,500
我们以“罗密欧（Romeo）”作为Prompt。

317
00:19:17,500 --> 00:19:24,599
你打算说什么？然后看看神经网络生成的结果。对吧？

319
00:19:24,599 --> 00:19:31,666
生成的是：“no good corona at least take your feetle and if I seem to my love you...”

321
00:19:32,232 --> 00:19:36,299
你会看到，结果并没有完全符合语法规则，

322
00:19:36,566 --> 00:19:50,632
这是因为我只在Vertex AI工作台上用很短的时间训练了这个模型。

325
00:19:50,700 --> 00:19:54,833
这是一个小实例，只用了一个GPU，所以训练规模很小。

326
00:19:55,133 --> 00:19:57,899
模型的代码只有几行，

327
00:19:57,900 --> 00:20:07,900
但你仍然能看到，它真的能从输入数据的结构中捕获到很多东西。

329
00:20:07,900 --> 00:20:11,065
它能够检测到你输入的字符模式。

330
00:20:11,066 --> 00:20:13,599
比如，“罗密欧”就是我们的输入，

331
00:20:15,266 --> 00:20:15,965
然后神经网络生成了“莱昂特斯（Leontes）”，

332
00:20:15,965 --> 00:20:21,832
以及“莱昂特斯”说的话。

334
00:20:23,532 --> 00:20:26,232
好的，就这样。

336
00:20:26,865 --> 00:20:34,099
如果你喜欢这个介绍，你可以在我们的ASL GitHub Repo中找到更多的机器学习Notebooks。

338
00:20:34,500 --> 00:20:37,199
如果你觉得这个Repo很有用，请给我们的Repo加星星⭐️。

340
00:20:37,665 --> 00:20:40,331
感谢你花时间来听我讲解。
