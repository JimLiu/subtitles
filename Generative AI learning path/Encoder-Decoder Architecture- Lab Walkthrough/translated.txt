大家好！我是Google Advanced Solutions Lab的机器学习工程师Benoit Dherin。


如果你想了解更多关于Advanced Solutions Lab的信息，请点击描述框下方的链接。

围绕着生成性AI和相关的新技术取得了令人兴奋的进展，例如像新的Vertex AI特性如GenAI Studio，Model Garden，GenAI API等。


在这个简短的课程中，我们的目标是帮助你了解一些生成式AI的基本概念。

今天，我将讲解与同一系列的“编码器-解码器架构概述”课程相辅助的代码。

我们将一起学习如何从头开始使用编码器-解码器架构建立一个诗歌生成器，


你可以在我们的GitHub Repo找到设置指南。
好的，现在让我们看一下代码。
要访问我们的Lab，请进入asl-ml-immersion文件夹。
然后是notebooks文件夹。
然后是text_models文件夹。
在solutions文件夹里你会找到text_generation的Notebook，
这就是我们今天要讲的实验。
在这个实验中，我们将基于编码器解码器架构实现一个基于字符的文本生成器。

基于字符意味着网络消耗和生成的Token是字符而不是单词。

我们将使用剧本作为数据集。
它们有特殊的结构，就像人们在彼此对话。

你在这里看到的是一个由训练过的神经网络生成的文本示例，

即使这些句子没有必然的意义，
也不一定符合语法规则，
但仍然有很多值得注意的地方。
首先，记住，它是基于字符的。
所以它只学习预测最可能的字符。
尽管如此，它还是学得很好
像单词被空格分开的概念，
以及剧本的基本结构，角色彼此对话。
所以继续
你将看到的这个非常小的网络是基于RNN 0架构的，并且只在Vertex AIr工作台上训练了30个周期，这是一个非常快的训练时间。


那么现在我们来看看代码。
首先要导入我们需要的库。
特别是，我们可以使用TensorFlow Keras来导入编码器解码器架构。

然后我们下载数据集
使用tf.keras.utils.get_file。
现在数据集已经在磁盘上，我们只需要将其加载到变量text中。
这个text变量现在包含了代表整个莎士比亚剧本数据集的整个字符串。

我可以快速看看它是什么吗？
你会看到，如果我们打印出前250个字符，
有第一位公民对所有人说话，然后所有人对第一位公民说话。


这个单元计算我们在文本数据集中有多少唯一的字符，我们看到我们有65个唯一的字符，对吧？


这些字符将是神经网络在训练和生成过程中将消耗的Token。

现在的第一步是对文本进行向量化。

向量化是什么意思呢？
这意味着我们首先需要从实际的字符串序列中提取出字符序列，

我们可以用TensorFlow的tf.strings.unicode_split来做到这一点。

以现在，例如，文本在这里被转换成了字符序列的列表。


神经网络不能直接消耗字符，我们需要将它转换成数字。


所以我们需要简单地将每个字符映射到一个给定的id。
为此我们有tf.keras.layers.StringLookup，你只需要将你的词汇表列表传给它。



我们在语料库中有的65个唯一字符，然后我们生成一个层，当传入字符时，它会产生相应的id。


在那个层中，你有一个已经生成的字符和id之间的映射。

要获得反向映射，你使用相同的字符串查找层，使用从第一层获取的相同的词汇表。



但你将参数设置为真，invert等于True，
那将计算反向映射，即从id到字符的映射。


实际上，如果你传递一系列ID给这个映射，它会给你返回对应的字符，



使用在这个层的内存中存储的映射。
就是这样。
好的。
现在我们来准备我们将用来训练神经网络的数据集。
我们使用了tf.data.Dataset API，它有一个很好的方法叫做“from_tensor_slices”，




它将把一个实例数组，代表我们的整个剧本文本语料库的id，转化为一个TF data数据集。

此刻，这些数据集的元素仅仅是单个字符。

这对我们来说并不理想。
我们想要给我们的神经网络提供的是等长的序列，而不仅仅是一个字符。

我们需要预测下一个字符。
但幸运的是，
数据集API有一个很好的功能叫做“batch”，它能完美地为我们做到这一点。
所以如果我们在我们的ID数据集上调用“batch”方法，

并传递一个给定的序列长度（这里我们设定为100），

那么存储在我们的数据集中的数据点就不再是字符，而是100个字符的序列。


这里有一个例子。
如果我们只取一个元素，那么它们不再是字符，而是百位的字符ID序列，

你需要的不是字符，而是字符ID。
好的，我们还没完全完成。

我们仍然需要创建我们将传给解码器的输入序列，以及我们想要预测的序列。


对吧？
那么，这些序列是什么呢？它们只是输入序列中下一个字符的序列。

例如，如果我们有序列TensorFlow
并且在开始时有序列TensorFlow，
在序列的开头，我们能从中得到的输入序列是"Tens-or-flow"（省略了最后一个W），

我们想要预测的目标序列是相同的序列，但是向右移动一位，

所以是"ensor-flow"，
你可以看到E是T的下一个字符，N是E的下一个字符，等等。

基本上，这个小函数就是实现这一功能的，
它接受一个原始序列，通过截断这个序列（去掉最后一个字符）创建一个输入序列，目标序列则是从第一个字符开始创建的。



我们怎么做呢？我们只需将这个分割输入目标函数映射到我们的序列数据集即可。

好的。
这样就完成了。
现在让我们看看如何构建模型。
首先，我们设置一些变量：
词汇表大小，我们希望表示字符的向量的大小（我认为应该是256），

以及我们的循环层的神经元数量。
对于模型本身。
这是一个相对简单的模型。
我们通过使用Keras子类API来创建它。
我们创建了一个新的叫做"MyModel"的类，并从tf.keras.Model中子类化。


当你这样做的时候，你只需要覆盖两个函数，构造函数和调用函数。

那么让我们看看这两个函数分别做什么。
第一个函数主要接收模型的超参数，
即词汇表大小，嵌入维度，神经元数量，

然后它只是构建你需要的层并将它们存储为类的变量。

好的。
而这些层是如何连接的，

所有这些都在调用函数中指定，也就是你的网络架构。

如果你想的话。
让我们看看这个函数主要做什么。
它接收输入，也就是代表字符的id序列。
我们有一个第一层，它会为每一个输入创建一个代表那个输入的向量，也就是训练层。


随着训练的进行，这些代表字符的向量将开始变得越来越有意义，

至少这是我们的想法。
然后，这些静态的字符表示被传递给循环层，它会根据之前看到的内容的上下文来修改这些表示，


并生成一个代表之前看到的内容的状态，这将在下一步被重用。


最后，我们将循环层的输出传递给一个密集层，它将输出与我们的词汇表中的数量相同的数，


也就是每一个可能的65个字符的一个分数，这个分数代表字符是下一个字符的概率。




这就是模型做的所有事情。
首先，我们实例化了模型。
有了模型后，我们可以通过使用模型摘要来查看模型的结构。
你会看到我们刚刚在模型中实现的嵌入层、循环层和密集层。


就是这样。
接下来，我们要训练模型。
在训练模型之前，我们需要一个损失函数，
我们将用它来比较模型的输出和真实结果。
由于我们的问题本质上是一个多类分类问题，
类别就是可能的下一个字符，所以我们会使用损失函数SparseCategoricalCrossentropy。


由于神经网络的输出（对数）并不直接对应概率，

我们将损失函数配置为从对数分数而不是概率分数计算。

好的，
有了损失函数后，我们可以编译模型，
也就是为模型附加损失函数和优化器。
优化器将在训练过程中更新权重，尽可能地减少损失。

此外，我们还设置了一个在训练过程中保存权重的回调函数，这是一个很有用的工具。




至此，我们已经准备好开始训练了。
我们对数据集执行model.fit，选择想要训练的轮次。

一轮是对数据集的一次完整遍历。
在这里，我们将数据集遍历了十次，

并在训练过程中使用回调函数确保权重被保存。

就是这样。
这个过程相对简单。我们用数据训练模型，
现在我们有了训练好的模型，接下来我们该怎么做呢？
在编码器-解码器架构中，你不能直接使用你的模型，你需要编写一个解码函数来一步步解码生成的文本。





好的。
在这个例子中，我们选择将解码函数作为一个Keras模型实现。


我们从tf.keras.Model子类化。
模型中的主要方法是生成一步。

这个方法接收输入，即你希望编码器-解码器模型完成、预测、生成新字符的初始字符序列。




然后，它将这段文本转换为一串字符，然后再转换为一串id。


使用了ids_from_chars方法。
这里我们之前有一个设置，然后我们调用我们的模型
或者之前训练过的编码器-解码器模型。
它做什么呢？
它会接收id输入并输出预测的对数。

这个对数对应了最可能的Token，也就是最可能的字符，
以及一个总结前面看到的内容的状态。
从预测的对数中，我们可以选择最可能的Token或字符。

在做这之前，有一个小技巧，
就是我们会将对数除以一个温度(temperature)值。
基本上，如果温度是1，就没有任何变化。
如果温度很高，它会使得所有Token的得分变得接近于0，



这意味着这个Token更有可能被选中。

所以，如果温度更高，会有更多的多样性，

更多的内容可以被预测，这会使得模型变得更有创造性。
如果温度太高，神经网络只会预测出无意义的东西。
好的。
如果温度非常低，最高的概率得分会被乘以一个非常大的数，

因为它被一个小数除，这是一个介于0和1之间的数字，
这会使得最高得分的Token有更大的被选中的概率，也就是说，模型的行为会更加确定。



好的，这就是温度。
所以，温度是这种架构中一个重要的参数。
好的。
这就是它的功能。
好的。
有了预测的对数后，我们使用tf.random.categorical从这些概率分数中随机选择下一个最可能的id，


然后将它转换回一个字符，这就是我们返回的结果。
好的，这就是解码函数的主要工作，大多数解码函数都是这样的结构。

这个设置“温度”参数的技巧，你也可以应用在大语言模型中。


好的，接下来，我们要使用解码函数。
通常，你会在一个循环中使用它。
在这里，我们将通过反复调用解码函数生成1000个字符。

你将前一次预测的结果和总结前一次发生的状态一起输入到解码函数中，


它会预测下一个字符和一个新的状态，
然后我们就可以开始这个过程了。
我们以“罗密欧（Romeo）”作为Prompt。

你打算说什么？然后看看神经网络生成的结果。对吧？

生成的是：“no good corona at least take your feetle and if I seem to my love you...”

你会看到，结果并没有完全符合语法规则，
这是因为我只在Vertex AI工作台上用很短的时间训练了这个模型。


这是一个小实例，只用了一个GPU，所以训练规模很小。
模型的代码只有几行，
但你仍然能看到，它真的能从输入数据的结构中捕获到很多东西。

它能够检测到你输入的字符模式。
比如，“罗密欧”就是我们的输入，
然后神经网络生成了“莱昂特斯（Leontes）”，
以及“莱昂特斯”说的话。

好的，就这样。

如果你喜欢这个介绍，你可以在我们的ASL GitHub Repo中找到更多的机器学习Notebooks。

如果你觉得这个Repo很有用，请给我们的Repo加星星⭐️。

感谢你花时间来听我讲解。