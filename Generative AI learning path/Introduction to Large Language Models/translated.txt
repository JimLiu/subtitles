JOHN EWALD：大家好，欢迎来到大型语言模型介绍课程。  我是JOHN EWALD，谷歌云的培训开发人员。  在这门课程中，您将学习定义大型语言模型， 即LLM，描述LLM的用例， 解释提示调优（Prompt Tuning），以及介绍谷歌的Gen AI开发工具。  大型语言模型，即LLM，是深度学习的一个子集。 想了解更多关于深度学习的信息， 请观看我们的生成式AI课程视频。 LLMs和生成式AI相交，它们都是 深度学习的一部分。 你可能经常听到的另一个AI领域 是生成式AI。 这是一种能够 生成新内容的人工智能，包括文本、图像、音频、 和合成数据。 那么大型语言模型是什么？ 大型语言模型是指可以预先训练，然后进行微调 以适应特定目的的大型通用语言模型。  什么是预训练和微调（Fine Tuned）？ 想象一下训练一条狗。 通常，你会教狗基本的命令 比如坐下、过来、趴下和待在原地。 这些命令对日常生活来说足够了 帮助你的狗成为一个好的犬类公民。 但是，如果你需要特殊服务犬，比如警犬、 导盲犬或猎犬，你需要增加特殊训练。 这个概念也适用于大型语言模型。 这些模型是为通用目的而训练的 解决常见的语言问题，如文本分类、问答、  文档摘要和跨行业的文本生成。 然后，可以使用相对较小规模的领域数据集，\N将模型定制来解决零售、金融、娱乐等不同领域的特定问题。    我们进一步分解这个概念， 将其分为大型语言模型的三个主要特点。 大有两层含义。 首先是训练数据集的庞大规模， 有时达到PB级别。 其次，它指的是参数数量。 在机器学习中，参数通常被称为超参数。 参数基本上是机器从模型训练中学到的记忆和知识。  参数定义了模型在解决问题（如预测文本）的技能。  通用性意味着这些模型 足以解决常见问题。 有两个原因导致了这个想法。 首先是人类语言的共性，无论 具体任务如何。 其次是资源限制。 只有某些组织具备能力 用大量数据集训练这种大型语言模型 和大量参数。 让他们为其他人创建基本语言模型怎么样？  这导致了最后一点，预训练和微调， 意味着用大型数据集预训练一个通用目的的大型语言模型  然后用更小的数据集为特定目标进行微调。  使用大型语言模型的好处很明显。  首先，一个模型可以应用于不同的任务。 这是梦想成真。 这些经过大量数据训练并生成数十亿参数的大型语言模型  足够智能，能解决不同的任务， 包括语言翻译、句子补全、文本分类、问答等。  其次，当你定制大型语言模型来解决特定问题时， 它们需要的领域训练数据很少。 大型语言模型表现不错 即使域训练数据很少。 换句话说，它们可用于少量样本（Few-shot）甚至零样本（Zero-shot）场景。  在机器学习中，少样本是指 用最少的数据训练模型， 而零样本意味着模型能识别 在以前的训练中未明确教过的事物。  第三，大型语言模型的性能 随着数据和参数的增加而不断提高。 以PaLM为例。 2022年4月，谷歌发布了PaLM， 简称Pathways Language Model，这是一个拥有5400亿参数的模型， 在多种语言任务中都实现了最先进的性能。  PaLM是一个仅解码器的密集型Transformer模型， 它有5400亿个参数。 它利用了新的路径系统， 这使得谷歌能够在多个TPU V4集群上有效地训练一个模型。  Pathway是一种新的AI架构，它可以 同时处理多个任务，快速学习新任务， 并更好地理解世界。 该系统使PaLM能够协调分布式 加速器的计算。 我们之前提到过PaLM是一个Transformer模型。 Transformer模型包括编码器和解码器。 编码器对输入序列进行编码， 然后将其传递给解码器，解码器 学会如何解码表示， 以完成相关任务。 我们已经从传统编程发展到了神经网络和生成模型  在传统编程中，我们需要 硬编码区分猫的规则，例如： 类型：动物；腿：四条；耳朵：两个；毛发：有； 喜欢：纱线，猫薄荷。 在神经网络浪潮中，我们 可以给网络提供猫和狗的图片，然后询问， 这是一只猫吗？ 它会预测出是猫。 在生成式中，我们作为用户 可以生成自己的内容，无论是文本、图片、 音频、视频还是其他。 例如，像PaLM或LaMDA这样的模型， 或者用于对话应用的语言模型， 从互联网的多个来源获取大量数据 建立基础语言模型， 我们只需提问， 无论是输入提示还是口头对话提示。  当你问它什么是猫时，它会 告诉你它所学到的关于猫的一切。 我们来比较一下使用预训练模型的LLM开发 和传统的ML开发。 首先，使用LLM开发，你不需要成为专家。 你不需要训练样本。 也不需要训练模型。 你只需要考虑提示设计，即 创建清晰、简洁、有信息量的提示。  自然语言处理的重要部分。 在传统的机器学习中，你 需要训练样本来训练模型。 还需要计算时间和硬件。 让我们看一个文本生成用例。 问答，或者说QA，是自然语言的一个子领域 处理自动回答的任务 用自然语言提出的问题。 QA系统通常在大量的 文本和代码上进行训练。 他们能回答各种问题， 包括事实、定义和观点类问题。 关键是需要领域知识 来开发这些问答模型。 例如，需要领域知识 来开发客户支持、医疗或供应链的问答模型。  使用生成式问答，模型根据上下文直接生成自由文本。  不需要领域知识。 让我们看看给Bard提出的三个问题， Bard是由谷歌AI开发的大型语言模型聊天机器人。 问题一。 "今年的销售额是100,000美元。 支出是60,000美元。 净利润是多少？" Bard首先分享了如何计算净利润，然后 进行计算。 接着Bard给出了净利润的定义。 这是另一个问题。 现有库存为6,000个单位。 新订单需要8,000个单位。 我需要补充多少单位才能完成订单？ 巴德再次通过计算回答了这个问题。 在我们的最后一个例子中，我们有1,000个传感器 分布在10个地理区域。 每个区域平均有多少个传感器？ 巴德用一个例子回答了这个问题 解决问题的方法和一些额外的背景。 在我们的每个问题中，都得到了期望的回答。 这是因为提示设计（Prompt design）。 提示设计和提示工程（Prompt Engineering） 是自然语言处理中密切相关的两个概念。 两者都涉及创建 一个清晰、简洁、有信息量的提示。 然而，两者之间存在一些关键差异。 提示设计是创建一个提示的过程， 它针对的是这个系统正在 执行的特定任务。 例如，如果系统正在 被要求将文本从英语翻译成法语， 提示应该用英语写 并且应该指定翻译应该用法语。  提示工程是一个过程 旨在创建有助于提高性能的提示  这可能涉及使用特定领域的知识， 提供期望输出的示例， 或使用已知对特定系统有效的关键词。  提示设计是一个更通用的概念， 而提示工程则是一个更专业的概念。 提示设计至关重要，而提示工程 只对需要高度准确性或性能的系统才是必要的。  有三种类型的大型语言模型， 通用语言模型、指令调优、 和对话调优。 每种都需要用不同的方式提示。 通用语言模型根据训练数据中的语言预测下一个词， 基于训练数据中的语言。 这是一个通用语言模型的例子。 下一个词是基于训练数据中的语言标记（Token）。  在这个例子中，"the cat sat on," 下一个词应该是"the."。 你可以看到"the."是最可能的下一个词。 把这种类型想象成搜索中的自动补全。 在指令调整中，模型被训练成 根据输入的指令预测响应。  例如，总结某某文章中的文本， 以某某的风格创作一首诗， 给我一个基于某某的语义相似度的关键词列表。 在这个例子中，将文本分类为 中性、消极或积极。 在对话调整中，模型被训练成通过下一个回应来进行对话。  对话调优模型是一种特殊情况 指令调优通常是将请求构建成 与聊天机器人的问题。 对话调优预计会在 较长的来回对话中发挥作用， 通常更适合自然的类似问题的表述。  思维链推理（Chain of thought reasoning）是指观察到到的一种现象： 如果让模型先解释答案的原因， 更容易得出正确答案。  我们来看这个问题。 罗杰有五个网球。 他又买了两罐网球。 每罐有三个网球。 现在他有多少个网球？ 这个问题一开始没有回答。 模型直接得出正确答案的可能性较小。 但到了第二个问题时， 输出更有可能得出正确答案。 一个能做所有事的模型在实际应用中是有局限性的。 针对特定任务的调优可以使LLMs更可靠。 Vertex AI提供针对特定任务的基础模型。 假设你有一个用例， 你需要收集情绪，或者了解 你的客户对你的产品或服务的感受。 你可以使用分类任务 情感分析任务模型。 对于视觉任务也是一样。 如果你需要进行占用率分析 那么有一个特定于你用例的任务模型。 调优一个模型可以让你根据\N你希望模型执行的任务的示例来定制模型的响应。   本质上，它是通过在新数据上训练模型， 将模型适应到新的领域， 或一套自定义的用例集合的过程。 例如，我们可以收集训练数据 并针对法律或医学领域专门调整模型。  你还可以通过微调进一步调整模型 在这里你可以用自己的数据集 并通过调整LLM中的每个权重来重新训练模型。 这需要大规模的训练工作， 以及托管你自己微调过的模型。 比如，这里有一个由医疗数据训练出的医疗基础模型，  其任务包括问答，图像分析，寻找相似患者等等。  但是，微调的费用高昂，在许多情况下并不现实。 那么，有没有更高效的调整方法呢？ 是的。 参数效率调整方法，或称为PETM， 是在不复制模型的情况下调整大型语言模型 的方法，而无需复制模型。 基础模型本身并没有改变， 只是调整了少数几层附加层， 这些层可以在推理时交换。 生成式AI工作室让你能快速探索和定制  可在Google Cloud上用于你的应用的生成式AI模型。 生成式AI工作室帮助开发者通过提供\N各种工具和资源创建和部署生成式AI模型，   使得入门变得简单。 例如，它提供了预训练模型库、 用于精细调整模型的工具、用于将模型部署到生产环境的工具， 它提供了预训练模型库、以及供开发者分享想法和合作的社区论坛。  生成式AI应用构建器让你 无需编写任何代码就能创建Gen AI应用。 Gen AI应用构建器具有拖放界面 使设计和构建应用变得简单， 一个可视化编辑器，方便创建和编辑 应用内容，一个内置搜索引擎，允许用户 在应用内搜索信息， 以及一个会话式AI引擎， 允许用户使用自然语言与应用进行交互。 你可以创建自己的聊天机器人、数字助手、 定制搜索引擎、知识库、培训应用、 等等。 PaLM API 让你可以测试和尝试 谷歌的大型语言模型和 Gen AI 工具。 为了使原型设计更快速、更易于使用， 开发者可以将 PaLM API 与 Maker Suite 集成 并通过图形用户界面访问 API。  该套件包括许多不同的工具， 如模型训练工具、模型部署工具、 以及模型监控工具。 模型训练工具帮助开发者用不同算法训练机器学习模型在他们的数据上。  模型部署工具帮助开发者用多种部署选项 将机器学习模型部署到生产环境。 模型监控工具则帮助 开发者通过仪表盘和多种指标 监控生产环境中机器学习模型的性能。  目前就是这些。 感谢收看本课程，大型语言模型简介。 