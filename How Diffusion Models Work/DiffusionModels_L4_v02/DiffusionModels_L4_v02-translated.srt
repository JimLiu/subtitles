1
00:00:05,000 --> 00:00:12,000
在这个视频中，我们将讨论如何训练这个U-Net神经网络并让它预测噪声。

2
00:00:12,000 --> 00:00:18,043
我们的目标是让网络预测噪声，真正的任务是让它学习图像上的噪声分布，

3
00:00:18,044 --> 00:00:20,999
但也要学习什么不是噪声，像是游戏角色的特征。

4
00:00:21,000 --> 00:00:28,000
我们的做法是从训练数据中取一个游戏角色，然后给它加噪声。

5
00:00:28,000 --> 00:00:32,000
我们给它加噪声，然后让神经网络预测这个噪声。

6
00:00:32,000 --> 00:00:37,000
然后我们将预测的噪声与实际添加到图像上的噪声进行比较。

7
00:00:37,000 --> 00:00:39,000
这就是我们计算损失的方式。

8
00:00:39,000 --> 00:00:44,000
然后通过反向传播让神经网络学会更好地预测噪声。

9
00:00:44,000 --> 00:00:47,000
那么如何确定这里的噪声是什么呢？

10
00:00:47,000 --> 00:00:51,000
你可以通过时间和采样，给它不同的噪声级别。

11
00:00:51,000 --> 00:00:56,000
但在实际训练中，我们不希望神经网络一直观察同一个游戏角色图像。

12
00:00:56,000 --> 00:01:02,000
如果在一个周期内观察不同的游戏角色图像，它会更稳定，更均匀。

13
00:01:02,000 --> 00:01:05,000
所以我们实际上是随机采样一个可能的时间步长，

14
00:01:05,000 --> 00:01:08,000
然后获取相应的噪声级别，

15
00:01:08,000 --> 00:01:11,000
添加到图像中，再让神经网络预测。

16
00:01:11,000 --> 00:01:14,000
然后我们取下一个训练数据中的游戏角色图像。

17
00:01:14,000 --> 00:01:17,000
再次随机采样一个时间步长，

18
00:01:17,000 --> 00:01:19,000
它可能完全不同，就像你在这里看到的。

19
00:01:19,000 --> 00:01:24,000
然后我们把它加到这个游戏角色图像上，再次让神经网络预测添加的噪声。

20
00:01:24,000 --> 00:01:27,000
这样就得到了一个更稳定的训练方案。

21
00:01:27,000 --> 00:01:29,000
那么训练实际上是什么样子？

22
00:01:29,000 --> 00:01:32,000
这是一个巫师帽子图像。

23
00:01:32,000 --> 00:01:35,000
这是一个添加了噪声的输入图像。

24
00:01:35,000 --> 00:01:43,000
当你刚把它放入神经网络时，神经网络还没有真正学会什么是图像。

25
00:01:43,000 --> 00:01:46,000
所以预测的噪声并没有改变输入的样子。

26
00:01:46,000 --> 00:01:50,000
当它被减去时，实际上就变成了这个，看起来差不多。

27
00:01:50,000 --> 00:01:56,000
但到了第31轮时，神经网络对这个图像有了更好的理解。

28
00:01:56,000 --> 00:02:04,000
然后它预测的噪声就能从这个输入中减去，产生一个看起来像这个巫师帽的图像。

29
00:02:04,000 --> 00:02:06,000
酷，这是一个样本。

30
00:02:06,000 --> 00:02:12,000
这是多个不同样本，多个不同图像经过多轮训练的样子。

31
00:02:12,000 --> 00:02:15,000
如你所见，在第一轮训练中，这些模型与我们的目标（游戏角色）还相距甚远。

32
00:02:15,000 --> 00:02:22,000
但是，到了第32轮，你会发现这些模型已经很像小游戏角色了，即便在那之前，其实也已经有了一些形状。

33
00:02:22,000 --> 00:02:26,000
好的，现在我们通过一些代码来了解训练算法。

34
00:02:26,000 --> 00:02:29,000
首先，你需要选择一个训练图像。

35
00:02:29,000 --> 00:02:32,000
这里我们将所有数据加载到数据加载器中，

36
00:02:32,000 --> 00:02:35,000
然后将其放入一个进度条，以便我们可以看到它的变化。

37
00:02:35,000 --> 00:02:37,000
你可以将这里想象成所有的数据。

38
00:02:37,000 --> 00:02:39,000
然后我们逐个处理所有的数据样本，

39
00:02:39,000 --> 00:02:42,000
x 在这里表示一个训练图片。

40
00:02:42,000 --> 00:02:44,000
现在我们来看看 x。

41
00:02:44,000 --> 00:02:48,000
在这个循环中，我们会选择一个时间步长 T，

42
00:02:48,000 --> 00:02:51,000
它决定了噪声的级别。

43
00:02:51,000 --> 00:02:55,000
我们不会遍历所有时间步长，只采样一个时间步长 T。

44
00:02:55,000 --> 00:02:57,000
我们产生一个噪音，

45
00:02:57,000 --> 00:03:01,000
然后根据时间步长将这个噪音加到图片上，

46
00:03:01,000 --> 00:03:05,000
然后我们将这个加入了噪音的图片输入到神经网络中。

47
00:03:05,000 --> 00:03:10,000
我们还输入时间步长，因为我们也要将时间嵌入进去。

48
00:03:10,000 --> 00:03:13,000
然后神经网络预测噪音的输出。

49
00:03:13,000 --> 00:03:20,000
通过比较预测的噪音和我们实际加入的噪音，我们可以使用均方误差（MSE）计算损失。

50
00:03:20,000 --> 00:03:23,000
然后我们所要做的就是反向传播并学习。

51
00:03:23,000 --> 00:03:27,000
这样，模型就会学习什么是噪音，什么是游戏角色了。

52
00:03:27,000 --> 00:03:30,000
好的，接下来我们来看我们训练用的 Notebook。

53
00:03:30,000 --> 00:03:39,000
这些都是之前的内容，只需按 Shift+Enter 键进行设置即可。

54
00:03:39,000 --> 00:03:43,000
这里的训练超参数比较有趣，我们的批次大小是100，

55
00:03:43,000 --> 00:03:47,000
我们将进行32个轮次的训练，还有我们的学习速率。

56
00:03:47,000 --> 00:03:50,000
我将按 Shift + Enter 键来运行它。

57
00:03:50,000 --> 00:03:59,000
这里的设置模型和噪音计划与之前相似。

58
00:03:59,000 --> 00:04:00,000
现在开始训练。

59
00:04:00,000 --> 00:04:05,000
你可以加载你的数据集，我们将它加载到数据加载器中。

60
00:04:05,000 --> 00:04:09,000
这是一个16x16的游戏角色数据集。

61
00:04:09,000 --> 00:04:12,000
我们也加载了优化器。

62
00:04:12,000 --> 00:04:17,000
这里有一个函数，它会扰乱我们的输入，

63
00:04:17,000 --> 00:04:23,000
意思是它会根据特定的时间步长向图像添加适当级别的噪音，并返回图像。

64
00:04:23,000 --> 00:04:26,000
我可以在这里按 Shift + Enter 键。

65
00:04:26,000 --> 00:04:31,000
由于在 CPU 上进行训练需要很多小时，因此我们在这里实际上不会逐步进行训练，

66
00:04:31,000 --> 00:04:33,000
这也是这些 Notebook 托管的位置。

67
00:04:33,000 --> 00:04:36,000
但我非常建议你走一遍这个过程。

68
00:04:36,000 --> 00:04:41,000
这就是我们刚刚一起看过的那段代码。

69
00:04:41,000 --> 00:04:45,000
但我们可以做的是，我们确实训练了这个模型，并在不同的训练轮次中保存了模型，

70
00:04:45,000 --> 00:04:50,000
这样你就可以运行采样，并能够看到它在每个训练轮次中的表现。

71
00:04:50,000 --> 00:04:54,000
这是你之前看到的相同的采样代码。

72
00:04:54,000 --> 00:04:56,000
我会快速过一下。

73
00:04:56,000 --> 00:05:00,000
这里是你加载第零轮次的模型的地方。

74
00:05:00,000 --> 00:05:05,000
这是模型检查点的路径，第零轮次的模型。

75
00:05:05,000 --> 00:05:08,000
我要加载这个模型。

76
00:05:08,000 --> 00:05:10,000
然后你可以直接可视化这些样本。

77
00:05:10,000 --> 00:05:16,000
再次运行之前相同的采样方法，这个方法在上一个视频中有讲解，叫做DDPM。

78
00:05:16,000 --> 00:05:19,000
这需要几分钟，我们将在视频中加快这个过程。

79
00:05:19,000 --> 00:05:20,000
非常好！

80
00:05:20,000 --> 00:05:25,000
我们可以在这里点击播放。

81
00:05:25,000 --> 00:05:31,000
虽然还有点不清晰，但已经开始理解游戏角色的大致轮廓。

82
00:05:31,000 --> 00:05:32,000
它并不是纯粹的噪音。

83
00:05:32,000 --> 00:05:35,000
我们也有第四轮的模型让你参考。

84
00:05:35,000 --> 00:05:37,000
你可以看到模型在改进，

85
00:05:37,000 --> 00:05:40,000
这些看起来更像游戏角色了。

86
00:05:40,000 --> 00:05:43,000
接下来是第八轮。

87
00:05:43,000 --> 00:05:45,000
再进一步，

88
00:05:45,000 --> 00:05:50,000
你可以看到里面有些书。

89
00:05:50,000 --> 00:05:54,000
最后，这是第31轮，

90
00:05:54,000 --> 00:05:57,000
或者当我们从零开始计数时，可能实际上是第32轮。

91
00:05:57,000 --> 00:05:59,000
这些看起来更像游戏角色图像了。

92
00:05:59,000 --> 00:06:01,000
你可以看到这里有一把剑。

93
00:06:01,000 --> 00:06:04,000
这可能是巫师帽。

94
00:06:04,000 --> 00:06:06,000
这里有个药水。

95
00:06:06,000 --> 00:06:09,000
但当然，这里还有一些斑点，一些人物。

96
00:06:09,000 --> 00:06:12,000
它还不够完美，还可以继续优化。

97
00:06:12,000 --> 00:06:19,000
在下一个视频中，你将可以控制你生成的内容，也就是你可以指定它生成物体或者这些人物。
