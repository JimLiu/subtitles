1
00:00:05,000 --> 00:00:12,000
在这个视频中，我们将讨论如何训练这个U-Net神经网络并让它预测噪声。
In this video, we'll discuss how to train this U-Net neural network and get it to predict noise.

2
00:00:12,000 --> 00:00:18,043
我们的目标是让网络预测噪声，真正的任务是让它学习图像上的噪声分布，
So the goal of the neural network is for it to predict noise, and really it learns the distribution of what is noise on the image,

3
00:00:18,044 --> 00:00:20,999
但也要学习什么不是噪声，像是游戏角色的特征。
but also what is not noise, what is sprite likeness, right?

4
00:00:21,000 --> 00:00:28,000
我们的做法是从训练数据中取一个游戏角色，然后给它加噪声。
And so how we do that is that we take a sprite from our training data and we actually add noise to it.

5
00:00:28,000 --> 00:00:32,000
我们给它加噪声，然后让神经网络预测这个噪声。
We add noise to it and we give it to the neural network and we ask the neural network to predict that noise.

6
00:00:32,000 --> 00:00:37,000
然后我们将预测的噪声与实际添加到图像上的噪声进行比较。
And then we compare the predicted noise against the actual noise that was added to that image.

7
00:00:37,000 --> 00:00:39,000
这就是我们计算损失的方式。
And that's how we compute the loss.

8
00:00:39,000 --> 00:00:44,000
然后通过反向传播让神经网络学会更好地预测噪声。
And that backprops through the neural network so that the neural network learns to predict that noise better.

9
00:00:44,000 --> 00:00:47,000
那么如何确定这里的噪声是什么呢？
So how do you determine what this noise here is?

10
00:00:47,000 --> 00:00:51,000
你可以通过时间和采样，给它不同的噪声级别。
You could just go through time and sampling and give it different noise levels.

11
00:00:51,000 --> 00:00:56,000
但在实际训练中，我们不希望神经网络一直观察同一个游戏角色图像。
But realistically in training, we don't want the neural network to be looking at the same sprite all the time.

12
00:00:56,000 --> 00:01:02,000
如果在一个周期内观察不同的游戏角色图像，它会更稳定，更均匀。
It helps it to be more stable if it looks at different sprites across an epoch and it's just more uniform.

13
00:01:02,000 --> 00:01:05,000
所以我们实际上是随机采样一个可能的时间步长，
So actually what we do is we randomly sample what this time step could be.

14
00:01:05,000 --> 00:01:08,000
然后获取相应的噪声级别，
We then get the noise level appropriate to that time step.

15
00:01:08,000 --> 00:01:11,000
添加到图像中，再让神经网络预测。
We add it to this image and then we have the neural network predict it.

16
00:01:11,000 --> 00:01:14,000
然后我们取下一个训练数据中的游戏角色图像。
We take the next sprite image in our training data.

17
00:01:14,000 --> 00:01:17,000
再次随机采样一个时间步长，
We again sample a random time step.

18
00:01:17,000 --> 00:01:19,000
它可能完全不同，就像你在这里看到的。
It could be totally different like you see here.

19
00:01:19,000 --> 00:01:24,000
然后我们把它加到这个游戏角色图像上，再次让神经网络预测添加的噪声。
And then we add it to this sprite image and again we have the neural network predict the noise that was added.

20
00:01:24,000 --> 00:01:27,000
这样就得到了一个更稳定的训练方案。
And this results in a much more stable training scheme.

21
00:01:27,000 --> 00:01:29,000
那么训练实际上是什么样子？
So what does training actually look like?

22
00:01:29,000 --> 00:01:32,000
这是一个巫师帽子图像。
Here is a wizard hat sprite.

23
00:01:32,000 --> 00:01:35,000
这是一个添加了噪声的输入图像。
And here is what a noised input would look like.

24
00:01:35,000 --> 00:01:43,000
当你刚把它放入神经网络时，神经网络还没有真正学会什么是图像。
And when you first put it into the neural network at epoch zero, the neural network hasn't really learned what a sprite is yet.

25
00:01:43,000 --> 00:01:46,000
所以预测的噪声并没有改变输入的样子。
So the predicted noise doesn't quite change what the input looks like.

26
00:01:46,000 --> 00:01:50,000
当它被减去时，实际上就变成了这个，看起来差不多。
And when it's subtracted out, it actually just turns into this which looks about the same.

27
00:01:50,000 --> 00:01:56,000
但到了第31轮时，神经网络对这个图像有了更好的理解。
But by the time you get to epoch 31, the neural network has a better understanding of what this sprite looks like.

28
00:01:56,000 --> 00:02:04,000
然后它预测的噪声就能从这个输入中减去，产生一个看起来像这个巫师帽的图像。
So then it predicts noise that is then subtracted from this input to produce something that does look like this wizard hat sprite.

29
00:02:04,000 --> 00:02:06,000
酷，这是一个样本。
Cool, so that was for one sample.

30
00:02:06,000 --> 00:02:12,000
这是多个不同样本，多个不同图像经过多轮训练的样子。
This is for multiple different samples, multiple different sprites across many epochs and what that looks like.

31
00:02:12,000 --> 00:02:15,000
如你所见，在第一轮训练中，这些模型与我们的目标（游戏角色）还相距甚远。
As you can see in this first epoch, it is quite far from sprites.

32
00:02:15,000 --> 00:02:22,000
但是，到了第32轮，你会发现这些模型已经很像小游戏角色了，即便在那之前，其实也已经有了一些形状。
But by the time you get to epoch 32 here, it looks quite like little video game characters and even before that.

33
00:02:22,000 --> 00:02:26,000
好的，现在我们通过一些代码来了解训练算法。
All right, so now we'll go through the training algorithm with some code.

34
00:02:26,000 --> 00:02:29,000
首先，你需要选择一个训练图像。
So first you want to sample a training image.

35
00:02:29,000 --> 00:02:32,000
这里我们将所有数据加载到数据加载器中，
So here we are loading up all the data into the data loader.

36
00:02:32,000 --> 00:02:35,000
然后将其放入一个进度条，以便我们可以看到它的变化。
We're putting into a progress bar so that we can visualize it.

37
00:02:35,000 --> 00:02:37,000
你可以将这里想象成所有的数据。
But essentially imagine all the data here.

38
00:02:37,000 --> 00:02:39,000
然后我们逐个处理所有的数据样本，
We're then iterating through all of the data samples.

39
00:02:39,000 --> 00:02:42,000
x 在这里表示一个训练图片。
So X here is a training image.

40
00:02:42,000 --> 00:02:44,000
现在我们来看看 x。
So just looking at X now.

41
00:02:44,000 --> 00:02:48,000
在这个循环中，我们会选择一个时间步长 T，
Within this loop, we are sampling a time step T.

42
00:02:48,000 --> 00:02:51,000
它决定了噪声的级别。
And this determines the level of noise.

43
00:02:51,000 --> 00:02:55,000
我们不会遍历所有时间步长，只采样一个时间步长 T。
We're not going through all the time steps, just sampling a time step T.

44
00:02:55,000 --> 00:02:57,000
我们产生一个噪音，
We sample a noise.

45
00:02:57,000 --> 00:03:01,000
然后根据时间步长将这个噪音加到图片上，
We add that noise to the image based on that time step.

46
00:03:01,000 --> 00:03:05,000
然后我们将这个加入了噪音的图片输入到神经网络中。
And then we input that noised image into the neural network.

47
00:03:05,000 --> 00:03:10,000
我们还输入时间步长，因为我们也要将时间嵌入进去。
We also put in the time step because we also care about adding that time embedding in.

48
00:03:10,000 --> 00:03:13,000
然后神经网络预测噪音的输出。
And the neural network predicts the noise as output.

49
00:03:13,000 --> 00:03:20,000
通过比较预测的噪音和我们实际加入的噪音，我们可以使用均方误差（MSE）计算损失。
Comparing that predicted noise with the noise that we actually added, we can compute the loss using mean squared error, MSE.

50
00:03:20,000 --> 00:03:23,000
然后我们所要做的就是反向传播并学习。
And then all we have to do is back prop and learn.

51
00:03:23,000 --> 00:03:27,000
这样，模型就会学习什么是噪音，什么是游戏角色了。
So the model will then learn what is noise and what is sprite.

52
00:03:27,000 --> 00:03:30,000
好的，接下来我们来看我们训练用的 Notebook。
Cool, so on to our training notebook here.

53
00:03:30,000 --> 00:03:39,000
这些都是之前的内容，只需按 Shift+Enter 键进行设置即可。
So this is all the same as before, just hitting shift enter, setting things up with the unit.

54
00:03:39,000 --> 00:03:43,000
这里的训练超参数比较有趣，我们的批次大小是100，
Here what's interesting is, you know, our training hyperparameters, our batch size of 100,

55
00:03:43,000 --> 00:03:47,000
我们将进行32个轮次的训练，还有我们的学习速率。
and we are going through 32 different epochs and our learning rate.

56
00:03:47,000 --> 00:03:50,000
我将按 Shift + Enter 键来运行它。
I'm just going to shift enter there to run it.

57
00:03:50,000 --> 00:03:59,000
这里的设置模型和噪音计划与之前相似。
Again, similar things here of setting up the model and the noise schedule for those scaling parameters.

58
00:03:59,000 --> 00:04:00,000
现在开始训练。
Now here's where you get into training.

59
00:04:00,000 --> 00:04:05,000
你可以加载你的数据集，我们将它加载到数据加载器中。
So you can load your data set, and we're loading it into that data loader here.

60
00:04:05,000 --> 00:04:09,000
这是一个16x16的游戏角色数据集。
It's this 16 by 16 sprites data set.

61
00:04:09,000 --> 00:04:12,000
我们也加载了优化器。
And we're also loading up our optimizer.

62
00:04:12,000 --> 00:04:17,000
这里有一个函数，它会扰乱我们的输入，
And here's the function that perturbs our input, meaning that it takes the image,

63
00:04:17,000 --> 00:04:23,000
意思是它会根据特定的时间步长向图像添加适当级别的噪音，并返回图像。
it adds the right noise level for that specific time step to that image, and returns it.

64
00:04:23,000 --> 00:04:26,000
我可以在这里按 Shift + Enter 键。
So I can hit Shift+Enter here.

65
00:04:26,000 --> 00:04:31,000
由于在 CPU 上进行训练需要很多小时，因此我们在这里实际上不会逐步进行训练，
So here we won't actually step through training because it takes many hours on CPU,

66
00:04:31,000 --> 00:04:33,000
这也是这些 Notebook 托管的位置。
and that's where these notebooks are hosted.

67
00:04:33,000 --> 00:04:36,000
但我非常建议你走一遍这个过程。
But I really recommend that you do go through this.

68
00:04:36,000 --> 00:04:41,000
这就是我们刚刚一起看过的那段代码。
This is the exact code that we had just looked at together.

69
00:04:41,000 --> 00:04:45,000
但我们可以做的是，我们确实训练了这个模型，并在不同的训练轮次中保存了模型，
But what we can do is that we did train this model and save the model at different epochs,

70
00:04:45,000 --> 00:04:50,000
这样你就可以运行采样，并能够看到它在每个训练轮次中的表现。
such that you can then run sampling and be able to see how it does at each epoch.

71
00:04:50,000 --> 00:04:54,000
这是你之前看到的相同的采样代码。
So this is, again, the same sampling code you saw before.

72
00:04:54,000 --> 00:04:56,000
我会快速过一下。
I'm just going to breeze through that.

73
00:04:56,000 --> 00:05:00,000
这里是你加载第零轮次的模型的地方。
And here is where you would load the model for epoch zero.

74
00:05:00,000 --> 00:05:05,000
这是模型检查点的路径，第零轮次的模型。
So this is the path to that model checkpoint, model_0 for epoch zero.

75
00:05:05,000 --> 00:05:08,000
我要加载这个模型。
I'm going to load that model.

76
00:05:08,000 --> 00:05:10,000
然后你可以直接可视化这些样本。
And then here you can just visualize the samples.

77
00:05:10,000 --> 00:05:16,000
再次运行之前相同的采样方法，这个方法在上一个视频中有讲解，叫做DDPM。
And, again, this is running the same sampling method as before called DDPM that you learned in the previous video.

78
00:05:16,000 --> 00:05:19,000
这需要几分钟，我们将在视频中加快这个过程。
This takes a couple minutes, and we'll speed this up in the video.

79
00:05:19,000 --> 00:05:20,000
非常好！
Great.

80
00:05:20,000 --> 00:05:25,000
我们可以在这里点击播放。
So we can hit play here.

81
00:05:25,000 --> 00:05:31,000
虽然还有点不清晰，但已经开始理解游戏角色的大致轮廓。
A bit amorphous still, but, you know, starting to understand the general outlines of sprites.

82
00:05:31,000 --> 00:05:32,000
它并不是纯粹的噪音。
It's not pure noise.

83
00:05:32,000 --> 00:05:35,000
我们也有第四轮的模型让你参考。
So we also have epoch four here for you to see.

84
00:05:35,000 --> 00:05:37,000
你可以看到模型在改进，
So you can see the model improving.

85
00:05:37,000 --> 00:05:40,000
这些看起来更像游戏角色了。
These look a little bit more like sprites.

86
00:05:40,000 --> 00:05:43,000
接下来是第八轮。
And epoch eight.

87
00:05:43,000 --> 00:05:45,000
再进一步，
A little bit more.

88
00:05:45,000 --> 00:05:50,000
你可以看到里面有些书。
See some books in there, actually.

89
00:05:50,000 --> 00:05:54,000
最后，这是第31轮，
And, finally, Epoch 31.

90
00:05:54,000 --> 00:05:57,000
或者当我们从零开始计数时，可能实际上是第32轮。
Or this might actually be 32 when we index from zero.

91
00:05:57,000 --> 00:05:59,000
这些看起来更像游戏角色图像了。
So these look a lot more like sprites.

92
00:05:59,000 --> 00:06:01,000
你可以看到这里有一把剑。
You can see a sword here.

93
00:06:01,000 --> 00:06:04,000
这可能是巫师帽。
This is probably the wizard hat.

94
00:06:04,000 --> 00:06:06,000
这里有个药水。
See a potion here.

95
00:06:06,000 --> 00:06:09,000
但当然，这里还有一些斑点，一些人物。
But, of course, there are still some blobs here and there, some people here.

96
00:06:09,000 --> 00:06:12,000
它还不够完美，还可以继续优化。
So it's not perfect, and it could keep going.

97
00:06:12,000 --> 00:06:19,000
在下一个视频中，你将可以控制你生成的内容，也就是你可以指定它生成物体或者这些人物。
So in the next video, you'll get to control what you generate, meaning you can tell it to generate objects or these people, for example.
