[Script Info]

Title: DiffusionModels_L3_v02
ScriptType: v4.00+
WrapStyle: 0
Collisions: Reverse
PlayResX: 384
PlayResY: 288
Timer: 100.0000
ScaledBorderAndShadow: no
Last Style Storage: Default
Video Aspect Ratio: 0
Video Zoom: 6
Video Position: 0

[V4+ Styles]
Format: Name,Fontname,Fontsize,PrimaryColour,SecondaryColour,OutlineColour,BackColour,Bold,Italic,Underline,StrikeOut,ScaleX,ScaleY,Spacing,Angle,BorderStyle,Outline,Shadow,Alignment,MarginL,MarginR,MarginV,Encoding
Style: Default,LXGW WenKai,20,&H000092FE,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,2,2,1,1,6,1
Style: Secondary,Helvetica,12,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,2,2,1,1,6,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:05.0,0:00:13.20,Secondary,,0,0,0,,In this video, we'll go over the neural network, the architecture of it, and how we can incorporate additional information into it.
Dialogue: 0,0:00:13.20,0:00:18.96,Secondary,,0,0,0,,So the neural network architecture that we use for diffusion models is a UNet.
Dialogue: 0,0:00:18.96,0:00:21.79,Secondary,,0,0,0,,And the most important thing that you need to know about a UNet is that
Dialogue: 0,0:00:21.79,0:00:32.96,Secondary,,0,0,0,,it is taking as input this image and it's producing as output something of the same size as that image, but here it is that predicted noise.
Dialogue: 0,0:00:32.96,0:00:40.4,Secondary,,0,0,0,,UNets have been around for a very long time, since 2015, and it was first used for image segmentation.
Dialogue: 0,0:00:40.4,0:00:45.52,Secondary,,0,0,0,,It was first used to take an image and actually segment it into either a pedestrian or a car,
Dialogue: 0,0:00:45.52,0:00:48.48,Secondary,,0,0,0,,so it's used a lot in self-driving car research.
Dialogue: 0,0:00:48.48,0:00:53.88,Secondary,,0,0,0,,But what's special about UNets is just that its input and outputs are the same size.
Dialogue: 0,0:00:53.88,0:00:57.89,Secondary,,0,0,0,,And what it does is it first embeds information about this input,
Dialogue: 0,0:00:57.89,0:01:06.37,Secondary,,0,0,0,,so it downsamples with a lot of convolutional layers into an embedding that compresses all that information into a small amount of space,
Dialogue: 0,0:01:06.57,0:01:13.88,Secondary,,0,0,0,,and then it upsamples with the same number of upsampling blocks into the output back out for its task.
Dialogue: 0,0:01:13.88,0:01:18.52,Secondary,,0,0,0,,And in this case, that task is to predict the noise that was applied to this image.
Dialogue: 0,0:01:18.52,0:01:21.17,Secondary,,0,0,0,,And if you want to look a little bit deeper, which we'll do together,
Dialogue: 0,0:01:21.17,0:01:27.28,Secondary,,0,0,0,,is that each of these named blocks here are also shown in the code with the same names.
Dialogue: 0,0:01:27.28,0:01:34.76,Secondary,,0,0,0,,And this predicted noise is the same dimension, 16,16 by 3, of the original input image.
Dialogue: 0,0:01:34.76,0:01:38.68,Secondary,,0,0,0,,What's also great about this UNet is that it can take in additional information.
Dialogue: 0,0:01:38.68,0:01:44.24,Secondary,,0,0,0,,So it's compressed that image to understand what's going on, but it can also take in more information.
Dialogue: 0,0:01:44.24,0:01:46.32,Secondary,,0,0,0,,And so what information do we want to include?
Dialogue: 0,0:01:46.32,0:01:50.94,Secondary,,0,0,0,,Well, one thing that's really important for these models is the time embedding.
Dialogue: 0,0:01:50.94,0:01:55.66,Secondary,,0,0,0,,And so this is an embedding that kind of tells the model what the time step is,
Dialogue: 0,0:01:55.66,0:01:58.72,Secondary,,0,0,0,,and therefore what kind of noise level we need.
Dialogue: 0,0:01:58.72,0:02:02.72,Secondary,,0,0,0,,And all you have to do for this time embedding is you embed it into some kind of vector,
Dialogue: 0,0:02:02.72,0:02:06.32,Secondary,,0,0,0,,and you can add it into these upsampling blocks.
Dialogue: 0,0:02:06.32,0:02:10.28,Secondary,,0,0,0,,Another piece of information that could be useful is a context embedding.
Dialogue: 0,0:02:10.28,0:02:16.4,Secondary,,0,0,0,,We'll do more of this later, but all that context embedding does is it helps you control what the model generates.
Dialogue: 0,0:02:16.4,0:02:22.68,Secondary,,0,0,0,,For example, a text description, like you really want it to be Bob, or some kind of factor like it needs to be a certain color.
Dialogue: 0,0:02:22.68,0:02:24.88,Secondary,,0,0,0,,We'll discuss this a bit more later.
Dialogue: 0,0:02:24.88,0:02:27.44,Secondary,,0,0,0,,And for that context embedding, you can just multiply it in.
Dialogue: 0,0:02:27.44,0:02:28.64,Secondary,,0,0,0,,Great.
Dialogue: 0,0:02:28.64,0:02:30.56,Secondary,,0,0,0,,So what does that look like in code?
Dialogue: 0,0:02:30.56,0:02:32.56,Secondary,,0,0,0,,Here you can see a context embedding.
Dialogue: 0,0:02:32.56,0:02:33.94,Secondary,,0,0,0,,This is just one of them.
Dialogue: 0,0:02:33.94,0:02:35.96,Secondary,,0,0,0,,And then here you see the time embedding.
Dialogue: 0,0:02:35.96,0:02:39.43,Secondary,,0,0,0,,And in the upsampling block, all you have to do again, just like in this diagram,
Dialogue: 0,0:02:39.44,0:02:45.12,Secondary,,0,0,0,,you multiply the context embedding with the upsampling block, and you add the time embedding.
Dialogue: 0,0:02:45.12,0:02:46.12,Secondary,,0,0,0,,Cool.
Dialogue: 0,0:02:46.12,0:02:49.96,Secondary,,0,0,0,,So now in the notebook, in the forward pass of the model, so this is running the model,
Dialogue: 0,0:02:49.96,0:02:56.96,Secondary,,0,0,0,,you can see some of these down, down, down blocks, and then also these up, up, up blocks here.
Dialogue: 0,0:02:56.96,0:02:59.36,Secondary,,0,0,0,,And again, here are your context and time embeddings.
Dialogue: 0,0:02:59.36,0:03:02.56,Secondary,,0,0,0,,We have two of them here for each of those up blocks.
Dialogue: 0,0:03:02.56,0:03:13.12,Secondary,,0,0,0,,And how these down and up blocks are defined is up here in initialization for the UNet.
Dialogue: 0,0:03:13.12,0:03:16.0,Secondary,,0,0,0,,And so for the down, this is what a UNet down looks like.
Dialogue: 0,0:03:16.0,0:03:20.96,Secondary,,0,0,0,,And we actually do have that in our helper functions if you want to look at them in greater detail.
Dialogue: 0,0:03:20.96,0:03:23.54,Secondary,,0,0,0,,But they are just convolutional blocks.
Dialogue: 0,0:03:23.54,0:03:26.80,Secondary,,0,0,0,,And in the next video, you'll learn how to train this neural network.
Dialogue: 0,0:00:05.0,0:00:13.20,Default,,0,0,0,,在这个视频中，我们将介绍\N神经网络和它的架构，以及\N如何将额外信息融入其中。
Dialogue: 0,0:00:13.20,0:00:18.96,Default,,0,0,0,,我们用于扩散模型的\N神经网络架构是一个UNet。
Dialogue: 0,0:00:18.96,0:00:21.79,Default,,0,0,0,,关于UNet最重要的是，
Dialogue: 0,0:00:21.79,0:00:32.96,Default,,0,0,0,,它将图像作为输入，\N输出与图像大小相同的预测噪声。
Dialogue: 0,0:00:32.96,0:00:40.4,Default,,0,0,0,,UNet已经存在\N很长时间了，自2015年以来，\N它首次被用于图像分割。
Dialogue: 0,0:00:40.4,0:00:45.52,Default,,0,0,0,,它最初被用来\N将一张图片中的行人或汽车分割出来，
Dialogue: 0,0:00:45.52,0:00:48.48,Default,,0,0,0,,因此在自动驾驶汽车\N研究中得到了广泛应用。
Dialogue: 0,0:00:48.48,0:00:53.88,Default,,0,0,0,,但UNet的特殊之处在于\N其输入和输出大小相同。
Dialogue: 0,0:00:53.88,0:00:57.89,Default,,0,0,0,,它首先将这个输入的信息嵌入，
Dialogue: 0,0:00:57.89,0:01:06.37,Default,,0,0,0,,通过许多卷积层将其降采样\N到一个压缩了所有信息的嵌入中，
Dialogue: 0,0:01:06.57,0:01:13.88,Default,,0,0,0,,然后用相同数量的\N上采样块将输出返回到任务中。
Dialogue: 0,0:01:13.88,0:01:18.52,Default,,0,0,0,,在这个例子中，它的任务\N就是预测应用到这个图片上的噪音。
Dialogue: 0,0:01:18.52,0:01:21.17,Default,,0,0,0,,如果你想深入了解，\N我们可以一起来看看，
Dialogue: 0,0:01:21.17,0:01:27.28,Default,,0,0,0,,这些命名块在代码中\N也用相同的名称显示。
Dialogue: 0,0:01:27.28,0:01:34.76,Default,,0,0,0,,这个预测的噪声与原始输入\N图像的尺寸相同，16x16x3。
Dialogue: 0,0:01:34.76,0:01:38.68,Default,,0,0,0,,UNet的另一个优点是\N它可以接收额外的信息。
Dialogue: 0,0:01:38.68,0:01:44.24,Default,,0,0,0,,所以它压缩了图像以了解发生\N了什么，但也可以接收更多信息。
Dialogue: 0,0:01:44.24,0:01:46.32,Default,,0,0,0,,那么我们想要包括拿些信息呢？
Dialogue: 0,0:01:46.32,0:01:50.94,Default,,0,0,0,,对于这些模型来说，\N一个非常重要的信息就是时间嵌入。
Dialogue: 0,0:01:50.94,0:01:55.66,Default,,0,0,0,,这是一种告诉模型时间步长的嵌入，
Dialogue: 0,0:01:55.66,0:01:58.72,Default,,0,0,0,,因此我们需要某种级别的噪音。
Dialogue: 0,0:01:58.72,0:02:02.72,Default,,0,0,0,,对于这个时间嵌入，你需要\N做的就是将它嵌入到一个向量中，
Dialogue: 0,0:02:02.72,0:02:06.32,Default,,0,0,0,,然后将其添加到这些上采样块中。
Dialogue: 0,0:02:06.32,0:02:10.28,Default,,0,0,0,,另一个有用的信息是上下文嵌入。
Dialogue: 0,0:02:10.28,0:02:16.4,Default,,0,0,0,,我们稍后会更深入地讨论\N这个，但上下文嵌入的作用就是\N帮助你控制模型生成的内容。
Dialogue: 0,0:02:16.4,0:02:22.68,Default,,0,0,0,,例如，一个文本描述，\N你想让它生成的是Bob，或者\N某种因子，比如需要是某种颜色。
Dialogue: 0,0:02:22.68,0:02:24.88,Default,,0,0,0,,稍后我们会再讨论这个问题。
Dialogue: 0,0:02:24.88,0:02:27.44,Default,,0,0,0,,对于这个上下文嵌入，\N你只需要将它乘进去就可以了。
Dialogue: 0,0:02:27.44,0:02:28.64,Default,,0,0,0,,很好！
Dialogue: 0,0:02:28.64,0:02:30.56,Default,,0,0,0,,那么这在代码中是什么样子的呢？
Dialogue: 0,0:02:30.56,0:02:32.56,Default,,0,0,0,,这里你可以看到一个上下文嵌入。
Dialogue: 0,0:02:32.56,0:02:33.94,Default,,0,0,0,,这只是其中之一。
Dialogue: 0,0:02:33.94,0:02:35.96,Default,,0,0,0,,然后在这里你可以看到时间嵌入。
Dialogue: 0,0:02:35.96,0:02:39.43,Default,,0,0,0,,在上采样模块中，你需要\N做的就是像图示中那样，
Dialogue: 0,0:02:39.44,0:02:45.12,Default,,0,0,0,,把上下文嵌入乘以上采样块，\N然后加上时间嵌入。
Dialogue: 0,0:02:45.12,0:02:46.12,Default,,0,0,0,,很好！
Dialogue: 0,0:02:46.12,0:02:49.96,Default,,0,0,0,,那么现在，在 Notebook 的\N模型前向传递中，这就是运行模型，
Dialogue: 0,0:02:49.96,0:02:56.96,Default,,0,0,0,,你可以看到一些这样的下采样块，\N然后也有这些上采样块。
Dialogue: 0,0:02:56.96,0:02:59.36,Default,,0,0,0,,再次强调，这里是\N你的上下文和时间嵌入。
Dialogue: 0,0:02:59.36,0:03:02.56,Default,,0,0,0,,我们在这里为每一个\N上采样块都设置了两个。
Dialogue: 0,0:03:02.56,0:03:13.12,Default,,0,0,0,,这些上采样和下采样块是如何定义\N的，是在UNet的初始化部分定义的。
Dialogue: 0,0:03:13.12,0:03:16.0,Default,,0,0,0,,所以对于下采样，这就是\N一个UNet下采样的样子。
Dialogue: 0,0:03:16.0,0:03:20.96,Default,,0,0,0,,如果你想详细了解的话我们实际\N上在我们的辅助函数中也有这个。
Dialogue: 0,0:03:20.96,0:03:23.54,Default,,0,0,0,,但它们就是卷积块。
Dialogue: 0,0:03:23.54,0:03:26.80,Default,,0,0,0,,在下一个视频中，你将\N学会如何训练这个神经网络。