1
00:00:05,000 --> 00:00:13,200
在这个视频中，我们将介绍神经网络和它的架构，以及如何将额外信息融入其中。
In this video, we'll go over the neural network, the architecture of it, and how we can incorporate additional information into it.

2
00:00:13,200 --> 00:00:18,960
我们用于扩散模型的神经网络架构是一个UNet。
So the neural network architecture that we use for diffusion models is a UNet.

3
00:00:18,960 --> 00:00:21,786
关于UNet最重要的是，
And the most important thing that you need to know about a UNet is that

4
00:00:21,787 --> 00:00:32,960
它将图像作为输入，输出与图像大小相同的预测噪声。
it is taking as input this image and it's producing as output something of the same size as that image, but here it is that predicted noise.

5
00:00:32,960 --> 00:00:40,040
UNet已经存在很长时间了，自2015年以来，它首次被用于图像分割。
UNets have been around for a very long time, since 2015, and it was first used for image segmentation.

6
00:00:40,040 --> 00:00:45,520
它最初被用来将一张图片中的行人或汽车分割出来，
It was first used to take an image and actually segment it into either a pedestrian or a car,

7
00:00:45,520 --> 00:00:48,480
因此在自动驾驶汽车研究中得到了广泛应用。
so it's used a lot in self-driving car research.

8
00:00:48,480 --> 00:00:53,880
但UNet的特殊之处在于其输入和输出大小相同。
But what's special about UNets is just that its input and outputs are the same size.

9
00:00:53,880 --> 00:00:57,886
它首先将这个输入的信息嵌入，
And what it does is it first embeds information about this input,

10
00:00:57,887 --> 00:01:06,368
通过许多卷积层将其降采样到一个压缩了所有信息的嵌入中，
so it downsamples with a lot of convolutional layers into an embedding that compresses all that information into a small amount of space,

11
00:01:06,568 --> 00:01:13,880
然后用相同数量的上采样块将输出返回到任务中。
and then it upsamples with the same number of upsampling blocks into the output back out for its task.

12
00:01:13,880 --> 00:01:18,520
在这个例子中，它的任务就是预测应用到这个图片上的噪音。
And in this case, that task is to predict the noise that was applied to this image.

13
00:01:18,520 --> 00:01:21,171
如果你想深入了解，我们可以一起来看看，
And if you want to look a little bit deeper, which we'll do together,

14
00:01:21,172 --> 00:01:27,280
这些命名块在代码中也用相同的名称显示。
is that each of these named blocks here are also shown in the code with the same names.

15
00:01:27,280 --> 00:01:34,760
这个预测的噪声与原始输入图像的尺寸相同，16x16x3。
And this predicted noise is the same dimension, 16,16 by 3, of the original input image.

16
00:01:34,760 --> 00:01:38,680
UNet的另一个优点是它可以接收额外的信息。
What's also great about this UNet is that it can take in additional information.

17
00:01:38,680 --> 00:01:44,240
所以它压缩了图像以了解发生了什么，但也可以接收更多信息。
So it's compressed that image to understand what's going on, but it can also take in more information.

18
00:01:44,240 --> 00:01:46,320
那么我们想要包括拿些信息呢？
And so what information do we want to include?

19
00:01:46,320 --> 00:01:50,940
对于这些模型来说，一个非常重要的信息就是时间嵌入。
Well, one thing that's really important for these models is the time embedding.

20
00:01:50,940 --> 00:01:55,656
这是一种告诉模型时间步长的嵌入，
And so this is an embedding that kind of tells the model what the time step is,

21
00:01:55,657 --> 00:01:58,720
因此我们需要某种级别的噪音。
and therefore what kind of noise level we need.

22
00:01:58,720 --> 00:02:02,720
对于这个时间嵌入，你需要做的就是将它嵌入到一个向量中，
And all you have to do for this time embedding is you embed it into some kind of vector,

23
00:02:02,720 --> 00:02:06,320
然后将其添加到这些上采样块中。
and you can add it into these upsampling blocks.

24
00:02:06,320 --> 00:02:10,280
另一个有用的信息是上下文嵌入。
Another piece of information that could be useful is a context embedding.

25
00:02:10,280 --> 00:02:16,040
我们稍后会更深入地讨论这个，但上下文嵌入的作用就是帮助你控制模型生成的内容。
We'll do more of this later, but all that context embedding does is it helps you control what the model generates.

26
00:02:16,040 --> 00:02:22,680
例如，一个文本描述，你想让它生成的是Bob，或者某种因子，比如需要是某种颜色。
For example, a text description, like you really want it to be Bob, or some kind of factor like it needs to be a certain color.

27
00:02:22,680 --> 00:02:24,880
稍后我们会再讨论这个问题。
We'll discuss this a bit more later.

28
00:02:24,880 --> 00:02:27,440
对于这个上下文嵌入，你只需要将它乘进去就可以了。
And for that context embedding, you can just multiply it in.

29
00:02:27,440 --> 00:02:28,640
很好！
Great.

30
00:02:28,640 --> 00:02:30,560
那么这在代码中是什么样子的呢？
So what does that look like in code?

31
00:02:30,560 --> 00:02:32,560
这里你可以看到一个上下文嵌入。
Here you can see a context embedding.

32
00:02:32,560 --> 00:02:33,940
这只是其中之一。
This is just one of them.

33
00:02:33,940 --> 00:02:35,960
然后在这里你可以看到时间嵌入。
And then here you see the time embedding.

34
00:02:35,960 --> 00:02:39,431
在上采样模块中，你需要做的就是像图示中那样，
And in the upsampling block, all you have to do again, just like in this diagram,

35
00:02:39,443 --> 00:02:45,120
把上下文嵌入乘以上采样块，然后加上时间嵌入。
you multiply the context embedding with the upsampling block, and you add the time embedding.

36
00:02:45,120 --> 00:02:46,120
很好！
Cool.

37
00:02:46,120 --> 00:02:49,960
那么现在，在 Notebook 的模型前向传递中，这就是运行模型，
So now in the notebook, in the forward pass of the model, so this is running the model,

38
00:02:49,960 --> 00:02:56,960
你可以看到一些这样的下采样块，然后也有这些上采样块。
you can see some of these down, down, down blocks, and then also these up, up, up blocks here.

39
00:02:56,960 --> 00:02:59,360
再次强调，这里是你的上下文和时间嵌入。
And again, here are your context and time embeddings.

40
00:02:59,360 --> 00:03:02,560
我们在这里为每一个上采样块都设置了两个。
We have two of them here for each of those up blocks.

41
00:03:02,560 --> 00:03:13,120
这些上采样和下采样块是如何定义的，是在UNet的初始化部分定义的。
And how these down and up blocks are defined is up here in initialization for the UNet.

42
00:03:13,120 --> 00:03:16,000
所以对于下采样，这就是一个UNet下采样的样子。
And so for the down, this is what a UNet down looks like.

43
00:03:16,000 --> 00:03:20,960
如果你想详细了解的话我们实际上在我们的辅助函数中也有这个。
And we actually do have that in our helper functions if you want to look at them in greater detail.

44
00:03:20,960 --> 00:03:23,540
但它们就是卷积块。
But they are just convolutional blocks.

45
00:03:23,540 --> 00:03:26,800
在下一个视频中，你将学会如何训练这个神经网络。
And in the next video, you'll learn how to train this neural network.
