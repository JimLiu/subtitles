在这个视频里，我们将讨论采样，\N我们将深入了解它的细节以及\N它在多个不同迭代中如何工作。 在我们讨论如何训练\N这个神经网络之前，先来谈谈采样， 也就是我们在神经网络\N训练完成后，在推理时会做什么。 你会有一个噪声样本， 把它放进已经理解了\N游戏角色样子的训练好的神经网络里， 然后它预测噪声。 它预测噪声，而不是游戏角色。 然后我们从噪声样本中减去预测的噪声，\N得到的东西就更像游戏角色一些。 现实情况是，这只是噪声的预测，\N并没有完全消除所有的噪声， 你需要多次迭代才能得到高质量的样本。 经过500次迭代后，\N我们得到了非常像游戏角色的图像。 现在让我们逐步了解这个算法。 首先，你可以采样一个\N随机噪声样本，这就是你一开始有的原始噪声。 然后你要逐步穿越时间，\N实际上就像在时光倒流， 从最后一次迭代，第500次，\N完全噪声的状态，一直倒退到第1次。 想象一下上一部视频中讲的\N墨水滴的例子，我们让时光倒流。 一开始它是完全扩散的，然后\N你一直倒退回到它刚刚滴入水中的时候。 接下来，你需要采样一些额外的噪声。\N我们稍后会详细讲解这个，所以现在不用担心。 这里你真正要做的是把那个\N原始的噪声，那个样本，再次输入\N你的神经网络，然后你得到一些预测的噪声。 这个预测的噪声就是\N训练过的神经网络想从原始噪声中\N减去的，从而得到更像游戏角色的图像。 最后，有一个叫做DDPM的采样算法，\N也就是噪扩散概率模型（Denoising Diffusion Probabilistic Models）， 这是由Jonathan Ho、Ajay Jain和我的\N好朋友Pieter Abbeel共同撰写的一篇论文。 这个采样算法基本上能够得到一些规模的数字。 那不是非常重要，但\N重要的是这里你实际上是\N在从原始噪声样本中减去预测的噪声。 而且，你还要再加回那一点\N额外的噪声，我们稍后会回到这一点。 好了，让我们回到Notebook。 你会看到这里有一些设置代码。 我认为这里真正重要的是\N你要导入PyTorch和很多PyTorch的实用工具。 我们还导入了一些为神经网络编写的辅助函数。 我只需按Shift+Enter运行\N这个单元格，以便我们导入所有内容。 现在这里我们设置了用于采样的神经网络， 稍后我们会详细讨论这个。 我现在就运行它，\N不用刚开始就关注所有细节。 这里我们设置了一些\N超参数（Hyperparameters），\N包括你在那里看到的那些时间步长。 就是那500个时间步长。 Beta 1和Beta 2只是DDPM的一些超参数。 这里你还可以看到高度。\N这是16乘16的图像。 再次说明，这只是一个正方形图像。\N我再按Shift+Enter运行。 这只是DDPM论文中定义的\N噪声调度（Noise Schedule）。 噪声调度的作用就是\N确定在某个时间步长应用于图像的噪声级别。 这部分主要是构建 DDPM 算法\N的一些参数，你还记得那些\N缩放因子（Scaling Factors）、\N缩放值（Scaling Values） S1、S2、S3 吧。 那些在噪声调度（Noise Schedule）中\N被计算，它被称为调度是因为它依赖于时间步长。 记住，你要看 500 个时间步长，因为\N你要经历这里的 500 次迭代，慢慢去除噪声。 我现在就运行一下。 这取决于我们所在的时间步长。 接下来，我将实例化模型，\N那个单元，我们稍后会回来。 然后这里就是那个采样算法，\N之前你看到的去噪加噪， 这真的是最重要的部分，\N因为它正在移除预测的噪声， 也就是模型认为不是游戏角色的部分，\N从原始噪声中去除。 我们可以通过 Shift+Enter 来运行以加载模型。 然后这就是我们刚刚讲过的那个采样算法。 特别是在这里运行模型以获取预测的噪声。 然后进行去噪。 现在让我们看看\N随着时间的推移采样是什么样子的。 这可能需要几分钟，取决于你用的硬件， 我们会在视频里加速这个过程。 但在下一个视频里，\N你还会看到更高效的采样技巧。 好了，让我们看看实际效果。 哇，看看这些游戏图像。 你绝对应该暂停并自己试试。 好吧，还有一个额外的细节。 现在你有个神经网络，\N它从原始噪声样本中预测噪声。 减去它，很好，你把它减去。\N很好。你得到的图像就更像游戏角色图像。 但问题是，这个神经网络需要这个\N噪声样本，这个正常分布的噪声样本，作为输入。 一旦你像这样去噪，\N它就不再按照那种方式分布了。 实际上，在每一步之后和下一步之前，\N你需要做的是 根据你所处的时间步长添加额外的噪声 然后作为下一个样本，\N下一个迭代输入你的训练过的神经网络。 从经验上看，这实际上有助于稳定神经网络， 使它不会坍塌成接近数据集平均值的样子， 意味着它看起来不会像左边的那些图像。 当我们不把噪音加回去时，神经网络\N只会生成这些看起来很普通的游戏角色图像， 而当我们把噪音加回去时，\N它就能生成这些漂亮的游戏角色图像。 这个算法就是在这里发生的。 我们实际上在每个时间步长都再次采样\N一个随机噪声，这个噪声是根据时间步长来的。 然后在这里，我们用缩放因子S3把它加回去。 现在让我们看看 Notebook。 现在在这个去噪加噪的函数里，\N我们讨论的是加噪部分。 那就是你随机抽取的这个Z，\N就是那个额外的噪音。 你用某个因子来缩放它，\N然后实际上把它加回去。 再次强调，这一切都发生在你的主要算法里。 好的，让我们继续之前的话题。 错误的方法是不加噪声回去，\N我们只需把Z设为0，然后传进去。 它只从原始噪声中减去预测的噪声，\N而不会加回任何额外的噪声。 让我们用Shift+Enter运行这个。 这个过程又要花几分钟。 好了，我们来看看这个方法的效果。 哦不，一团糟！ 这显然不是我们想要的。 一定要把那些额外的噪声加回去。 建议你先暂停，自己试试这个方法，\N然后跟另一个加回额外噪声的方法比较。 下一个视频我们会讲解\N神经网络架构，那个U-Net。