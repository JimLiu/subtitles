1
00:00:05,000 --> 00:00:12,000
在这个视频里，我们将讨论采样，我们将深入了解它的细节以及它在多个不同迭代中如何工作。
In this video, we'll talk about sampling, we'll get into the details of it and how it works across multiple different iterations.

2
00:00:12,000 --> 00:00:16,954
在我们讨论如何训练这个神经网络之前，先来谈谈采样，
So before we talk about how to train this neural network, let's talk about sampling,

3
00:00:16,955 --> 00:00:21,000
也就是我们在神经网络训练完成后，在推理时会做什么。
or what we do with the neural network after it's trained at inference time.

4
00:00:21,000 --> 00:00:23,404
你会有一个噪声样本，
So what happens is you have that noise sample,

5
00:00:23,405 --> 00:00:28,000
把它放进已经理解了游戏角色样子的训练好的神经网络里，
you put it through your trained neural network that has understood what a sprite kind of looks like,

6
00:00:28,000 --> 00:00:30,346
然后它预测噪声。
and what it does is it predicts noise.

7
00:00:30,546 --> 00:00:33,000
它预测噪声，而不是游戏角色。
It predicts noise as opposed to the sprite.

8
00:00:33,000 --> 00:00:39,000
然后我们从噪声样本中减去预测的噪声，得到的东西就更像游戏角色一些。
And then we subtract that predicted noise from the noise sample to get something a little bit more sprite-like.

9
00:00:39,000 --> 00:00:44,000
现实情况是，这只是噪声的预测，并没有完全消除所有的噪声，
Now realistically, that is just a prediction of noise, and it doesn't fully remove all the noise,

10
00:00:44,000 --> 00:00:47,000
你需要多次迭代才能得到高质量的样本。
so you need multiple steps to get high-quality samples.

11
00:00:47,000 --> 00:00:52,000
经过500次迭代后，我们得到了非常像游戏角色的图像。
That's after 500 iterations, we're able to get something that looks very sprite-like.

12
00:00:52,000 --> 00:00:55,000
现在让我们逐步了解这个算法。
So now let's step through this algorithmically.

13
00:00:55,000 --> 00:01:02,000
首先，你可以采样一个随机噪声样本，这就是你一开始有的原始噪声。
So first, you can sample a random noise sample, and that was that original noise you had in the beginning.

14
00:01:02,000 --> 00:01:06,000
然后你要逐步穿越时间，实际上就像在时光倒流，
And then you want to step through time, and actually you're stepping backwards through time,

15
00:01:06,000 --> 00:01:12,000
从最后一次迭代，第500次，完全噪声的状态，一直倒退到第1次。
all the way from the last iteration, 500, where it's completely noisy, all the way down to 1.

16
00:01:12,000 --> 00:01:15,000
想象一下上一部视频中讲的墨水滴的例子，我们让时光倒流。
And just think of your ink drop, you're actually going backwards in time.

17
00:01:15,000 --> 00:01:22,000
一开始它是完全扩散的，然后你一直倒退回到它刚刚滴入水中的时候。
It's fully diffused initially, and then you're going back all the way up to when it was first dropped into the water.

18
00:01:22,000 --> 00:01:28,000
接下来，你需要采样一些额外的噪声。我们稍后会详细讲解这个，所以现在不用担心。
Next, you'll sample some extra noise. We'll actually touch on this in a minute, so don't worry about this just now.

19
00:01:28,000 --> 00:01:35,000
这里你真正要做的是把那个原始的噪声，那个样本，再次输入你的神经网络，然后你得到一些预测的噪声。
Here is where you actually pass that original noise, that sample, back into your neural network, and you get some predicted noise.

20
00:01:35,000 --> 00:01:43,000
这个预测的噪声就是训练过的神经网络想从原始噪声中减去的，从而得到更像游戏角色的图像。
And this predicted noise is noise that the trained neural network wants to subtract from the original noise to get something that looks more sprite-like.

21
00:01:43,000 --> 00:01:51,000
最后，有一个叫做DDPM的采样算法，也就是噪扩散概率模型（Denoising Diffusion Probabilistic Models），
And finally, there's a sampling algorithm called DDPM, which stands for Denoising Diffusion Probabilistic Models,

22
00:01:51,000 --> 00:01:57,000
这是由Jonathan Ho、Ajay Jain和我的好朋友Pieter Abbeel共同撰写的一篇论文。
and it's a paper written by Jonathan Ho, Ajay Jain, and one of my good friends, Pieter Abbeel.

23
00:01:57,000 --> 00:02:01,000
这个采样算法基本上能够得到一些规模的数字。
And this sampling algorithm essentially is able to get a few numbers for scale.

24
00:02:01,000 --> 00:02:10,000
那不是非常重要，但重要的是这里你实际上是在从原始噪声样本中减去预测的噪声。
That's not super important, but what is important is that this is where you are actually subtracting out that predicted noise from the original noise sample.

25
00:02:10,000 --> 00:02:14,000
而且，你还要再加回那一点额外的噪声，我们稍后会回到这一点。
And again, you're adding that little extra noise back in, which we'll return to in a moment.

26
00:02:14,000 --> 00:02:15,985
好了，让我们回到Notebook。
All right, let's jump to the notebook.

27
00:02:15,986 --> 00:02:18,000
你会看到这里有一些设置代码。
So you'll see here some setup code.

28
00:02:18,000 --> 00:02:24,000
我认为这里真正重要的是你要导入PyTorch和很多PyTorch的实用工具。
I think all that's really important here is that you're importing PyTorch and a lot of utilities from PyTorch.

29
00:02:24,000 --> 00:02:29,000
我们还导入了一些为神经网络编写的辅助函数。
We also import some helper functions here that we had written for the neural network.

30
00:02:29,000 --> 00:02:34,000
我只需按Shift+Enter运行这个单元格，以便我们导入所有内容。
So I'm just going to hit Shift+Enter to run that cell so that we import everything.

31
00:02:34,000 --> 00:02:37,000
现在这里我们设置了用于采样的神经网络，
And now here's setting up the neural network, which we're going to use for sampling.

32
00:02:37,000 --> 00:02:40,000
稍后我们会详细讨论这个。
We'll go into the details of this later.

33
00:02:40,000 --> 00:02:46,000
我现在就运行它，不用刚开始就关注所有细节。
So I'm just going to run this, and no need to really follow everything that's going on there just yet.

34
00:02:46,000 --> 00:02:51,000
这里我们设置了一些超参数（Hyperparameters），包括你在那里看到的那些时间步长。
Here we're setting up some hyperparameters, and that includes those time steps that you've seen there.

35
00:02:51,000 --> 00:02:53,000
就是那500个时间步长。
So that's the 500 time steps.

36
00:02:53,000 --> 00:02:59,000
Beta 1和Beta 2只是DDPM的一些超参数。
Beta 1 and Beta 2 are just some hyperparameters for DDPM.

37
00:02:59,000 --> 00:03:03,000
这里你还可以看到高度。这是16乘16的图像。
And here you can also see the height. This is the 16 by 16 image.

38
00:03:03,000 --> 00:03:07,000
再次说明，这只是一个正方形图像。我再按Shift+Enter运行。
And again, it's just a square image. So I'm going to run this Shift+Enter again.

39
00:03:07,000 --> 00:03:10,000
这只是DDPM论文中定义的噪声调度（Noise Schedule）。
And this is just a noise schedule defined in the DDPM paper.

40
00:03:10,000 --> 00:03:17,000
噪声调度的作用就是确定在某个时间步长应用于图像的噪声级别。
And all a noise schedule is, is it determines what level of noise to apply to the image at a certain time step.

41
00:03:17,000 --> 00:03:28,000
这部分主要是构建 DDPM 算法的一些参数，你还记得那些缩放因子（Scaling Factors）、缩放值（Scaling Values） S1、S2、S3 吧。
So this part is just constructing some of the parameters for the DDPM algorithm that you remember, those scaling factors, those scaling values, S1, S2, S3.

42
00:03:28,000 --> 00:03:34,000
那些在噪声调度（Noise Schedule）中被计算，它被称为调度是因为它依赖于时间步长。
That's being computed here in the noise schedule, and it's called a schedule because it is dependent on the time step.

43
00:03:34,000 --> 00:03:41,000
记住，你要看 500 个时间步长，因为你要经历这里的 500 次迭代，慢慢去除噪声。
Remember, you're looking through 500 time steps because you're going through those 500 iterations that you see here of slowly removing noise.

44
00:03:41,000 --> 00:03:43,056
我现在就运行一下。
So I'm just going to run that here.

45
00:03:43,057 --> 00:03:45,000
这取决于我们所在的时间步长。
So just dependent on that time step that we're on.

46
00:03:45,000 --> 00:03:51,000
接下来，我将实例化模型，那个单元，我们稍后会回来。
Next, I'm just going to instantiate the model, that unit, which we will come back to.

47
00:03:51,000 --> 00:03:56,000
然后这里就是那个采样算法，之前你看到的去噪加噪，
And then here is the sampling algorithm, the denoise add noise that you had seen previously,

48
00:03:56,000 --> 00:04:01,000
这真的是最重要的部分，因为它正在移除预测的噪声，
which is really the main important part is that it is removing the predicted noise,

49
00:04:01,000 --> 00:04:07,000
也就是模型认为不是游戏角色的部分，从原始噪声中去除。
which is what the model thinks is not a sprite, from the original noise.

50
00:04:07,000 --> 00:04:12,000
我们可以通过 Shift+Enter 来运行以加载模型。
So we can run that Shift+Enter to load that model.

51
00:04:12,000 --> 00:04:17,000
然后这就是我们刚刚讲过的那个采样算法。
And then here is what we had just stepped through, that sampling algorithm.

52
00:04:17,000 --> 00:04:22,000
特别是在这里运行模型以获取预测的噪声。
And specifically here is running the model to get the predicted noise.

53
00:04:22,000 --> 00:04:24,000
然后进行去噪。
And then running the denoise.

54
00:04:24,000 --> 00:04:28,000
现在让我们看看随着时间的推移采样是什么样子的。
Now let's visualize what sampling looks like over time.

55
00:04:28,000 --> 00:04:32,000
这可能需要几分钟，取决于你用的硬件，
This may take a few minutes depending on what kind of hardware you're running on,

56
00:04:32,000 --> 00:04:34,000
我们会在视频里加速这个过程。
and we're going to speed this up in the video.

57
00:04:34,000 --> 00:04:38,000
但在下一个视频里，你还会看到更高效的采样技巧。
But in the next video, you'll also see a more efficient sampling technique as well.

58
00:04:38,000 --> 00:04:41,000
好了，让我们看看实际效果。
All right, let's see it in action.

59
00:04:41,000 --> 00:04:44,000
哇，看看这些游戏图像。
Wow, look at those sprites.

60
00:04:44,000 --> 00:04:47,000
你绝对应该暂停并自己试试。
So you should definitely pause and try these yourself.

61
00:04:47,000 --> 00:04:49,000
好吧，还有一个额外的细节。
All right, so there's one more extra detail.

62
00:04:49,000 --> 00:04:53,000
现在你有个神经网络，它从原始噪声样本中预测噪声。
So right now you have your neural network that's predicting noise from your original noise sample.

63
00:04:53,000 --> 00:04:57,000
减去它，很好，你把它减去。很好。你得到的图像就更像游戏角色图像。
You subtract it out. Great. And you get something a little bit more sprite-like.

64
00:04:57,000 --> 00:05:04,000
但问题是，这个神经网络需要这个噪声样本，这个正常分布的噪声样本，作为输入。
But the thing is, this neural network expects this noisy sample, this normally distributed noisy sample, as input.

65
00:05:04,000 --> 00:05:09,000
一旦你像这样去噪，它就不再按照那种方式分布了。
And once you've denoised it like this, it's no longer distributed in that way.

66
00:05:09,000 --> 00:05:13,029
实际上，在每一步之后和下一步之前，你需要做的是
So actually what you have to do after each step and before each next step

67
00:05:13,030 --> 00:05:17,057
根据你所处的时间步长添加额外的噪声
is to add in additional noise that's scaled based on what time step you're at

68
00:05:17,058 --> 00:05:24,000
然后作为下一个样本，下一个迭代输入你的训练过的神经网络。
to get passed in as the next sample, the next iteration into your trained neural network.

69
00:05:24,000 --> 00:05:28,042
从经验上看，这实际上有助于稳定神经网络，
And empirically, this actually helps stabilize the neural network

70
00:05:28,043 --> 00:05:31,457
使它不会坍塌成接近数据集平均值的样子，
so it doesn't collapse to something that's close to the average of the data set,

71
00:05:31,458 --> 00:05:34,000
意味着它看起来不会像左边的那些图像。
meaning it doesn't look like this thing on the left.

72
00:05:34,000 --> 00:05:40,000
当我们不把噪音加回去时，神经网络只会生成这些看起来很普通的游戏角色图像，
When we don't add that noise back in, the neural network just produces these average-looking blobs of sprites,

73
00:05:40,000 --> 00:05:45,000
而当我们把噪音加回去时，它就能生成这些漂亮的游戏角色图像。
versus when we go add it back in, it actually is able to produce these beautiful images of sprites.

74
00:05:45,000 --> 00:05:48,000
这个算法就是在这里发生的。
So here in the algorithm is where this happens.

75
00:05:48,000 --> 00:05:54,000
我们实际上在每个时间步长都再次采样一个随机噪声，这个噪声是根据时间步长来的。
So we actually sample a random noise again at each time step based on the time step.

76
00:05:54,000 --> 00:06:00,000
然后在这里，我们用缩放因子S3把它加回去。
And then down here, we actually add it back in with that scaling factor S3.

77
00:06:00,000 --> 00:06:02,000
现在让我们看看 Notebook。
So now let's take a look at the notebook.

78
00:06:02,000 --> 00:06:07,000
现在在这个去噪加噪的函数里，我们讨论的是加噪部分。
So now in this function denoise add noise, we are talking about the add noise part.

79
00:06:07,000 --> 00:06:12,000
那就是你随机抽取的这个Z，就是那个额外的噪音。
And what that is, is this Z that you randomly sample, that's that extra noise.

80
00:06:12,000 --> 00:06:18,000
你用某个因子来缩放它，然后实际上把它加回去。
And you scale it by some factor, and then you actually do add it back in.

81
00:06:18,000 --> 00:06:22,000
再次强调，这一切都发生在你的主要算法里。
And again, that all happens down here in your main algorithm.

82
00:06:22,000 --> 00:06:25,000
好的，让我们继续之前的话题。
All right, so let's pick up where we left off then.

83
00:06:25,000 --> 00:06:33,000
错误的方法是不加噪声回去，我们只需把Z设为0，然后传进去。
So for the incorrect way where we don't add the noise back in, we actually just set Z to 0, and we pass that in.

84
00:06:33,000 --> 00:06:39,000
它只从原始噪声中减去预测的噪声，而不会加回任何额外的噪声。
It only subtracts the predicted noise from the original noise, and it doesn't add any extra noise back in.

85
00:06:39,000 --> 00:06:43,000
让我们用Shift+Enter运行这个。
And let's run this with Shift+Enter.

86
00:06:43,000 --> 00:06:46,000
这个过程又要花几分钟。
And again, this will take a couple minutes.

87
00:06:46,000 --> 00:06:52,000
好了，我们来看看这个方法的效果。
All right, so let's take a look at what this does instead.

88
00:06:52,000 --> 00:06:56,000
哦不，一团糟！
Oh no, blobs!

89
00:06:56,000 --> 00:06:58,000
这显然不是我们想要的。
So this is obviously not what you want.

90
00:06:58,000 --> 00:07:01,000
一定要把那些额外的噪声加回去。
So make sure you add that extra noise back in.

91
00:07:01,000 --> 00:07:07,000
建议你先暂停，自己试试这个方法，然后跟另一个加回额外噪声的方法比较。
And so you should definitely pause and try these yourself and compare it to the other method where you do add that extra noise.

92
00:07:07,000 --> 00:07:13,000
下一个视频我们会讲解神经网络架构，那个U-Net。
And in the next video, we're going to cover that neural network architecture, that U-Net.
