1
00:00:05,000 --> 00:00:12,000
在这个视频里，我们将讨论采样，我们将深入了解它的细节以及它在多个不同迭代中如何工作。

2
00:00:12,000 --> 00:00:16,954
在我们讨论如何训练这个神经网络之前，先来谈谈采样，

3
00:00:16,955 --> 00:00:21,000
也就是我们在神经网络训练完成后，在推理时会做什么。

4
00:00:21,000 --> 00:00:23,404
你会有一个噪声样本，

5
00:00:23,405 --> 00:00:28,000
把它放进已经理解了游戏角色样子的训练好的神经网络里，

6
00:00:28,000 --> 00:00:30,346
然后它预测噪声。

7
00:00:30,546 --> 00:00:33,000
它预测噪声，而不是游戏角色。

8
00:00:33,000 --> 00:00:39,000
然后我们从噪声样本中减去预测的噪声，得到的东西就更像游戏角色一些。

9
00:00:39,000 --> 00:00:44,000
现实情况是，这只是噪声的预测，并没有完全消除所有的噪声，

10
00:00:44,000 --> 00:00:47,000
你需要多次迭代才能得到高质量的样本。

11
00:00:47,000 --> 00:00:52,000
经过500次迭代后，我们得到了非常像游戏角色的图像。

12
00:00:52,000 --> 00:00:55,000
现在让我们逐步了解这个算法。

13
00:00:55,000 --> 00:01:02,000
首先，你可以采样一个随机噪声样本，这就是你一开始有的原始噪声。

14
00:01:02,000 --> 00:01:06,000
然后你要逐步穿越时间，实际上就像在时光倒流，

15
00:01:06,000 --> 00:01:12,000
从最后一次迭代，第500次，完全噪声的状态，一直倒退到第1次。

16
00:01:12,000 --> 00:01:15,000
想象一下上一部视频中讲的墨水滴的例子，我们让时光倒流。

17
00:01:15,000 --> 00:01:22,000
一开始它是完全扩散的，然后你一直倒退回到它刚刚滴入水中的时候。

18
00:01:22,000 --> 00:01:28,000
接下来，你需要采样一些额外的噪声。我们稍后会详细讲解这个，所以现在不用担心。

19
00:01:28,000 --> 00:01:35,000
这里你真正要做的是把那个原始的噪声，那个样本，再次输入你的神经网络，然后你得到一些预测的噪声。

20
00:01:35,000 --> 00:01:43,000
这个预测的噪声就是训练过的神经网络想从原始噪声中减去的，从而得到更像游戏角色的图像。

21
00:01:43,000 --> 00:01:51,000
最后，有一个叫做DDPM的采样算法，也就是噪扩散概率模型（Denoising Diffusion Probabilistic Models），

22
00:01:51,000 --> 00:01:57,000
这是由Jonathan Ho、Ajay Jain和我的好朋友Pieter Abbeel共同撰写的一篇论文。

23
00:01:57,000 --> 00:02:01,000
这个采样算法基本上能够得到一些规模的数字。

24
00:02:01,000 --> 00:02:10,000
那不是非常重要，但重要的是这里你实际上是在从原始噪声样本中减去预测的噪声。

25
00:02:10,000 --> 00:02:14,000
而且，你还要再加回那一点额外的噪声，我们稍后会回到这一点。

26
00:02:14,000 --> 00:02:15,985
好了，让我们回到Notebook。

27
00:02:15,986 --> 00:02:18,000
你会看到这里有一些设置代码。

28
00:02:18,000 --> 00:02:24,000
我认为这里真正重要的是你要导入PyTorch和很多PyTorch的实用工具。

29
00:02:24,000 --> 00:02:29,000
我们还导入了一些为神经网络编写的辅助函数。

30
00:02:29,000 --> 00:02:34,000
我只需按Shift+Enter运行这个单元格，以便我们导入所有内容。

31
00:02:34,000 --> 00:02:37,000
现在这里我们设置了用于采样的神经网络，

32
00:02:37,000 --> 00:02:40,000
稍后我们会详细讨论这个。

33
00:02:40,000 --> 00:02:46,000
我现在就运行它，不用刚开始就关注所有细节。

34
00:02:46,000 --> 00:02:51,000
这里我们设置了一些超参数（Hyperparameters），包括你在那里看到的那些时间步长。

35
00:02:51,000 --> 00:02:53,000
就是那500个时间步长。

36
00:02:53,000 --> 00:02:59,000
Beta 1和Beta 2只是DDPM的一些超参数。

37
00:02:59,000 --> 00:03:03,000
这里你还可以看到高度。这是16乘16的图像。

38
00:03:03,000 --> 00:03:07,000
再次说明，这只是一个正方形图像。我再按Shift+Enter运行。

39
00:03:07,000 --> 00:03:10,000
这只是DDPM论文中定义的噪声调度（Noise Schedule）。

40
00:03:10,000 --> 00:03:17,000
噪声调度的作用就是确定在某个时间步长应用于图像的噪声级别。

41
00:03:17,000 --> 00:03:28,000
这部分主要是构建 DDPM 算法的一些参数，你还记得那些缩放因子（Scaling Factors）、缩放值（Scaling Values） S1、S2、S3 吧。

42
00:03:28,000 --> 00:03:34,000
那些在噪声调度（Noise Schedule）中被计算，它被称为调度是因为它依赖于时间步长。

43
00:03:34,000 --> 00:03:41,000
记住，你要看 500 个时间步长，因为你要经历这里的 500 次迭代，慢慢去除噪声。

44
00:03:41,000 --> 00:03:43,056
我现在就运行一下。

45
00:03:43,057 --> 00:03:45,000
这取决于我们所在的时间步长。

46
00:03:45,000 --> 00:03:51,000
接下来，我将实例化模型，那个单元，我们稍后会回来。

47
00:03:51,000 --> 00:03:56,000
然后这里就是那个采样算法，之前你看到的去噪加噪，

48
00:03:56,000 --> 00:04:01,000
这真的是最重要的部分，因为它正在移除预测的噪声，

49
00:04:01,000 --> 00:04:07,000
也就是模型认为不是游戏角色的部分，从原始噪声中去除。

50
00:04:07,000 --> 00:04:12,000
我们可以通过 Shift+Enter 来运行以加载模型。

51
00:04:12,000 --> 00:04:17,000
然后这就是我们刚刚讲过的那个采样算法。

52
00:04:17,000 --> 00:04:22,000
特别是在这里运行模型以获取预测的噪声。

53
00:04:22,000 --> 00:04:24,000
然后进行去噪。

54
00:04:24,000 --> 00:04:28,000
现在让我们看看随着时间的推移采样是什么样子的。

55
00:04:28,000 --> 00:04:32,000
这可能需要几分钟，取决于你用的硬件，

56
00:04:32,000 --> 00:04:34,000
我们会在视频里加速这个过程。

57
00:04:34,000 --> 00:04:38,000
但在下一个视频里，你还会看到更高效的采样技巧。

58
00:04:38,000 --> 00:04:41,000
好了，让我们看看实际效果。

59
00:04:41,000 --> 00:04:44,000
哇，看看这些游戏图像。

60
00:04:44,000 --> 00:04:47,000
你绝对应该暂停并自己试试。

61
00:04:47,000 --> 00:04:49,000
好吧，还有一个额外的细节。

62
00:04:49,000 --> 00:04:53,000
现在你有个神经网络，它从原始噪声样本中预测噪声。

63
00:04:53,000 --> 00:04:57,000
减去它，很好，你把它减去。很好。你得到的图像就更像游戏角色图像。

64
00:04:57,000 --> 00:05:04,000
但问题是，这个神经网络需要这个噪声样本，这个正常分布的噪声样本，作为输入。

65
00:05:04,000 --> 00:05:09,000
一旦你像这样去噪，它就不再按照那种方式分布了。

66
00:05:09,000 --> 00:05:13,029
实际上，在每一步之后和下一步之前，你需要做的是

67
00:05:13,030 --> 00:05:17,057
根据你所处的时间步长添加额外的噪声

68
00:05:17,058 --> 00:05:24,000
然后作为下一个样本，下一个迭代输入你的训练过的神经网络。

69
00:05:24,000 --> 00:05:28,042
从经验上看，这实际上有助于稳定神经网络，

70
00:05:28,043 --> 00:05:31,457
使它不会坍塌成接近数据集平均值的样子，

71
00:05:31,458 --> 00:05:34,000
意味着它看起来不会像左边的那些图像。

72
00:05:34,000 --> 00:05:40,000
当我们不把噪音加回去时，神经网络只会生成这些看起来很普通的游戏角色图像，

73
00:05:40,000 --> 00:05:45,000
而当我们把噪音加回去时，它就能生成这些漂亮的游戏角色图像。

74
00:05:45,000 --> 00:05:48,000
这个算法就是在这里发生的。

75
00:05:48,000 --> 00:05:54,000
我们实际上在每个时间步长都再次采样一个随机噪声，这个噪声是根据时间步长来的。

76
00:05:54,000 --> 00:06:00,000
然后在这里，我们用缩放因子S3把它加回去。

77
00:06:00,000 --> 00:06:02,000
现在让我们看看 Notebook。

78
00:06:02,000 --> 00:06:07,000
现在在这个去噪加噪的函数里，我们讨论的是加噪部分。

79
00:06:07,000 --> 00:06:12,000
那就是你随机抽取的这个Z，就是那个额外的噪音。

80
00:06:12,000 --> 00:06:18,000
你用某个因子来缩放它，然后实际上把它加回去。

81
00:06:18,000 --> 00:06:22,000
再次强调，这一切都发生在你的主要算法里。

82
00:06:22,000 --> 00:06:25,000
好的，让我们继续之前的话题。

83
00:06:25,000 --> 00:06:33,000
错误的方法是不加噪声回去，我们只需把Z设为0，然后传进去。

84
00:06:33,000 --> 00:06:39,000
它只从原始噪声中减去预测的噪声，而不会加回任何额外的噪声。

85
00:06:39,000 --> 00:06:43,000
让我们用Shift+Enter运行这个。

86
00:06:43,000 --> 00:06:46,000
这个过程又要花几分钟。

87
00:06:46,000 --> 00:06:52,000
好了，我们来看看这个方法的效果。

88
00:06:52,000 --> 00:06:56,000
哦不，一团糟！

89
00:06:56,000 --> 00:06:58,000
这显然不是我们想要的。

90
00:06:58,000 --> 00:07:01,000
一定要把那些额外的噪声加回去。

91
00:07:01,000 --> 00:07:07,000
建议你先暂停，自己试试这个方法，然后跟另一个加回额外噪声的方法比较。

92
00:07:07,000 --> 00:07:13,000
下一个视频我们会讲解神经网络架构，那个U-Net。
