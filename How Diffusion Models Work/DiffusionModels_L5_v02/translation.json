{
  "chunks": [
    {
      "items": [
        {
          "id": "1",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 5,
            "milliseconds": 0
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 9,
            "milliseconds": 540
          },
          "text": "In this video, you'll learn how to control the model and what it generates."
        },
        {
          "id": "2",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 9,
            "milliseconds": 540
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 17,
            "milliseconds": 300
          },
          "text": "For many, this is the most exciting piece because you get to tell the model what you want and it gets to imagine it for you."
        },
        {
          "id": "3",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 17,
            "milliseconds": 300
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 22,
            "milliseconds": 660
          },
          "text": "When it comes to controlling these models, we actually want to use embeddings."
        },
        {
          "id": "4",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 22,
            "milliseconds": 660
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 28,
            "milliseconds": 457
          },
          "text": "And what embeddings are, which we looked at a little bit in previous videos of a time embedding and a context embedding,"
        },
        {
          "id": "5",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 28,
            "milliseconds": 458
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 34,
            "milliseconds": 340
          },
          "text": "what embeddings are is they're vectors, they're numbers that are able to capture a meaning."
        },
        {
          "id": "6",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 34,
            "milliseconds": 340
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 40,
            "milliseconds": 60
          },
          "text": "And here it's capturing the meaning of this sentence or this joke, perhaps, for diffusion models."
        },
        {
          "id": "7",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 40,
            "milliseconds": 60
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 42,
            "milliseconds": 500
          },
          "text": "Brownians often bump into each other."
        },
        {
          "id": "8",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 42,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 47,
            "milliseconds": 500
          },
          "text": "So it encodes that into this embedding, which is this set of numbers in a vector."
        },
        {
          "id": "9",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 47,
            "milliseconds": 500
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 53,
            "milliseconds": 700
          },
          "text": "And what's special about embeddings is because they can capture the semantic meaning, text with similar content will have similar vectors."
        },
        {
          "id": "10",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 53,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 59,
            "milliseconds": 280
          },
          "text": "And one of the kind of magical things about embeddings is you can almost do this vector arithmetic with it."
        }
      ],
      "source": [
        "In this video, you'll learn how to control the model and what it generates.",
        "For many, this is the most exciting piece because you get to tell the model what you want and it gets to imagine it for you.",
        "When it comes to controlling these models, we actually want to use embeddings.",
        "And what embeddings are, which we looked at a little bit in previous videos of a time embedding and a context embedding,",
        "what embeddings are is they're vectors, they're numbers that are able to capture a meaning.",
        "And here it's capturing the meaning of this sentence or this joke, perhaps, for diffusion models.",
        "Brownians often bump into each other.",
        "So it encodes that into this embedding, which is this set of numbers in a vector.",
        "And what's special about embeddings is because they can capture the semantic meaning, text with similar content will have similar vectors.",
        "And one of the kind of magical things about embeddings is you can almost do this vector arithmetic with it."
      ],
      "result": [
        "在这个视频中，你将学习\\N如何控制模型和生成的内容。",
        "对很多人来说，这是最令人兴奋的\\N部分，因为你可以告诉模型想要\\N什么，然后它帮你实现你想要的。",
        "在控制这些模型时，我们实际上\\N想要使用嵌入（Embeddings）。",
        "嵌入是什么呢？我们在之前的视频中\\N稍微了解过时间嵌入和上下文嵌入，",
        "嵌入就是向量，\\N是能够捕捉意义的数字。",
        "在这里，它捕捉了这个句子或这个\\N笑话的意义，可能是针对扩散模型的。",
        "布朗运动的粒子经常相互碰撞。",
        "所以它将这个意义编码到这个\\N嵌入中，也就是向量中的一组数字。",
        "嵌入的特殊之处在于，\\N因为它们可以捕捉语义意义，\\N内容相似的文本将具有相似的向量。",
        "关于嵌入的神奇之处之一是，\\N你甚至可以用它进行向量运算。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "11",
          "startTime": {
            "hours": 0,
            "minutes": 0,
            "seconds": 59,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 4,
            "milliseconds": 180
          },
          "text": "So Paris minus France plus England equals the London embedding, for example."
        },
        {
          "id": "12",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 4,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 9,
            "milliseconds": 740
          },
          "text": "Okay, so how do these embeddings actually become context to the model during training?"
        },
        {
          "id": "13",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 9,
            "milliseconds": 740
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 14,
            "milliseconds": 460
          },
          "text": "Well, here you have an avocado image, which you want the neural network to understand."
        },
        {
          "id": "14",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 14,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 17,
            "milliseconds": 760
          },
          "text": "And you also have a caption for it, a ripe avocado."
        },
        {
          "id": "15",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 17,
            "milliseconds": 760
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 22,
            "milliseconds": 328
          },
          "text": "And you can actually pass that through, get an embedding and input that into the neural network"
        },
        {
          "id": "16",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 22,
            "milliseconds": 329
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 28,
            "milliseconds": 940
          },
          "text": "to then predict the noise that was added to this avocado image, and then compute the loss and do the same thing as before."
        },
        {
          "id": "17",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 28,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 33,
            "milliseconds": 220
          },
          "text": "And you could do this across a lot of different images with captions."
        },
        {
          "id": "18",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 33,
            "milliseconds": 220
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 39,
            "milliseconds": 780
          },
          "text": "So here is a comfy armchair, you can pass it through an embedding, pass it into the model and have that be part of training."
        },
        {
          "id": "19",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 39,
            "milliseconds": 780
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 48,
            "milliseconds": 200
          },
          "text": "Now the magic of this section is that while you were able to scrape these images of avocados and armchairs off the internet with those captions,"
        },
        {
          "id": "20",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 48,
            "milliseconds": 201
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 55,
            "milliseconds": 140
          },
          "text": "you're able to at sample time, be able to generate things that the model has never seen before."
        }
      ],
      "source": [
        "So Paris minus France plus England equals the London embedding, for example.",
        "Okay, so how do these embeddings actually become context to the model during training?",
        "Well, here you have an avocado image, which you want the neural network to understand.",
        "And you also have a caption for it, a ripe avocado.",
        "And you can actually pass that through, get an embedding and input that into the neural network",
        "to then predict the noise that was added to this avocado image, and then compute the loss and do the same thing as before.",
        "And you could do this across a lot of different images with captions.",
        "So here is a comfy armchair, you can pass it through an embedding, pass it into the model and have that be part of training.",
        "Now the magic of this section is that while you were able to scrape these images of avocados and armchairs off the internet with those captions,",
        "you're able to at sample time, be able to generate things that the model has never seen before."
      ],
      "result": [
        "例如：将巴黎的嵌入减去法国的嵌入\\N加上英国的嵌入等于伦敦的嵌入。",
        "那么，在训练过程中，这些嵌入\\N是如何成为模型的上下文的？",
        "好吧，这里有一个牛油果图片，\\N你希望神经网络能理解它。",
        "还有一个关于它的标题，\\N一个成熟的牛油果。",
        "实际上，你可以将其传递，获得\\N一个嵌入并将其输入到神经网络中。",
        "然后预测添加到这个\\N牛油果图像的噪声，然后计算损失\\N并像以前一样做同样的事情。",
        "你可以在很多不同的\\N带有标题的图片上做这个。",
        "这里有一个舒适的扶手椅，\\N你可以将其通过嵌入，传递到\\N模型中，并成为训练的一部分。",
        "现在这部分的神奇之处\\N在于，虽然你能够从互联网上抓取\\N这些牛油果和扶手椅的图片和标题，",
        "但在抽样时，\\N你能够生成模型从未见过的东西。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "21",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 55,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 57,
            "milliseconds": 280
          },
          "text": "And that could be an avocado armchair."
        },
        {
          "id": "22",
          "startTime": {
            "hours": 0,
            "minutes": 1,
            "seconds": 57,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 3,
            "milliseconds": 99
          },
          "text": "And the magic of this is because you can embed the words avocado armchair into this embedding that has,"
        },
        {
          "id": "23",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 3,
            "milliseconds": 100
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 5,
            "milliseconds": 643
          },
          "text": "you know, a bit of avocado in there, a bit of armchair in there,"
        },
        {
          "id": "24",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 5,
            "milliseconds": 644
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 14,
            "milliseconds": 220
          },
          "text": "put that through the neural network, have it predict noise, subtract that noise out and get lo and behold, an avocado armchair."
        },
        {
          "id": "25",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 14,
            "milliseconds": 220
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 18,
            "milliseconds": 180
          },
          "text": "So more broadly, context is a vector that can control generation."
        },
        {
          "id": "26",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 18,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 23,
            "milliseconds": 420
          },
          "text": "Context can be just as we have seen now, the text embeddings that of that avocado armchair,"
        },
        {
          "id": "27",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 23,
            "milliseconds": 420
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 26,
            "milliseconds": 900
          },
          "text": "that's very long, but context doesn't have to be that long."
        },
        {
          "id": "28",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 26,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 30,
            "milliseconds": 335
          },
          "text": "Context can also be different categories that are five in length, you know,"
        },
        {
          "id": "29",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 30,
            "milliseconds": 336
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 37,
            "milliseconds": 140
          },
          "text": "five different dimensions such as having a hero or being a non-hero like these objects of a fireball and a mushroom."
        },
        {
          "id": "30",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 37,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 41,
            "milliseconds": 140
          },
          "text": "It could be food items, you know, apple, orange, watermelon."
        }
      ],
      "source": [
        "And that could be an avocado armchair.",
        "And the magic of this is because you can embed the words avocado armchair into this embedding that has,",
        "you know, a bit of avocado in there, a bit of armchair in there,",
        "put that through the neural network, have it predict noise, subtract that noise out and get lo and behold, an avocado armchair.",
        "So more broadly, context is a vector that can control generation.",
        "Context can be just as we have seen now, the text embeddings that of that avocado armchair,",
        "that's very long, but context doesn't have to be that long.",
        "Context can also be different categories that are five in length, you know,",
        "five different dimensions such as having a hero or being a non-hero like these objects of a fireball and a mushroom.",
        "It could be food items, you know, apple, orange, watermelon."
      ],
      "result": [
        "那可能是个牛油果扶手椅。",
        "这个的神奇之处在于，\\N你可以把牛油果扶手椅\\N这几个词嵌入到这个词嵌入中，",
        "里面有一点牛油果，一点扶手椅，",
        "通过神经网络预测噪音，减去\\N噪音，然后得到一个牛油果扶手椅。",
        "从更广泛的角度来看，\\N上下文是一个可以控制生成的向量。",
        "上下文可以是我们现在看到\\N的文本嵌入，比如牛油果扶手椅，",
        "虽然很长，\\N但上下文不一定要那么长。",
        "上下文也可以是\\N五个不同的类别，比如，",
        "五个不同的维度，如英雄或非\\N英雄，比如火球和蘑菇这样的物体。",
        "还可以是食物，\\N比如苹果、橙子、西瓜。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "31",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 41,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 44,
            "milliseconds": 460
          },
          "text": "It could be spells and weapons like this bow and arrow or this candle."
        },
        {
          "id": "32",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 44,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 48,
            "milliseconds": 360
          },
          "text": "And finally, it could be whether these sprites are side facing or not."
        },
        {
          "id": "33",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 48,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 52,
            "milliseconds": 820
          },
          "text": "So now let's take a look at adding context to your model in the next lab."
        },
        {
          "id": "34",
          "startTime": {
            "hours": 0,
            "minutes": 2,
            "seconds": 52,
            "milliseconds": 820
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 2,
            "milliseconds": 940
          },
          "text": "Onto our lab, we can just run the setup here for all these things, just setting up the same things as before."
        },
        {
          "id": "35",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 2,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 8,
            "milliseconds": 980
          },
          "text": "And then down here in context, I want to instantiate our neural network again."
        },
        {
          "id": "36",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 8,
            "milliseconds": 980
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 13,
            "milliseconds": 700
          },
          "text": "And again, we're not training, but I'm going to call out a few places where we do add the context."
        },
        {
          "id": "37",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 13,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 21,
            "milliseconds": 620
          },
          "text": "So when we do load the data here, we now iterate through both the data point and the context factor associated with it."
        },
        {
          "id": "38",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 21,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 28,
            "milliseconds": 700
          },
          "text": "And the context that we do have are these one hot encoded vectors of hero, non-hero, food, spells and weapons and side facing."
        },
        {
          "id": "39",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 28,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 30,
            "milliseconds": 180
          },
          "text": "We create a context mask."
        },
        {
          "id": "40",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 30,
            "milliseconds": 180
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 34,
            "milliseconds": 660
          },
          "text": "And what's important here is that actually with some randomness, we completely mask out"
        },
        {
          "id": "41",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 34,
            "milliseconds": 660
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 39,
            "milliseconds": 460
          },
          "text": "the context so that the model is able to learn generally what a sprite is as well."
        }
      ],
      "source": [
        "It could be spells and weapons like this bow and arrow or this candle.",
        "And finally, it could be whether these sprites are side facing or not.",
        "So now let's take a look at adding context to your model in the next lab.",
        "Onto our lab, we can just run the setup here for all these things, just setting up the same things as before.",
        "And then down here in context, I want to instantiate our neural network again.",
        "And again, we're not training, but I'm going to call out a few places where we do add the context.",
        "So when we do load the data here, we now iterate through both the data point and the context factor associated with it.",
        "And the context that we do have are these one hot encoded vectors of hero, non-hero, food, spells and weapons and side facing.",
        "We create a context mask.",
        "And what's important here is that actually with some randomness, we completely mask out",
        "the context so that the model is able to learn generally what a sprite is as well."
      ],
      "result": [
        "这可能是像这弓箭\\N或蜡烛这样的法术和武器。",
        "最后，这可能是\\N这些游戏角色是否侧面的问题。",
        "现在让我们在下一个实验室中\\N看看如何为您的模型添加上下文。",
        "在我们的实验室里，\\N我们只需为所有这些东西\\N运行设置，就像之前一样。",
        "然后在这里的上下文中，\\N我想再次实例化我们的神经网络。",
        "同样，我们没有进行训练，但\\N我会指出我们在哪里添加了上下文。",
        "所以当我们在这里加载\\N数据时，我们现在遍历数据点\\N和与之相关的上下文因素。",
        "我们拥有的上下文是这些\\N英雄、非英雄、食物、法术和\\N武器以及侧面的独热编码向量。",
        "我们创建一个上下文遮罩。",
        "这里重要的是，实际上，\\N我们用一些随机性完全遮住",
        "上下文，以便模型能够\\N学习到什么是游戏角色。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "42",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 39,
            "milliseconds": 460
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 42,
            "milliseconds": 40
          },
          "text": "It's pretty common for diffusion models."
        },
        {
          "id": "43",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 42,
            "milliseconds": 40
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 45,
            "milliseconds": 980
          },
          "text": "And then we add context when we call the neural network right here."
        },
        {
          "id": "44",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 45,
            "milliseconds": 980
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 49,
            "milliseconds": 940
          },
          "text": "So let's load a checkpoint where we did train the model with context."
        },
        {
          "id": "45",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 49,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 54,
            "milliseconds": 580
          },
          "text": "So just loading that model here, running that."
        },
        {
          "id": "46",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 54,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 56,
            "milliseconds": 20
          },
          "text": "Running our sampling code again."
        },
        {
          "id": "47",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 56,
            "milliseconds": 20
          },
          "endTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 58,
            "milliseconds": 100
          },
          "text": "So we have that for this notebook."
        },
        {
          "id": "48",
          "startTime": {
            "hours": 0,
            "minutes": 3,
            "seconds": 58,
            "milliseconds": 100
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 0,
            "milliseconds": 464
          },
          "text": "And here you can see that when you run this,"
        },
        {
          "id": "49",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 0,
            "milliseconds": 465
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 5,
            "milliseconds": 360
          },
          "text": "this is actually choosing completely random context right here, completely randomly."
        },
        {
          "id": "50",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 5,
            "milliseconds": 360
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 12,
            "milliseconds": 980
          },
          "text": "You can see the different types of outputs of objects and people."
        },
        {
          "id": "51",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 12,
            "milliseconds": 980
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 16,
            "milliseconds": 220
          },
          "text": "And now controlling it a bit, you can actually define it here."
        }
      ],
      "source": [
        "It's pretty common for diffusion models.",
        "And then we add context when we call the neural network right here.",
        "So let's load a checkpoint where we did train the model with context.",
        "So just loading that model here, running that.",
        "Running our sampling code again.",
        "So we have that for this notebook.",
        "And here you can see that when you run this,",
        "this is actually choosing completely random context right here, completely randomly.",
        "You can see the different types of outputs of objects and people.",
        "And now controlling it a bit, you can actually define it here."
      ],
      "result": [
        "这对扩散模型来说是很常见的。",
        "然后我们在这里\\N调用神经网络时添加上下文。",
        "让我们加载一个\\N带有上下文训练的模型检查点。",
        "加载这个模型，运行它。",
        "再次运行我们的采样代码。",
        "这个Notebook就有了。",
        "你可以看到运行时，",
        "这里实际上是\\N完全随机选择的上下文。",
        "你可以看到\\N不同类型的物体和人物输出。",
        "现在稍微控制一下，\\N你可以在这里定义它。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "52",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 16,
            "milliseconds": 220
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 20,
            "milliseconds": 900
          },
          "text": "So here I just defined, oh, hero, a couple heroes, the first two."
        },
        {
          "id": "53",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 20,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 21,
            "milliseconds": 900
          },
          "text": "So these two are heroes."
        },
        {
          "id": "54",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 21,
            "milliseconds": 900
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 23,
            "milliseconds": 720
          },
          "text": "The next two are side facing."
        },
        {
          "id": "55",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 23,
            "milliseconds": 720
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 28,
            "milliseconds": 580
          },
          "text": "So it's one hot with this last value here for side facing."
        },
        {
          "id": "56",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 28,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 30,
            "milliseconds": 300
          },
          "text": "The next two are non-heroes."
        },
        {
          "id": "57",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 30,
            "milliseconds": 300
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 31,
            "milliseconds": 700
          },
          "text": "So kind of beasts."
        },
        {
          "id": "58",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 32,
            "milliseconds": 140
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 35,
            "milliseconds": 620
          },
          "text": "They look very blobby here."
        },
        {
          "id": "59",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 35,
            "milliseconds": 620
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 37,
            "milliseconds": 660
          },
          "text": "And the last two are food items."
        },
        {
          "id": "60",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 37,
            "milliseconds": 660
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 40,
            "milliseconds": 60
          },
          "text": "So this kind of looks like an apple."
        },
        {
          "id": "61",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 40,
            "milliseconds": 60
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 42,
            "milliseconds": 940
          },
          "text": "And this kind of looks like a pear."
        }
      ],
      "source": [
        "So here I just defined, oh, hero, a couple heroes, the first two.",
        "So these two are heroes.",
        "The next two are side facing.",
        "So it's one hot with this last value here for side facing.",
        "The next two are non-heroes.",
        "So kind of beasts.",
        "They look very blobby here.",
        "And the last two are food items.",
        "So this kind of looks like an apple.",
        "And this kind of looks like a pear."
      ],
      "result": [
        "我在这里定义了两个英雄，\\N第一个和第二个。",
        "这两个都是英雄。",
        "接下来的两个是侧面的。",
        "最后一个值是侧面的。",
        "接下来的两个不是英雄。",
        "有点像野兽。",
        "它们看起来很胖乎乎的。",
        "最后两个是食物。",
        "这个看起来像苹果。",
        "这个看起来像梨子。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "62",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 42,
            "milliseconds": 940
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 48,
            "milliseconds": 580
          },
          "text": "And now getting into the avocado armchair vibe, we can actually mix and match these a bit."
        },
        {
          "id": "63",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 48,
            "milliseconds": 580
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 51,
            "milliseconds": 833
          },
          "text": "So while we trained it on one hot encoded vectors,"
        },
        {
          "id": "64",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 51,
            "milliseconds": 857
          },
          "endTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 57,
            "milliseconds": 780
          },
          "text": "we can also provide it with these float numbers between 0 and 1 to get a mix of things."
        },
        {
          "id": "65",
          "startTime": {
            "hours": 0,
            "minutes": 4,
            "seconds": 57,
            "milliseconds": 780
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 3,
            "milliseconds": 380
          },
          "text": "So here for the second one here, it is a hero and partially food."
        },
        {
          "id": "66",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 3,
            "milliseconds": 380
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 5,
            "milliseconds": 260
          },
          "text": "And so now it looks like a potato man."
        },
        {
          "id": "67",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 5,
            "milliseconds": 260
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 7,
            "milliseconds": 20
          },
          "text": "The third one is also a little bit quirky."
        },
        {
          "id": "68",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 7,
            "milliseconds": 20
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 8,
            "milliseconds": 820
          },
          "text": "It is part food and part spells."
        },
        {
          "id": "69",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 8,
            "milliseconds": 820
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 10,
            "milliseconds": 20
          },
          "text": "So it kind of looks like this potion."
        },
        {
          "id": "70",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 10,
            "milliseconds": 20
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 12,
            "milliseconds": 280
          },
          "text": "But yeah, you can play with these yourself."
        },
        {
          "id": "71",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 12,
            "milliseconds": 280
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 19,
            "milliseconds": 80
          },
          "text": "You can try to put in something contradictory, like it's supposed to be a hero, but also side facing, like both front facing and side facing."
        }
      ],
      "source": [
        "And now getting into the avocado armchair vibe, we can actually mix and match these a bit.",
        "So while we trained it on one hot encoded vectors,",
        "we can also provide it with these float numbers between 0 and 1 to get a mix of things.",
        "So here for the second one here, it is a hero and partially food.",
        "And so now it looks like a potato man.",
        "The third one is also a little bit quirky.",
        "It is part food and part spells.",
        "So it kind of looks like this potion.",
        "But yeah, you can play with these yourself.",
        "You can try to put in something contradictory, like it's supposed to be a hero, but also side facing, like both front facing and side facing."
      ],
      "result": [
        "现在我们可以混合这些一下，\\N就像牛油果扶手椅的感觉那样。",
        "虽然我们在一个\\N热编码的向量上训练了它，",
        "但我们也可以用0到1之间\\N的浮点数来获得各种混合效果。",
        "所以这里的第二个\\N是英雄和部分食物。",
        "现在它看起来像个土豆人。",
        "第三个也有点古怪。",
        "它是部分食物和部分法术。",
        "所以它看起来像这种药水。",
        "不过，你可以自己试试。",
        "你可以尝试输入一些矛盾的东西，\\N比如它应该是个英雄，但同时\\N又是侧面的，就像正面和侧面都有。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    },
    {
      "items": [
        {
          "id": "72",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 19,
            "milliseconds": 80
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 21,
            "milliseconds": 700
          },
          "text": "So this is good fun."
        },
        {
          "id": "73",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 21,
            "milliseconds": 700
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 27,
            "milliseconds": 529
          },
          "text": "Feel free to stop, pause, and play with this a few times and start changing these values up."
        },
        {
          "id": "74",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 27,
            "milliseconds": 530
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 30,
            "milliseconds": 364
          },
          "text": "So now that you can create all these samples, control them,"
        },
        {
          "id": "75",
          "startTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 30,
            "milliseconds": 365
          },
          "endTime": {
            "hours": 0,
            "minutes": 5,
            "seconds": 36,
            "milliseconds": 320
          },
          "text": "in the next video you'll explore speeding up the sampling process so that you don't have to wait so long to see these amazing samples."
        }
      ],
      "source": [
        "So this is good fun.",
        "Feel free to stop, pause, and play with this a few times and start changing these values up.",
        "So now that you can create all these samples, control them,",
        "in the next video you'll explore speeding up the sampling process so that you don't have to wait so long to see these amazing samples."
      ],
      "result": [
        "这很有趣。",
        "建议你随时停下来，\\N暂停，玩几次，尝试改变这些值。",
        "现在你可以创建\\N所有这些样本并控制它们，",
        "在下一个视频中，你将学习如何\\N加速采样过程，这样不用等待\\N太久就能看到这些精彩的样本了。"
      ],
      "status": "success",
      "errors": [],
      "mismatched": false
    }
  ],
  "sourcePath": "input/How Diffusion Models Work/DiffusionModels_L5_v02.srt",
  "ouputBasePath": "input/How Diffusion Models Work/DiffusionModels_L5_v02",
  "totalCost": 0.19299,
  "translationPath": "input/How Diffusion Models Work/DiffusionModels_L5_v02/translation.json"
}
