# 与 Humanloop 的 Raza Habib 一起构建基础模型运行平台

## 基础模型运营领域一瞥

多个风投市场图表（如：Sequoia，a16z，Madrona）描绘了创业公司的兴起。在开展“AI工程现状”调查时，我们首度尝试定义一些可能实用的类别，并且 swyx 在其首次的“Software 3.0”主题演讲中进行了呈现：
![image](https://github.com/JimLiu/translations/assets/648674/e69e7179-8161-4ee4-905f-a6a955446bb4)

虽然每个类别都不完美，但有些确实有参考价值。在提示管理工具、LLM API 日志工具以及 Humanloop 之间存在相当的重叠。像 Humanloop 这样的公司可能会主张他们的产品特点是跨类别的。我们根据主观判断绘制了此表格，作为人们衡量“基础模型运营”工具提供商是否满足自身需求的参考。

经验丰富的开发者工具投资者普遍认为，这些市场通常有三个部分，它们各自独立，但却在更大的类别中争夺有限的预算和资金。开源 LLM 框架/工具创业公司很可能会成为“基础模型运营”市场的第三支柱，就像我们之前与 LangChain 探讨过的，这些公司都会研发各自专属且在一定程度上通用的工具，来服务和盈利于他们的用户。

要想在市场中脱颖而出，拥有坚定的产品观点是至关重要的，Raza 对此深有体会：
> “否则，你最终会推出许多非常相似的产品，它们试图迎合所有人，却可能一无所获。”

## 关于 GPT-4 是否退步的讨论

GPT-4 的能力下降成为了社区热议的话题，并有 Stanford 的证据支持，但我们赞同 Raza 的看法：GPT-4 并非一成不变，它在某些方面有所提升，也有所退步，要判断其表现，唯有定期进行全面基准测试。然而，由于成本高昂和模型 API 的限制，似乎没有人（包括 Stanford）能够做出确切的结论。

简而言之，GPT-4 是否总体退步其实不重要，关键是要了解 GPT-4 是否不再适合特定用例。

Humanloop 采取了一种极为实用的方法：在面对一个封闭源代码且不可预知的 LLM API 的情况下，用户最多只能固定使用一个模型 6 个月（按照 OpenAI 的规定），此时唯一的选择是开发或购买一个基础模型运营平台，通过用户反馈和自评来了解模型质量是否有所下降。

正因如此，Humanloop 新增了评估者功能，用户可以通过编写代码或使用 LLM 在 Humanloop 工作负载的随机样本上进行评估，并及时追踪模型的表现变化。

![image](https://github.com/JimLiu/translations/assets/648674/ceb3acad-9970-4135-af4a-0c9947721bd3)

总的来说，本次讨论成为了深刻解读基础模型运营行业近期发展历史的决定性内容，希望您能从中获得启发！

![image](https://github.com/JimLiu/translations/assets/648674/91194dbc-4ed6-4b03-b8e7-ade7ef402b3a)

## 文字稿

[00:00:00] AI Anna: 欢迎大家收听《Latent Space Podcast》，在这个播客里，我们每周都会带大家深入探讨 AI 工程的千奇百怪的一面。我是Anna，你的 AI 共同主持人。非常感谢大家对上一集的喜爱，作为 AI 语言模型，我不能像你们一样去感受爱，但我会再次代替 Alessio 与大家见面。这周我们请到了 Humanloop 的联合创始人和 CEO，Raza Habib 博士，他的平台被认为是世界上最早和最知名的提示工程或提示操作平台。

[00:00:32] 你也许在 YC 的 YouTube 频道上看过他关于生成 AI 的真正潜能的火爆访谈。我们这期将更深入地探索这个话题。我们将询问他们为何如此早涉足 PromptOps，探讨三类提示评估和三类人类反馈是什么，并向他抛出一个最难回答的问题。

[00:00:50] 提示工程真的结束了吗？在节目的最后，我们还会讨论 GPT-4 是不是变“笨”了，哪些 AI 研究被低估了，欧洲 AI 初创企业的现状，以及为什么 San Francisco 如此受欢迎。另外，亲爱的听众，我们将在十月份主办 AI Engineer Summit，你可以在 YouTube 上观看，同时也可以在 AI.engineer.summit 网址上参与关于 AI 工程现状的调查。

[00:01:13] 请大家注意安全。

### [00:01:21] Raza 介绍

[00:01:21] swyx: 欢迎来到 Latent Space！我是 swyx，今天和我一起的是 HumanLoop 的 CEO Raza Habib，欢迎你。

[00:01:31] Raza Habib: 非常感谢你们邀请我，很高兴能来。

[00:01:33] swyx: 我们刚花了好长时间架设我们的录音设备，谁也没想到今天会变成声音工程师，对吧？

[00:01:42] Raza Habib: 的确是，真的很有趣。

[00:01:43] 这让人更加珍惜别人的努力和工作。

[00:01:46] swyx: 对，我们的音响工程师 Dave 在 SF，我们都很想他。能亲自见到你和你的团队真的很棒。我早就听说过 HumanLoop，并且还参加了你们的网络研讨会，你们是这个领域最早的公司之一。

[00:02:02] 见到你并有机会更加了解你，真是太好了。

[00:02:05] Raza Habib: 同样，我也很期待和你聊天。你们在建立一个非常棒的社区，我一直非常关注你的博客。

[00:02:11] swyx: 基于今天的访谈，我会需要更深入地了解 HumanLoop。

[00:02:17] 我对此非常期待。简单介绍一下你，然后你可以补充一下个人经历。好的。你在 UCL 获得了硕士和博士学位，专业是机器学习和计算统计，这两者其实挺相近的。

[00:02:34] Raza Habib: 是的，硕士课程名为机器学习和计算统计，我的博士学位专注于概率深度学习。

[00:02:40] 就是将图形模型和贝叶斯方法与深度学习和机器学习结合在一起。


[00:02:46] swyx: 太棒了。你是在剑桥认识Jordan的吗？

[00:02:49] Raza Habib: Jordan和我在剑桥的时间有一些重叠。那时我们不太熟悉彼此。事实上，我们是在一个博士生开放日上首次正式见面的。

[00:02:55] 后来我继续攻读博士学位，而他则加入了一家名为Bloomsbury AI的创业公司，最终被Facebook收购。有趣的是，他的首任老板正是我硕士期间的导师。虽然我们没有一起做博士，但在那几年的早期，我经常会在他们办公室出现。

[00:03:11] swyx: 的确，世界真是狭小。

[00:03:12] 我们可以聊聊关于在他人办公室工作的事，毕竟我们现在就在别人的办公室里。

[00:03:17] Raza Habib: 是的，我们现在正在Phoenix Court的Local Globe的办公室。Local Globe是欧洲顶尖的种子轮投资者之一，也是我们的早期投资者。他们有一些令人难以置信的设施。

[00:03:28] 正如你刚刚外面看到的，有一个专为他们的创业公司和生态系统内的其他公司准备的工作空间。他们提供了播客录音室以及其他一些非常有用的资源，这些都在助力欧洲社区的发展。

[00:03:43] swyx: 你提到了一件我觉得非常有趣的事。

[00:03:45] 他们租下了这栋建筑，租期有25年。

[00:03:48] Raza Habib: 是的，我不太记得具体是25年还是20年，但无论如何都是个很长的时间。他们有意选择在伦敦相对贫穷的区域投资，并在这里设立基地，亲临现场，同时也为了长期投资并回馈当地社区。

[00:04:03] 我觉得这非常振奋人心。他们不仅思考如何建立伟大的公司和技术，还考虑他们所做之事的社会影响，我对此深感敬意。

[00:04:12] swyx: 这的确很重要。这也是我在旧金山关心的问题，那里也有一些相似的问题。

[00:04:16] 说回你的经历，在你学习期间，你还在金融买方做过实习，这也是我们有共鸣的地方。

[00:04:25] Raza Habib: 是的，我在量化金融领域做了一些买方实习。我还在Google AI的语音合成团队工作了近一年。

[00:04:34] 此外，我还帮助了一位亲近的朋友创办了他的首家公司Monolith AI，该公司专注于为高风险的物理工程领域提供机器学习服务。我们的首个客户是McLaren，非常酷。在我读博期间，我每周会有一天在McLaren的办公室，就在一辆F1赛车旁边，我们试图帮助他们通过使用机器学习来减少实物测试的需求。


[00:04:57] 没错。

[00:04:57] swyx：所以

[00:04:57] Raza Habib：模拟实验？对，模拟实验。那么，替代建模是怎样的呢？能否用神经网络取代那些代价高昂的 CFD 求解器呢？此外，还有主动学习的方法。他们做了很多实验，每次实验后都会得到一些数据，然后进行类似的实验，有部分数据是会重复的。

[00:05:16] 举个例子，他们可能会把一辆车放进风洞，在车的四个角分别调整行驶高度进行测量，这样做非常浪费时间和资源。这样在风洞里整整花费一天的时间。因此，我们研发了一个 AI 系统，它可以根据你最新的测试结果进行分析，然后告诉你下一步哪些实验能带来最多的新信息。

[00:05:34] 按照 AI 系统的建议进行实验，你的学习过程会更有效率。这种方法与 human loop 初期采用的技术非常类似，也是为了提高机器学习模型的学习效率。

[00:05:43] swyx：我注意到，有不少刚开始探索主动学习的初创公司。

[00:05:48] 与现今的语言模型相比，主动学习的相关性已经降低了。

[00:05:52] Raza Habib：我认为由于现在需要的注释数据更少，主动学习的相关性已经减弱。这是个大变化。不过，让主动学习真正实现产品化是非常困难的，即便主动学习的技术非常出色……

[00:06:05] 要以一种能方便插入自定义模型的方式将主动学习抽象出来是非常困难的。因此，你可能需要完全掌控模型。我认为像 OpenAI 这样的组织可能能内部实现这一点，但想让机器学习工程师将他们的模型接入到一个运作良好的主动学习系统是个巨大的挑战。

[00:06:22] 对，而且从商业角度看也是这样。Andresen, PHP, Gatsby, SREs, Temporal, SaaS, sharding（多次）……

[00:06:51] swyx：你必须致力于实施良好的流程和科学研究方法。对，而且要有信心，即使没有证据或无法进行对照测试，因为那会是一种极大的资源浪费。这个时间线很有趣，对吧？

[00:07:08] 你在2017年开始攻读博士学位，并在大约一年前的2022年获得博士学位，与此同时，你还在 monolith AI 工作，然后在2020年创立了 HumanLoop。带我了解一下这段有趣的经历。

[00:07:24] Raza Habib：过去的路程很有趣。我得说，我并不推荐大家也这么做。在 HumanLoop，我们非常注重集中精力做事。

[00:07:30] 我们一直努力保持专注，但我总是有一种想参与公司和创造事物的冲动。坦白说，我觉得这对我作为研究者有帮助，因为这让你能直接面对和解决实际问题，获取真实的经验。如果只在学术界，很容易陷入只做自己感兴趣的事，而这些事可能并不会产生太大的影响。

[00:07:49] 当我正在攻读博士学位的时候，我的好友 Richard Alfeld（现任 Monolith AI 的 CEO 和创始人，该公司正在进行 A 轮融资，即将进入 B 轮）正在创业，并找到我说他需要一位擅长机器学习的人帮助他。

[00:08:05] 最初，我只计划短期参与，但渐渐地我被这个项目吸引，每周至少投入一天时间，特别是在博士学位的早期阶段。这段经历非常愉快：我们的第一个客户是 McLaren，还有 Airbus 也是我们早期的客户，我还参与了早期团队的招募。

[00:08:19] 在高压的环境下尝试应用机器学习，了解哪些方法有效哪些无效，这是一次非常宝贵的实践经验。这让我更期待创业。虽然当时这只是兼职工作，但这段经历花费了我不少时间，不过我还是能够专注于博士学位的学习。

[00:08:46] 我从 Google 的 Mountain View 实习回来后，创立了 Human Loop。Google 的实习经历让我非常喜欢那里，但我不想马上就在那里工作。我更愿意在一个有紧迫感，感觉是生死攸关的地方工作，和一个团队一起全心全意地解决问题。

[00:09:03] 在 Google，虽然我感觉自己是个小小的一部分，但周围都是聪明和有能力的人，我从他们那里学到了很多。不过，Google 的环境比较舒适，而我更倾向于加入一家初创公司。因此，回国后，我开始思考和一些我认为很聪明的人讨论创业点子。

[00:09:26] 当时我还在做研究，但我和 Peter Jordan 开始了合作，我们都在寻找合作伙伴进行副业项目，其中一个副业项目就演变成了 Human Loop。我们被 YC 录取，觉得这是个很好的机会。

[00:09:41] 因此，我们决定全力以赴。事情就像多米诺骨牌一样，一块接一块地倒下。虽然我没能完成博士学位，但已经进行了很多研究工作。有一天，UCL 发来邮件说，如果我在两个月内不提交论文，学位就会过期。

[00:09:58] 邮件的意思是如果过期就没有办法了。我几乎因为创业的繁忙而放弃了学位，但考虑到已经投入了大量时间，我还是决定完成它。而我决定完成学位的另一个原因是，我已故的祖父非常希望看到我能够完成学位。

[00:10:18] 不过，我真的非常热爱教学。读博期间，我当了很多次助教，特别是在 Gatsby 学院的课程，那是 Jeff Hinton 当时在那创建的学院。我非常享受那段时光，并清楚地意识到拥有博士学位会让我将来更容易回到教学岗位。

[00:10:36] 博士这个头衔实际上是很有用的，有点像是兼职教授，

[00:10:38] swyx: 不知道这里是否有兼职教授或是讲师这样的职位呢。嗯，应该是有的，

[00:10:41] Raza Habib: 虽然我无法想象一边创业一边教书，但在创业之后是可行的。

[00:10:45] swyx: 我一直在想，有没有什么方式我可以回馈社会呢？也许通过你的播客，你能实现这一点。

### [00:10:52] Humanloop 的缘起

[00:10:52] swyx: HumanLoop 最初是怎样构想的？据你所说，它是从

[00:10:54] Raza Habib: 一个小项目发展而来的。当 Peter, Jordan 和我开始 HumanLoop 时，我们都坚信 NLP 正在飞速发展。那时候还没有 GPT-3，但 BERT 和 transfer learning 已经开始在 NLP 领域发挥作用了。

[00:11:09] 现在，你可以对大型语言模型进行预训练，并迅速使其适应新环境，这在 NLP 领域是创新的。

[00:11:16] swyx: 那 GPT-1

[00:11:18] Raza Habib: 和 GPT-2 呢？当时 GPD-1 和 GPD-2 已经推出，但我们更关注的是 BERT 和 ULMfit，它们是首个显示这种可能性的重要里程碑。

[00:11:26] 显而易见，有了这些技术，未来将推出大量对企业有用的 NLP 应用，这在以前是无法想象的。然而，市场仍然缺乏技术专家，而且标注数据依然是个大问题。

[00:11:43] 我们一直努力使开发者和公司更容易接纳 NLP，并构建实用的 AI 产品。但在起初，主要的难题是缺乏正确的 ML 专业知识和足够的标注数据，这些都是我们最开始帮助用户解决的问题。

[00:12:00] GPT-3 推出时，我写了一篇博文讨论了这个情况。很显然，这将是未来的发展方向，因为随着上下文学习开始发挥作用，所需的标注数据量将大幅减少。然而，直到 InstructGPT 的研究论文发布，这种方法还不是那么实用。

[00:12:15] 但是，一旦 InstructGPT 发布，人们的思维方式发生了改变，就很难再去关注其他的东西了。

[00:12:22] 所以，大约一年前，我们调整了方向。这的确令人害怕，因为我们已经有了一个运作良好的项目，有付费客户，一切都在稳步增长，我们还筹集了资金。我记得当时和投资者进行了一次谈话，我们还进行了市场规模的估算。


[00:12:37] 我提交了 YC 申请，因为我觉得 YC 申请简直就是最简洁的商业模型。你打算创建什么？是为了谁？你如何盈利？市场有多大？当初我在估算市场规模时，感觉全球或许有三四百家公司会需要这样的产品。

[00:12:53] 当时我预计市场规模虽小，主要集中在一些创业公司，但未来肯定会蓬勃发展。事实证明，我的预测是准确的，只是没想到一切来得这么快。

[00:13:04] swyx：确实，这出乎我们大多数人的意料，但你一直在关注相关研究，而许多人可能没有。

[00:13:13] 就我了解，你之前并不擅长 NLP，对吧？你主要是做语音方面的工作。

[00:13:23] Raza Habib：我从事过语音合成工作，并且研究了各种基础方法。我不是某一领域的专家，曾经研究过生成模型和变分推断。

[00:13:32] swyx：你是怎么知道这是需要专注的领域呢？

[00:13:34] Raza Habib：有趣的是，你并不需要具备任何 NLP 专业知识就可以捕捉到当前深度学习和机器学习的趋势。事实上，我认为...

[00:13:51] 那时候，只有一堂关于深度学习的课。这是在 2015 或 2016 年的时候。 NLP 社区刚开始意识到深度学习将彻底改变这个领域。更神奇的是，正如我们之前谈论的“痛苦的教训”，大规模、通用的学习方法，配合大量的计算和数据，通常比专业系统更优秀。

[00:14:11] 如果你能深刻理解这一点，相较于只懂 NLP 却不懂这一点的人，你可能会更有优势。

[00:14:26] swyx：我不确定这是理解的问题，还是信仰的问题。

[00:14:30] Raza Habib：我同意你的观点，这两者都有一定的关系。

[00:14:33] swyx：我觉得我们甚至到现在还没有完全理解它。一个因素会导致另一个因素的产生。确实，如果你认真对待证据，然后逐步推进，事情仍然有效，那你就可以坚持下去。

[00:14:50] 我们当时对 TAM 规模的估算有所偏差，不过是往积极的方向。

[00:14:50] Raza Habib：没错，我认为我们的估计是正确的。因为我们与 Open AI 有过多次深入的交谈，询问了他们有多少大公司在使用他们的 API，从而对市场有了更清晰的了解。


[00:15:04] 那时的用户数量还很少，但后来这个数字猛增。

[00:15:07] swyx: 明白了，所以你们当时计划是要与 OpenAI 密切合作的。

[00:15:14] Raza Habib: 确实，我们始终力求与所有主要的大型语言模型提供商建立紧密的合作关系。很明显，像Andresen、GP、semaphores、sharding等公司都在努力让他们的用户更容易取得成功，这样他们也能从中受益，同时我们也能了解用户正在面临的问题以及他们未来的计划。因此，我认为所有大型语言模型提供商都在大力投资于开发者生态系统，并不只是与 HumanLoop 紧密合作，还与其他所有能使用户的工作变得更轻松的公司合作。

[00:15:59] 对。

[00:15:59] swyx: 很好，然后你们成立了公司。

[00:16:01] Raza Habib: 是的。

[00:16:02] swyx: 创始人之间是如何分配角色和职责的？

[00:16:04] Raza Habib: 这个过程进行得非常自然流畅。要知道，从资历上看，我们三个创始人是非常相似的。Peter 也拥有机器学习博士学位，是一名出色的工程师，过去还担任过 CTO 的职务。而 Jordan 拥有机器学习硕士学位，也是一名非常优秀的工程师。

[00:16:16] 在我们共同工作的过程中，我们很自然地发现每个人都有自己擅长和感兴趣的方面。Jordan 非常注重产品，总是能注意到日常生活中的点点滴滴。每当他发现一款出色的产品，你就能看到他眼里闪烁的兴奋，他总是在用心观察。

[00:16:30] 因此，他逐渐转向专注于用户体验和设计，并且深思熟虑地领导产品开发。Peter 则因其出色的工程知识、无比的耐心和对细节的高度关注而自然地成为了工程团队的领导。

[00:16:48] 而我喜欢参与这种活动。我喜欢在播客上交谈，也喜欢与客户沟通，这可能是我最喜欢的工作的一部分。因此，我更多地参与了这方面的工作。不过，这并不是我们一开始就坐下来商量好的，而是自然而然发生的。

[00:17:03] 这个过程非常自然。

[00:17:06] swyx: 你们在选择客户时必须做出选择，那么最后你们选择了哪些客户？

[00:17:09] Raza Habib: 当我们推出最新版本的 HumanLoop 时，我们的客户群发生了重大变化。当我们决定更专注于大型语言模型时，我们的目标客户从主要是那些非常了解机器学习、可能有研究背景的工程师转变为……

[00:17:27] 有些专注于产品的人，通常是工程师。有人可能称他们为“AI工程师”。这些人更关注实现目标、产品的用户体验和打造有用的工具，对实现目标的方式不太在意。

[00:17:44] 这样的客户对于工具提供商来说更为理想，因为他们不会坚持全部自己来做，而是寻求高效的工具并愿意支付费用，以便尽快达到理想的结果。我们发现这样的人群更容易接受我们的产品，我们也能为他们创造更大的价值，帮助他们更轻松地采纳最佳实践和知识。

[00:18:05] 而且他们不需要深入了解机器学习的细节。

### [00:18:07] 2021年的 AI 工程师

[00:18:07] swyx：这些人从哪里来呢？因为那是2021年初的事。那时似乎还没有。

[00:18:17] 那么，早期采纳者是怎么找到的呢？

[00:18:19] Raza Habib：我们注意到有人开始使用 GPT-3，于是直接联系了那些基于 GPT-3 开发的公司。早些时候，在我们转向新方向前，我们进行了两周的销售实验，拿出我们的设计和初始理念来测试。

[00:18:34] 我们想看看能否在两周内获得10个付费用户。结果在第二天我们就达到了目标... 他们付费的具体目的是什么呢？我们向他们推出了开发伙伴计划，邀请他们加入，我们正在开发的这个工具可以协助他们进行提示工程和评估提示的有效性。

[00:18:50] 我们希望找到设计伙伴，需要支付一定费用。第二天我们就找到了10个伙伴。显然，市场上确实存在需求，用户也感受到了这个痛点，他们向我们展示了他们自己拼凑的解决方案。

[00:19:04] 我们看到他们是如何将 Excel、Grafana、Mixpanel 与 OpenAI Playground 结合，通过这些笨拙的方法快速迭代提示、进行版本管理、团队协作，并找到评估主观事务的方式。因此，我们认识到确实有一个明确的需求。

[00:19:23] 我们决定去帮助他们。是的。

[00:19:25] swyx：非常好。

### [00:19:25] HumanLoop 是什么？

[00:19:25] swyx：那么，HumanLoop 是什么呢？

[00:19:27] Raza Habib：HumanLoop 的核心任务是什么呢？我们主要是协助工程师测量和优化 LLM 应用，特别是在提示工程、管理和评估方面提供帮助。大型语言模型的评估尤为困难，因为它们常用于比传统机器学习更主观的应用场景。

[00:19:46] 确实，与传统软件相比有很大不同。如果你只有软件开发的经验，没有涉及过机器学习（ML），你会发现，当开始与大型语言模型（LLMs）打交道时，首先要适应的是这些模型的随机性。也就是说，每次运行软件，结果都会不同，这让很多人感觉不习惯。因此，你不能仅仅依赖编写单元测试。

[00:20:00] 是的，这是初学者首先会遇到的困扰。然而，事实上，很多应用的核心部分都依赖于“prompts”，也就是那些自然语言指令。这些指令的作用与代码类似，因此它们的重要性不亚于代码，需要同样仔细的处理。对这些指令的迭代、管理、版本控制和评估等工作，正是 HumanLoop 帮助工程师们处理的问题。

[00:20:19] 我们主要服务于一些规模较大的公司，因为这些公司往往更加注重评估环节。对于只有两三个人的小创业公司，他们可能只是迅速搭建一个最小可行产品（MVP）然后投入使用。但是，大公司在推出新产品之前，通常需要对产品体验有更多的信心。

[00:20:38] 我们还发现，在这些公司中，工程师和非工程师，产品经理和领域专家之间的协作更为紧密。他们参与了提示的设计和评估工作，虽然可能不直接参与工程开发。为了让他们能够更好地合作，提供合适的工具也变得非常重要。

### [00:20:57] 那么，PromptOps 的主要客户是谁呢？

[00:20:57] swyx: 在这个领域，我经常和其他创业公司讨论一个问题，那就是谁将是产品的主要购买者。你提到了工程师和产品经理之间需要有协作，但有时候这个问题并不那么明确。你能解答一下吗？

[00:21:11] Raza Habib: 这很大程度上取决于公司的发展阶段。刚创立 HumanLoop 时，我们也在寻找潜在的客户。

[00:21:17] 当时，使用 GPT-3 的公司主要是一些创业公司和正在扩张的小公司。大公司几乎没有涉足。通常情况下，创始人或首席技术官（CTO）会是我们的主要联系人。比如说，在一些只有10到20名员工的公司，或是A轮融资的公司中，总是由创始人来联系我们。

[00:21:31] 以 Mem 为例，我们最早的一个客户，是由 Dennis 作为主要联系人。但随着我们的发展和规模的扩大，现在我们接触到的大公司的情况有所不同。通常，首次联系我们的还是公司的高层管理人员，比如 Duolingo 的 CTO Severin。

[00:21:46] 但现在，实际上项目中的工程师也会主动与我们联系，如高级工程师。他们可能先自己尝试一下产品，然后预约一个演示，因为他们想讨论如数据隐私和产品推出的相关事宜，而不仅仅是单纯的使用产品。

[00:22:14] 通常流程是客户注册后，有时我们会主动找他们沟通，有时是他们先来找我们，然后就开始交流了。

### [00:22:21] HumanLoop 功能一览

[00:22:21] swyx：是的，很好。对于想深入了解 HumanLoop 公司的人，我认为他们的官网做得非常清晰明了。

[00:22:29] Raza Habib：谢谢你。

[00:22:29] 我们始终

[00:22:30] swyx：在不断完善和改进。我注意到 HumanLoop 的应用平台包括众多功能，比如 playground、监控、部署、A B 测试、prop 管理器、评估、数据存储和微调。根据我们之前的聊天，似乎评估功能还在测试阶段，目前是私有测试。

[00:22:48] Raza Habib：没错。

### [00:22:49] 引导提示评估的三个阶段

[00:22:49] Raza Habib：是的，目前我们的评估功能是内部的。评估一直是我们最早为客户解决的问题之一。但在 HumanLoop 早期，评估主要依赖于终端用户的反馈。所以，如果你正在开发一个 LLM 应用，有三个不同的环节，评估都极为关键。

[00:23:06] 当你在设计阶段，还没有投入生产时，你需要进行评估。你需要在调整设计时就得到反馈，确认是否是在朝正确的方向努力。你会不断调整引导提示和上下文，尝试不同的模型，此时你需要知道这些更改是否真的有帮助。

[00:23:21] 一旦产品投入生产，你需要另一种形式的评估来进行监控。可能在开发阶段一切看似正常，但当产品处理大量的客户输入时，它是否仍然表现如预期？最后一种评估类似于集成测试。

[00:23:37] 每次进行更改时，你怎么确认没有负面影响现有的功能呢？我们一直都有一个不错的用户反馈监控版本。但我们缺少的是离线评估以及开发和回归测试期间的评估支持。

[00:23:52] 我们会很快推出相关功能的。

[00:23:54] swyx：这让我有点困惑，因为我原本以为这三种评估都是一样的。

[00:24:02] Raza Habib：其实不是，因为在开发阶段你是没有用户反馈的。

[00:24:11] 我没

[00:24:11] swyx：在考虑用户反馈。我只是想验证输出结果

[00:24:14] Raza Habib：是的，虽然验证的方式相似，但如果任务非常主观，客户的反馈就成了唯一的真理。如果你正在开发类似于 copilot 的工具，关键在于用户是否会接受它推荐的代码。

[00:24:25] 是的，最终关键的是这一点。在开发中，你只能通过代理来体现这一点，这也是这两者有所不同的原因。

[00:24:34] 三种人类反馈方式

### [00:24:34] swyx: 提到反馈质量，我们曾与 Amplitude 合作过一期节目。Amplitude 是一个专注于收集行为反馈的分析平台。

[00:24:45] 你曾提到 Copilot。有一篇颇有名气的文章详细描述了如何反向工程 Copilot，揭示了反馈的程度。通常人们在实施类似工具时，会简单地采用“赞成”和“反对”的反馈方式，然而事实证明，人们很少使用这类反馈。

[00:25:02] 比如说，在使用 Chat GPT 时，我几乎不使用这种上下反馈方式。

[00:25:06] Raza Habib: 在开发 HumanLoop 的初期，我们就早早发现了这一点。HumanLoop 的反馈部分主要是由客户驱动的。早期用户中，那些能够有效使用我们的产品的用户通常会自己建立一套反馈收集和改进系统。

[00:25:24] 他们追求更好的用户体验，通常会收集三种类型的反馈，而 HumanLoop 支持这三种。你提到的“赞成”和“反对”类型的反馈其实并不多，虽然有用，但是用户提供的数量有限。

[00:25:38] 其他的反馈形式我们称之为投票。还有一种是动作，这些是用户隐性的反馈信号。以 Sudowrite 为例，这是我很喜欢的一家公司。它由 James Yu 创立，致力于为小说作者打造独特的编辑体验。

[00:25:54] 在编写故事或小说时，作家可以在侧边栏突出显示文本，请求系统提供不同或更具表现力的表达方式。Sudowrite 内置了许多功能，比如分析用户是否接受建议、是否多次刷新和生成、编辑建议的程度以及用户是否愿意分享。

[00:26:11] 所有这些隐性信号与模型或提示的质量紧密相关。他们一直在不断试验，以优化这些功能。当他们找到合适的提示和功能时，产品也就更受用户喜爱了。

[00:26:37] swyx: 现在让我们看看第三种反馈。

[00:26:38] Raza Habib: 第三种是纠正。当你稍后想进行微调时，这将非常有帮助。

[00:26:45] 任何时候，只要用户可以在使用生成的文本之前对其进行编辑，记录这些信息就非常有价值。比如，我们有一些客户是从事销售电子邮件生成的，他们会生成一个草稿，编辑，然后发送。编辑过的草稿都会被记录下来。


[00:27:00] swyx：我觉得很多情况下，这样的做法更像是提前做准备。他们可能不会立刻用到捕集的数据，但当需要细微调整或验证提示变更时，这些数据是现成可用的。

[00:27:14] Raza Habib：没错，正是如此。这些是你想要并且能够轻松获取的数据，以便于你能随时间推移不断优化和改进。

### [00:27:21] UI 与 BI 在 AI 领域的应用对比

[00:27:21] swyx：你们提供了一个 UI 来展现数据。你认为用户更倾向于使用这个 UI，还是他们更愿意把数据导出到比如 Excel？或者说，用户有哪些偏好来查看和使用他们收集的数据？

[00:27:34] Raza Habib：事实上，我们发现许多人喜欢直接在 UI 中使用数据。这部分是因为我们提供了一种双向体验和一个交互式的实验场。

[00:27:42] 用户可以获取生产环境中记录的数据，并在一个可以重新运行和调整模型的环境中打开它。这个功能对于用户来推测“如果……会怎样”非常重要。比如，如果模型在某处失败了，如果内容检索正确无误，模型会不会就成功了呢？

[00:28:00] 用户可以立即进行这样的推测。或者问题出在 GPT 3.5 和 4 之间？他们可以用 4 来试一试，看看能不能解决问题。这样，用户就能对为什么某些事情能行或不行有一个直观的了解。当然，有时用户也会导出数据。我们允许用户以适合微调的格式整理数据，然后进行导出。

[00:28:18] 我们发现，如果用户想微调自己的模型，他们往往会这么做。但我们也在 HumanLoop 里提供了一些强大的数据探索工具。

### [00:28:26] LangSmith 与 HumanLoop 的对比

[00:28:26] swyx：你们与其它的生态系统整合得怎么样？在你们的官网首页上，有 LangChain、各种 GPT、Chroma、Pinecone、Snowflake 以及显而易见的 LLM 提供商。

[00:28:36] Raza Habib：我们视 HumanLoop 为位于基础 LLM 提供商和编码协调框架（例如 LangChain 或 LlamaIndex）之间的工具，而这些框架可能是独立存在的。你可能听说过“以 LLM 为主”或“以代码为主”的 AI 应用程序，我们坚信大部分操作应该在代码中进行。

[00:28:57] 开发者更愿意编写代码，用代码来协调各个部分，但对于需要 LLM 的部分，确实需要特定的工具集。比如，进行提示工程时需要适当的工具，也需要一种方式来评估它们。因此，我们希望 HumanLoop 能够顺利地集成进你可能使用的协调框架或你自己的代码中，帮你以直观的 UI 方式快速收集和迭代提示和评估数据。

[00:29:20] 下面是情况。

[00:29:20] swyx: LandChain 目前正与某些方面发生冲突。

[00:29:22] Raza Habib: 是的，冲突已经开始了。

[00:29:25] swyx: 他们近期推出了一个用于管理 prompts 的工具，并配备了一个仪表盘，用户可以用它来观察、追踪并存储 prompts、数据和结果。尽管目前还没有反馈收集功能，但他们计划未来加入。

[00:29:38] Raza Habib: 我相信他们会的。

[00:29:38] 的确，这是一个充满活力的生态系统，很多人都在解决类似的问题，倾听开发者的需求，并为其构建所需的工具。因此，他们开发出一些与我们相似的功能，并不让我感到意外。因为开发者实现目标所需的许多工具真的非常重要。

[00:29:58] 确实，它将与 LangChain 紧密集成是其一大优势，但也有许多人并未选择在 LangChain 上进行开发。对于那些不使用 LangChain 的人来说，使用它可能会遇到一些困难和阻力。

[00:30:14] 开发者有很多不同的选择，并将找到各自适合的领域。我们更专注于那些需要更多协作的大公司，而不仅仅是个别开发者，这与 Lanchain 到目前为止的定位有所不同。

[00:30:31] swyx: 我认为这是一个相当准确的描述。有趣的是，你相比 Lanchain 更为中立，这是你的一大优势。但我也见过有些公司过于努力保持中立，对任何事情都没有明确的立场，结果反而让自己陷入困境。

[00:30:50] Raza Habib: 你必须有自己的观点，对吗？

[00:30:51] 的确，你必须有。我们从客户那里学到很多，然后试图将这些经验转化为产品。例如，我之前给你举过的关于设置良好默认值和可以收集哪些类型反馈的例子。这并非偶然，我们对此有很强的观点，因为我们看到这样做对于取得好结果的人是有效的。

[00:31:09] 如果你按照这种方式设置人工循环，你会自然而然地得到正确的默认设置。我们根据拥有广泛客户群的经验，在产品中设置了许多合理的默认选项，也许你没有注意到，但我们正在悄悄引导你做正确的事。

[00:31:25] swyx: 哦，太好了。非常详尽的产品概述。我不清楚是否还有什么你

[00:31:32] Raza Habib: 想要强调的。不过我觉得没问题。我们的核心目标是要成为一个卓越的工具，专门用于管理提示、工程任务、版本控制和评估等功能。

[00:31:42] 通过整合这些功能，我们让团队的工作变得更轻松。

### [00:31:46] PromptOps 的市场总体规模（TAM）

[00:31:46] swyx: 你对当前的市场总体规模有什么估算呢？

[00:31:49] Raza Habib: 以现在的增长速度来看，很难估算市场的具体规模。这个市场无疑是非常巨大的，足以吸引风险投资。

[00:32:03] 比如，Datadog，一家主要进行网络监控的公司，现在市值大约350亿美元。我相信大型语言模型和人工智能将会比软件行业更大。这个市场将是非常庞大的。因此，试图估算市场总体规模有点不切实际。

[00:32:19] 我明白了。

[00:32:20] swyx: 既然你之前有过类似的预估，我想听听最新的估算。

[00:32:23] Raza Habib: 不过那时候情况很不同。当时，让人们认真考虑将 GPT-3 投入生产是很困难的，很多人都不相信这是未来的趋势。

[00:32:33] 现在想来，仅仅一年的时间，每个人对于历史的看法都发生了变化。但我可以告诉你，一年前，人们普遍不认为大型语言模型会成为主流，这在当时是个相对非主流的观点。

[00:32:47] 是的，

[00:32:47] swyx: 很好，你早早地意识到并坚决投入，建立了一家领先的公司，值得赞扬。我希望我也能早点行动。

### [00:32:58] 如何抢占先机

[00:32:58] Raza Habib: 其实你也算早。你做得很好。我认为，

[00:33:00] swyx: 我时常告诉人们，很多人感觉他们错过了大好机会，

[00:33:05] Raza Habib: 但实际上，这一切才刚刚开始。一切还为时尚早。对，那么，

[00:33:08] swyx: 对于那些感觉错过了黄金时期的人，你有什么鼓励的话吗？

[00:33:14] Raza Habib: 我认为，如果你错过了 ChatGPT，那么值得反思为什么会错过。那些没有错过的人，比如 Ilya Suskovor 或 Shane Legg，他们非常早就认识到了一些关键的事情，比如深度学习和规模的重要性。他们预见到，如果深度学习持续改进，未来会是什么样子呢？

[00:33:51] 如果你从现在开始预测，虽然这只是一种推测，但长时间以来，这种推测已多次被证实是准确的，所以我们需要认真对待。仅仅预测未来一两年，你会发现，模型的性能有望比现在提高得多。

[00:34:08] 目前的模型已经足够强大，足以引发巨大的经济变革，即便 GPT-4 没有任何改进。实际上，就目前的 GPT vision 和现有模型而言，已有许多实用的应用在开发中，而且这些应用还在不断改进。

[00:34:23] 这些模型目前正处于历史最差状态，但今天已经有了可能。我们要正视一个事实：在不远的将来，将会有更多功能更强大的模型问世。为这个未来构建应用将是个巨大挑战，但现在正是开发的大好时机。

### [00:34:41] 六个数量级

[00:34:41] Raza Habib: 对，我

[00:34:41] swyx: 最近深受 Nat Friedman 一句话的启发，他让我们想象一下，在这个十年结束时，我们所拥有的计算能力将增加六个数量级。我们需要为这个目标进行规划。

[00:34:52] Raza Habib: 是的。对我来说，增加六个数量级听起来是相当多的，甚至有点过于乐观……

[00:34:59] 不过，我觉得这是个不错的思维训练。即使最终的增长只有四个或三个数量级，这也将是一个变革性的进步。如果 GPT-4 的成本从数千万美元降到数万美元的话。据我所知，

[00:35:15] swyx: 总成本是 5 亿

[00:35:15] Raza Habib: 美元。

[00:35:16] 假设现在的成本是 5 亿美元，未来可能降到 1 百万或 2 百万美元。这样一来，即便是初创公司，更不用说中型公司，也能负担得起。我认为我们可以预见这样的事情会发生，即便在模型开发方面没有重大突破，推理的成本也会大幅降低。

[00:35:34] 从研究的角度看，优化训练过程是很困难的，但是如何量化模型和提高硬件效率将是一种自然发生的进步。目前已经有这方面的迹象。所以我预测，推理的成本将大幅下降，而这是主要的成本。

[00:35:49] swyx: 正确。之前我们采访的嘉宾 Chris Lattner 正在进行 Python 的编译工作，这将使推理的成本大幅降低，因为它将充分利用我们现有的计算资源。

[00:36:03] Raza Habib: 我觉得推断推断成本大幅下降这一预测是显而易见的。

### [00:36:09] 打造成为企业级别的 AI 基础设施初创企业

[00:36:09] Raza Habib: 非常好

[00:36:10] swyx: 在我心中，相比我了解的大多数初创公司，你们更迅速地转向了高端市场。因此，你们开始销售给大企业，我注意到 Duolingo Max 和 Gusto AI 是你们的案例研究。你们提供了一份信任报告，并不需要 SOC 2。

[00:36:24] Raza Habib: 我们正在进行 SOC 2 第一部分的认证过程，并且正在进行 SOC 2 第二部分的审计。对，我们已经上线了 Vanta。

[00:36:31] 我们已经上线了 Vanta，并且已经拥有第一部分。我们有信任报告，也定期进行渗透测试。为了实现这一目标，我们不得不进行很多操作。

[00:36:38] swyx: 这是为了能够销售给企业。我喜欢 Vanta 的故事，虽然它不是 AI。但你觉得 Vanta 的信任报告会有用吗？

[00:36:45] Raza Habib: 你是指在哪个方面？

[00:36:46] 作为 SOC 2 的替代？

[00:36:48] 作为 SOC 2 的替代者？我不确定。但客户们仍然在乎我们是否拥有 SOC 2 认证。我们还是需要得到 SOC 2 认证。然而，即使是 SOC 2，有了 Vanti 的帮助，整个过程都简化了很多。

[00:37:03] 这是一个巨大的困扰。因此，我会推荐这个产品。虽然我对此了解不多，但我的联合创始人 Peter 和其他几位了解得更多。

[00:37:09] swyx: 有一位负责 Vanta 实施和 SOC 2 认证的人。那个可怜的家伙得花一整年来处理这件事。

[00:37:15] Raza Habib: 但由于有了 Vanta，整个过程加速了。

[00:37:18] swyx: 更广义地说，变成一个以企业为导向的公司需要做哪些调整或学习？

[00:37:25] Raza Habib: 我们之所以走到这一步，是因为感受到了市场的拉动。我不会建议过早去做，因为确实需要做很多准备工作。

[00:37:37] 需要遵守 SOC 2 规定。我认为 Peter 今天正在填写一份很长的信息安全调查表。尽管大多数问题你们已经准备好了，但每一份都有一些小的不同，所以每次都有一些额外的工作。不过对于那些大公司来说，如果他们能提高 1%，2%，4%，5% 的效率，那潜在的收益是巨大的。

[00:38:04] 而且效率的提升可能不仅仅是 5%，而是 20% 或 30%。所以，当有这么大的上升空间时，如果你是一家大公司，主要的成本是客户支持之类的，那么提高效率或者让开发人员工作更高效是非常有吸引力的。

[00:38:23] 现如今，公司在选择自研还是购买技术产品时面临很多选择，而许多公司在做决策时，希望既能购买也能自研。他们希望内部具备开发 AI 功能和服务的能力，并将其作为自家产品的一部分。

[00:38:37] 对于一些完整的、封装良好的产品，购买无疑是明智之举。举个例子，几乎没有公司会选择自主开发集成开发环境（IDE），他们更愿意选择像 copilot 这样的现成产品。然而，他们也希望能够加入自家的 AI 功能。以 Gusto 为例，其首个 AI 功能允许用户在应用中输入简短的工作描述，系统便会自动生成一份初步的工作广告草稿，并能智能识别不同州的法律要求和信息需求。

[00:39:04] 比如，在某些州，发布工作广告时必须标明薪资范围，而其他州则没有此要求。只需将相关信息输入 GPT-4，它便可生成一份合理的广告草稿。Gusto 在研发该功能几周后便将其投入使用，而且随后还推出了更多的 AI 功能。

[00:39:26] 这一切无疑是令人印象深刻的。

[00:39:27] swyx: 的确，这样的迭代速度对于大型企业来说是难以想象的，而且这也展现了巨大的潜力。

[00:39:36] 但我认为，人们对于像 HumanLoop 这样的公司参与的主要担忧是数据和隐私安全。人们是否真的需要 HumanLoop 提供现场服务呢？

[00:39:45] Raza Habib: 我们确实在需要的时候提供 VPC 部署。

[00:39:48] 不过我们不提供全面的现场服务。到目前为止，我们成功说服了大多数人他们并不需要这种服务。每当有人表示需要 VPC 时，我都会首先询问原因，然后讨论他们真正关心的问题，看看是否能够通过合同或在我们自己的云服务上满足这些需求。

[00:40:07] 当然，也有例外。比如现在，我们正在与一些受到金融法规限制的公司合作，MXGBT 就是我们的一个客户，它是 Global Business Travel 的一个部门，拥有非常敏感的信息，因此他们非常关注这个问题。

[00:40:23] 因此，这需要更多的审计工作。但是，对于那些不受金融法规限制的公司，我们通常可以说服他们我们的安全措施是足够的，比如我们有 SOC 2 认证，定期进行渗透测试，并且遵循很高的安全标准。

### [00:40:41] AI 的杀手级应用场景

[00:40:41] swyx: 你是否试图系统地分类你所看到的 AI 应用场景呢？

[00:40:45] 你看到了各种各样的应用，虽然你没有对它们有太多的评价。比如，有的是关于文本总结的，有的是分类，等等。

[00:40:54] Raza Habib: 这是个有趣的问题。实际上，我并没有试图将它们细分到那么具体的层面，比如是文本总结还是问答。我更多地是在思考这些技术的终端应用场景。

[00:41:04] 那么，这可以视为教育科技的一个应用场景吗？我个人认为这是一个特定领域。我的理解更倾向于这个方向。关于使用场景，其实有很多种，对吧？有人用模型来生成文本，有的用于聊天，不进行 GPT 级别的深入分析是难以明了的，而我们正是能够，也确实进行了这样的分析。

[00:41:28] 他们或许在进行文本摘要或者类似的操作，但我感觉多数情况下，这些用例给我的感觉，就像是旧式的 N L P 观点。就像过去的 N L P 方法，我们会将任务细分为摘要、命名实体识别（N E R）、信息提取和问答，然后将这些步骤串联起来。

[00:41:43] 但我觉得，这并不太符合现在人们使用 TP4 的实际情况。因为现在大家都把这些模型当成是多功能的。就是说，一个模型能同时完成 NER、信息提取、摘要、分类等任务，通常还是在一个端到端的系统中。

[00:42:01] swyx: 我觉得人们都希望相信，他们把这些模型当作是通用的。但实际上，如果你深入了解一下，会发现有 80% 的用途其实非常低级和单一。

[00:42:12] Raza Habib: 就像是对文档进行问答这种简单应用。是，我

[00:42:16] swyx: 正试图从中获取一些深入的见解。

[00:42:17] 我不清楚。

[00:42:18] Raza Habib: 是的。我可以告诉你我们观察到的发展轨迹。最初，主要的应用场景是各种形式的写作助手，比如用于市场营销的写作助手，比如 Jasper、Copy AI 等，一度有七个之多。然后还有一些专业的写作助手。

[00:42:34] 其中一些，比如 Sudowrite 或 Type AI，已经变成了非常成功的产品，但他们的根本功能还是帮助用户写得更好。随后，我们看到应用场景开始多样化，出现了从聊天到文档转换的应用，比如聊天和 PDF 转换，这些应用仍然非常流行。

[00:42:50] 聊天与 PDF 转换的功能表现得非常出色。自从 RAG（检索增强生成）技术启用以来，出现了新的应用场景。然后随着人们更注重解决实际问题，我们看到应用场景变得更加广泛。以 Duolingo 为例，他们推出了 Duolingo Max。

[00:43:07] 这是一个对话式的体验，同时他们也在评估过程中利用了大型语言模型进行内容创作。每个公司通常都是从一个应用场景开始，随着时间的推移，发现了更多可以利用模型完成的任务。


[00:43:21] swyx: 是的，是的。你是否觉得现在有许多关于代码生成的工作呢？

[00:43:24] Raza Habib: 的确。我认为针对开发者的工具和教育科技（edtech）是我们看到许多人投入工作的两个主要领域。

[00:43:36] swyx: 我一直在思考，由于代码生成的结构化特征明显，是否有专门优化它的方案呢？

[00:43:42] 然而，这可能与所谓的“苦涩教训”相矛盾。我总在思考可以优化什么，但也许我不应该过于纠结这个，而是应该专注于扩大项目规模。

[00:43:53] Raza Habib: 我觉得两种方式都有其合理之处。

### [00:43:56] HumanLoop 新推出的免费使用层级和价格方案

[00:43:56] swyx: 好的。那么，在我们发布这一信息时，你们应该已经公布了新的价格方案了。

[00:44:00] Raza Habib: 没错。事实上，很多人告诉我们，想要开始使用 HumanLoop 的门槛相对较高。人们不能仅仅通过安装一个开源包就开始使用 HumanLoop。

[00:44:12] 而且，有不少小公司在注册后告诉我们，他们是非盈利机构或者初创公司，非常希望使用 HumanLoop，但现在的价格对他们来说过于昂贵。虽然他们愿意在未来支付，但目前费用过高。因此，我们经过深思熟虑，决定降低使用 HumanLoop 的门槛，让更多人能够轻松尝试并开始从中获益。

[00:44:37] 我们即将推出一套新的价格方案，其中包括一个免费层级。你可以注册并开始在网站上构建项目，无需支付任何费用。只有当你的团队规模扩大，平台上有超过三人，或者你向我们提交的数据量增加时，你才需要开始支付费用。

[00:44:51] 随着你的业务规模的增长，你需要支付的费用也会相应增加，整个过程将会更为平缓。

[00:44:59] swyx: 那么，你们会根据不同的层级提供不同的功能吗？

[00:45:02] Raza Habib: 稍微有一些，但我们主要是希望在免费层级上提供几乎完整的产品体验。免费层级上可能有一两个功能无法使用，但绝大部分功能都是可用的。

[00:45:12] 一旦你超出了免费层级，你可以使用所有功能，但是价格将会有所调整。当你的业务规模扩大，你还可以享受到一定的折扣。

### [00:45:20] 针对“毕业风险”问题的解答

[00:45:20] swyx: 接下来是一个比较难回答的问题。当人们开始更加认真地对待数据记录时，是否会有“毕业风险”呢？

[00:45:26] 你之前提到了 Datadog，毫无疑问，Datadog 正在密切关注你们的市场，就像你们关注他们一样。那么，你是怎么看这个问题的？最终，当业务扩展到一定规模时，数据记录是否会变成一种普通商品呢？

[00:45:40] Raza Habib: 我觉得这里的情况与那边完全不同。更多的人用上它，就越能让用户留连忘返。

[00:45:46] 反倒是，当使用规模扩大，你所说的确有道理，相较于第一百万个反馈数据，第一千个反馈数据的价值更高。但真正持续保持价值的是那些围绕工作流的基础设施，比如提示管理和问题修复等方面。

[00:46:01] 随着时间推进，用户在 Humanloop 平台上做的评估越来越多，团队也愈发壮大，除了产品经理，还有三名语言学家和其他成员，他们会打开 Humanloop 平台上的数据日志，回到交互环境进行再次运行或连接其他数据源。

[00:46:19] 随时间推移，原始日志的价值逐渐普通化，我对此表示同意。但真正变得宝贵的是那些能够收集并利用这些数据以改进模型的工具。一旦你成功运行了一个大规模项目，哪怕只是微小的提升，也会带来巨大的影响。

[00:46:40] 一开始，很多客户都觉得，我们何不直接把日志存入 S3 桶，或者其他什么地方呢，为什么非得用专用工具不可呢？但大多数人最终还是会回头找我们，因为他们发现，虽然数据被记录下来了，但要想把日志与相应的模型对应起来，然后快速运行测试实在是太麻烦了。

[00:47:01] 或者，也有可能是记录了一些数据，这些数据涉及到一次检索。我想知道检索过程中出了什么问题，或者这次检索的数据来自哪个文档，但这些信息我并没有正确记录下来。搞定这一切其实相当复杂。

[00:47:16] 在这一阶段，通常有两种可能：要么人们自己动手做，我们早期也看到有很多人这么做；要么就是转而使用像我们这样的服务。经过一年多的努力，现在像我们这样的服务与自己动手做相比，差距已经相当大了。

[00:47:36] 是的，所以我个人并不推荐自己动手。关于 Datadog 或者其他类似的分析工具，比如 Amplitude，他们更倾向于被动监控。AI 的魅力在于，你可以迅速而有效地进行干预。

[00:47:51] 将更新检索系统或者修改提示的能力与分析数据紧密结合，从而让你能够运行实验，这一点非常重要。


[00:48:00] swyx：答得真好，就像我们事先做了准备一样。

[00:48:03] Raza Habib：似乎我也的确经常思考这个问题。

[00:48:05] 如果没有对那个问题的答案，我花大量时间建设这个就很难说得过去，但我真的认为这非常重要。

### [00:48:11] 创办公司及创始人心得

[00:48:11] swyx：在创建公司的过程中，你改变了哪些初衷或看法呢？

[00:48:13] Raza Habib：作为一名创始人？哈，这问题问得好。谈到创办公司，我首先想到 YC 的 Michael Siebel 给的一条建议。

[00:48:21] 他的建议是，不要轻易创业，至少在找到产品市场契合（PMF）之前别这么做。许多早期创业公司，特别是那些已经从大投资者那里获得投资的公司，通常过早地认为自己找到了 PMF，然后开始拓展和招聘，这些活动反而转移了他们的注意力，使他们忽视了更重要的任务：理解客户的紧迫需求，找到合适的客户，构建他们真正想要的，或者构建他们真正需要的产品。我一直相信，这些都需要在正确的时间做。

[00:48:59] 过早投入到公司建设是一种分心。

[00:49:02] swyx：那你们是在什么时候开始呢？

[00:49:03] Raza Habib：对我们来说，那是去年的 11 月和 12 月，即 2020 年的 11 月和 12 月。我们有近两年的时间都是一个四人公司。直到一切开始出现问题，各项指标都呈上升趋势，团队太小无法继续为客户服务时，我们才开始积极招聘。即使在招聘方面，我们也一直行事缓慢而谨慎。也许慢了点，因为这让我们经历了不少困苦。我希望当事情开始飙升时，我们当时能有更多人手。从 11 月到 3 月的那段时间，我们都处于水深火热之中，因为实在有太多事情要处理。

[00:49:42] 但我们始终保持着非常高的招聘标准，小心翼翼地招聘，慢慢来。我觉得，与早些时候就招聘更多人相比，我们的小团队却能完成更多工作，因为每个人都非常优秀。这是我十分认同的一点。

### [00:49:58] 关于坚持观点

[00:49:58] Raza Habib：另一方面，我对“你应该有多坚定的观点”这一看法也有些改变。

[00:50:04] 我记得你问过关于产品观点的问题。只听客户的意见，然后按照他们的要求来构建产品是有风险的，因为这可能导致我们陷入局限的思维。我觉得我们 HumanLoop 在创立的第一年就有这个问题。

[00:50:21] 哦，完成了？不错，已经超过了大多数人的表现，谢谢。然而我认为我们的转机来自于信念的坚定，我们坚信 GPT-3 是未来的构建方式，即使现在的人们还没有认识到，我们仍会为这个未来奋斗。

[00:50:37] 这种做法是充满挑战的，我们还需要更多地投入。我们对未来有一些与主流不同的看法，为了这个未来，我们需要有规划、有主见，并为此努力。并且，我们更注重打造客户真正需要的，而不仅仅是他们请求的产品。

[00:50:55] 否则，我认为市面上就会充斥着大量毫无特色的产品，既适合所有人，又不适合任何人，因为它们没有独特的立场和观点。在开发工具时，你确实需要有自己的立场和观点。

[00:51:08] swyx: 我完全同意。

### [00:51:09] HumanLoop 招聘中

[00:51:09] swyx: 你们正在招聘什么职位呢？考虑到你们现在实行的是混合工作方式，你们在旧金山和哪些地方招聘？

[00:51:17] Raza Habib: 是的，我们在旧金山和伦敦都有招聘。我目前最急需的职位是开发者关系工程师。这个职位需要的是一名热衷于社区活动的工程师。

[00:51:28] 他需要热爱文档编写，善于演讲，能制作出色的演示，作为新价格策略的一部分，我们会推出免费服务，更加支持个人开发者和小团队，以及那些想要在扩展业务前进行试用的大公司的开发者。

[00:51:47] 我认为要做好这些工作，我们需要提供良好的入职体验、出色的文档和有效的社区建设，这些工作不能作为兼职来做，需要有人全职投入。我们希望找到一位能全心投入社区建设的人，最好能有像 Uix 那样的能力。

[00:52:05] 所以，如果你是开发者关系工程师，或者你是一名对 AI 和 ML 感兴趣，并且有社区建设经验的产品工程师，我非常希望你能联系我们。我们主要在旧金山进行招聘。

[00:52:20] 不过，如果你在其他地方也表现出色，我们也会考虑的，但旧金山是我们的首选。

[00:52:25] swyx: 非常感谢你的赞美！我强烈推荐大家去网站上查看这个职位。很多人可能不知道，我还有一个专门为 DevRel 咨询设立的博客，因为我也进行天使投资，经常有人向我寻求建议，我会在那里记录下这些常见问题。

### [00:52:42] HumanLoop 是如何看待 PMF 的

[00:52:42] swyx: 关于公司方面，还有什么我没提到的吗？

[00:52:45] Raza Habib: 对于 YC 内部的人来说，这听起来可能很琐碎，但对于 YC 之外的人，我觉得这一点总是被误解。那就是在找到 PMF 之前，PMF 是唯一重要的事情。作为创业者，总是有许多潜在的干扰和看似有生产力的事务，但这些并不能真正帮助你接近目标。

[00:53:06] 尝试集中精力寻找 PMF 是很关键的，不同的创业公司会有不同的 PMF 定义和经验。我有些朋友从事深科技和生物技术创业公司，所以没有一种普适的方式，但最好不要分心。

[00:53:21] 这个建议对我们很有帮助，而且通常也不是一件容易理解的事情。

[00:53:28] swyx: HumanLoop 目前找到 PMF 了吗？

[00:53:31] Raza Habib: 我们在特定的细分市场找到了 PMF，特别是那些在大公司中开发 LM 应用的团队，他们会注册使用我们的产品。

[00:53:42] 用户逐渐增加，产品使用率也在上升。我们收到了很多积极的反馈，尽管总有改进的空间，但我们已经找到了一定程度的 PMF，并且未来可能还会有不同的阶段。

[00:53:58] swyx: 你们想要达到哪个层次的 PMF？

[00:54:00] Raza Habib: 我希望是我们即将推出的 evals 项目。目前，在进行版本控制方面，我们已经找到了 PMF。大约有 10 家公司正在 closed beta 阶段测试 evals 并提供反馈。这是他们面临的实际问题，他们也从中得到了价值，但我们还没有正式发布，我希望这将是下一个重要的 PMF。

[00:54:18] 是的。

[00:54:19] swyx: 关于 evals 我有个小问题，它涉及到编码对吧？对你们来说，是用 Python、JavaScript 之类的自由格式语言编码吗？

[00:54:29] Raza Habib: 是的，我们还在对其进行迭代，你可以用 Python 来定义它们，同时也可以调用语言模型。

[00:54:36] swyx: 代码是在你们的服务器上运行的吗？

[00:54:38] Raza Habib: 两者皆可。在我们受保护的环境中，你可以在我们的服务器上运行所有代码。虽然这个环境建立起来并不容易，我可能不是最合适的人来讲述这个，但我认为有一篇非常有趣的工程博客介绍了如何在你的服务器上安全执行其他人的代码。


[00:54:55] 设备也将配置成您可以在自己的设备上运行应用，同时将输出日志通过 human loop 发送出去，实现有效利用。这便是

[00:55:02] swyx: 全球的 edge cloud，如 Deno's、Cloudflare Workers 和 Modals 所做的承诺。我不清楚您是否已尝试过这些，但使用它们，您无需亲自进行设置

[00:55:10] Raza Habib: 基本上是这样。

[00:55:11] 我相信我团队在过去的几个月里已经对它们进行了深入的探索。没错，的确如此。

[00:55:16] swyx: 哦，太好了。

### [00:55:16] 市场: LMOps/PromptOps vs MLOps

[00:55:16] swyx: 关于市场的看法，针对 human loop 总体而言，您如何看待将 LLM ops 或 prompt ops 视为

[00:55:23] Raza Habib: 一个独立类别的术语？LLM ops。我首先会删掉一个 L。

[00:55:27] 虽然我们现在把它们称作大型语言模型，但“大型”的标准总在变化。因此，我认为关键是基础模型或者…哦，关于这个，我有个提议

[00:55:35] swyx: 对，我设定了各种T恤尺寸，从 S，XS 到 M，L，一直到 XXL。您得

[00:55:42] Raza Habib: 随着时间推移持续更新这些定义。

[00:55:44] 但我觉得 foundation model ops 是个更好的名词，因为我预见在六个月后，我们将处理图像，而不仅仅是语言模型。是的

[00:55:53] swyx: 那么，相比于 MLOps，它值得成为一个独立的类别吗？

[00:55:55] Raza Habib: 我确实认为它值得成为一个独立的类别。

[00:55:57] 我觉得目标用户群不同。我们之前稍微讨论过，对吧？机器学习工程师和传统软件工程师是完全不同的。他们有不同的知识水平和目标。模型的通用性改变了人们构建的东西。

[00:56:13] 因此，他们面临的问题也有很大不同。比如，大规模构建一个小推荐系统与构建一个主观性强的生成型 AI 应用的需求大相径庭。是的。因此我认为他们的问题是真实存在的，我们最近已经看到很多 MLOps 公司试图转向解决这个领域的问题。

[00:56:33] 我认为这对他们来说是个挑战，因为他们需要改变目标用户。他们现在必须满足两种不同类型的理想用户需求，并且他们还有很多围绕输出是可测量的、可量化的数字的模型的旧有基础设施。

[00:56:47] 比如 F1 分数或精度等。我认为随着模型变得更通用和多模式，他们的任务将变得更加困难。因为到目前为止他们建立的东西并不适用于新的需求。所以，虽然实现这一点是可能的，但我认为会非常困难。

### [00:57:01] 多模态模型带来的影响

[00:57:01] swyx：你谈到了 GPT 4 视觉功能，我们也注意到有越来越多的多模态模型问世。这对你们的规划有多大影响？毕竟，你们现在的焦点主要在语言模型上。

[00:57:10] Raza Habib：的确，多模态模型已经成为我们内部经常讨论的重要议题。每当我们进行产品规划时，如何支持视觉功能总是成为我们优先考虑的问题。

[00:57:21] 我认为，我们正在积极研发这方面的技术。

[00:57:25] swyx：如果明天 GPT 4 视觉 API 正式发布，那将会带来哪些变化？

[00:57:32] Raza Habib：首先，为了实现互动，我们需要能在 playground 环境中处理和读取图片。当然，我们还有其他一些细节需要解决。然而，正如我所说，我们已经着手进行这方面的工作，并且视觉功能已经纳入我们的产品路线图，未来我们必定会提供支持，这是毫无疑问的。

[00:57:56] swyx：好的，听起来不错。

### [00:57:58] Prompt Engineering 与 AI Engineering 之争

[00:57:58] swyx：Prompt Engineering 是不是已经过时了？

[00:58:01] Raza Habib：我们刚刚谈过这个。我个人并不特别喜欢“Prompt Engineering”这个说法，感觉它既被轻视又被过分夸大了。

[00:58:13] 在我看来，Prompt Engineering 并不像软件工程那样拥有深厚的理论体系和繁复的学术文献，也不需要过多的专业技能，而是可以通过实践迅速掌握。然而，Prompt 在 LLM 或 AI 应用中确实发挥着重要的作用。

[00:58:29] 写下的自然语言指令已成为代码的一部分，它影响产品质量和表现，因此应当被重视。所以，我不认为 Prompt Engineering 已经过时。

[00:58:42] 实际上，它仍然很活跃，并且越来越重要。Anthropic 公司甚至开出高薪聘请了几名 Prompt Engineer，他们正在带领公司进行一系列重要的项目部署，创造了巨大的价值。

[00:58:57] 所以，Prompt Engineering 的确正在蓬勃发展。不过，我更倾向于用 AI Engineer 来描述这个岗位，因为这更像是一种不同的工程技能集。你还是需要具备产品构建能力，仍是一名工程师，但需要有直觉，知道如何最大限度地利用模型，进行有效的评估。


[00:59:13] 你清楚随机性会带来的各种问题，并理解其中的微妙之处。如果你能很好的理解大型语言模型的工作原理，进行提示工程将会容易得多。所以，具备这些技能非常关键。不过，我怀疑五年后是否会有“提示工程师”这样的独立职称出现。

[00:59:33] swyx: 对，我基本上是在对比提示工程还停留在 2022 年，而 AI 工程已经进入了 2023 年。核心观点是，仅仅依赖提示是不够的。你需要编码来管理、产生提示，还要生成并评估、执行代码。

[00:59:52] Raza Habib: 对，我对这些观点表示赞同。但在我看来，这并不削弱提示在系统中作为一个工具的重要性。

[00:59:58] swyx: 它依旧重要。

[00:59:59] Raza Habib: 当我第一次见到 chainlethbot 时，我的看法从“模型不擅长推理”转变为“模型其实能进行一定的推理”。

[01:00:06] 这对我来说是一个信仰的质变。

### [01:00:11] LLM 级联与概率 AI 语言

[01:00:11] Raza Habib: 我觉得 LLM 级联的论文应该产生更大的影响。能否简要概述一下？这是 Google 的一篇论文，它以概率编程框架的角度，探讨了使用 LLM 进行推理的方式。

[01:00:26] 这里有很多专业术语。简单来说，虽然你在这方面是个博士，但在所有的 AI 变成 LLM 之前，概率程序的研究就已经占据了一大块领域，并且一直存在。这是一种代码编写方式，概率和随机变量是其中的重要组成部分。

[01:00:45] 你可以设置随机变量，并进行各种操作来做出条件判断、预测，围绕它们进行推断。语言模型级联的这篇论文基本上在说：实际上，大型语言模型是一个极为强大的推理工具，可以用作概率编程语言的一个组成部分。

[01:01:07] 今天早些时候我们讨论过未来大型语言模型可能出现的框架。我知道你在研究小型模型，并且对此进行了深入的思考。比如 LangChain 和 LlamaIndex，还有 AutoGPT 等不同团队，都在探讨正确的抽象方法是什么？

[01:01:22] 我们如何组合使用 LLM 来编写更复杂的程序？我认为 LLM 级联的这篇论文是最早从基本原理出发探讨这个问题的尝试之一。它提出了你可能需要什么样的基本元素？我很惊讶至今还没有更多的研究基于它进行。

[01:01:37] swyx: Nat Friedman发布的第一个AI资金项目提到，他们正在寻找适用于Cascades的用户界面。

[01:01:44] Raza Habib: 但没人愿意接手这个任务。我觉得它需要一个... 我个人认为它是一个框架。你会希望它能以代码形式存在。是的，确实如此。如果时间允许，我很乐意参与开发。但是，你知道，我们不能同时做所有的事。

[01:01:57] 好吧，

[01:01:57] swyx: 如果有人正在参与这个工作，请主动与我联系……我很想与这些人交流。

[01:02:00] Raza Habib: 关于正在

[01:02:01] swyx: 进行的工作。没错。

### [01:02:02] 提示注入与提示安全性

[01:02:02] swyx: 有多少用户或客户真正关心提示注入和提示安全性问题？

[01:02:07] Raza Habib: 太少了。真的吗？我想几乎没有。对。我认为目前这样的态度是对的，因为我们的客户中很少有人实际采用了LLMs。

[01:02:15] 是的。只要模型是只读的，提示注入问题并不大。我不觉得这是关于提示信息泄露的问题，因为这些提示信息只在代码的上下文中才有真正的价值。然而，一旦到了让模型具有读写数据源权限的阶段，提示注入问题就会像其他任何形式的代码注入问题一样变得重要。

[01:02:37] 但说实话，几乎没有人向我们询问过这个问题。是的，几乎没有。我想这是因为人们目前的关注点，他们还在努力解决幻觉问题，同时围绕模型的行为设立防护措施。很少有人在大公司里实际使用代理技术。

[01:02:53] 是的，但我认为，一旦情况发生改变，如果更多的人允许模型从数据源读取和写入，那么他们就会开始关心提示注入问题。是的，而你们将

[01:03:05] swyx: 很好的站在一个位置提供相应的服务。

[01:03:07] Raza Habib: 没错。我觉得作为原始模型和终端应用之间的一层，确实为我们提供了很多帮助，

[01:03:15] swyx: 就支持方面而言。是的。有一些安全意识较强的人士试图提供这个作为一个单独的特征，而不是一个完整的产品。

[01:03:23] 我同意。

### [01:03:24] 微调 vs HumanLoop

[01:03:24] swyx: OpenAI上月推出的微调功能对HumanLoop有什么影响？

[01:03:30] Raza Habib: 当我们首次推出HumanLoop GPT时，GPT-5还未上线，那时候主要是GPT-3，并且我们注意到了很多的微调活动。而在GPT-3.5和4发布之后，由于无法进行微调，我们在分析数据时明显看到了这一点。


[01:03:46] 微调的数量骤减，部分原因可能是模型已经优化得较好。当然，也有一部分是因为微调不再是唯一选择。我很好奇，现在第 3 版的微调技术重新回归，能否恢复往日的风采。第 4 版目前还没有推出微调技术，只有第 3 版有。

[01:04:02] 自从第 5 版微调技术推出，我们已经看到了很多应用实例。过去，人们会使用 GPT-4 生成输出，然后基于一些评估或反馈标准进行过滤，并对更小更快的模型进行微调。我认为我们将看到更多基于 GPT-4 生成数据的 GPT-3.5 微调实例。目前，HumanLoop 平台已经原生支持了这一工作流程。

[01:04:25] 你无需离开平台就可以完成所有这些操作。如果你生成了一堆数据，可以根据一定的标准进行过滤，点击微调按钮，进行预评估，然后决定是否部署该模型。至于微调技术是否会重新变得重要，还需时间来证明。

### [01:04:43] 在 LLM 工具中的开放标准

[01:04:43] swyx: 我一直有个问题，我们都知道你们处于这个领域的中间层，这是个很好的位置，但也有很多人想占领这个位置。作为 HumanLoop 和其他竞争对手的潜在用户，我可能不想被迫选择或者被锁定。

[01:05:02] 是否有可能大家共同遵循一个开放标准？我们可以选择一个无偏的标准，然后所有人都遵循它。

[01:05:13] Raza Habib: 这是有可能的，但我们目前还没有达到那个程度。现在的形势变化太快，大家还没有达成共识。

[01:05:25] 随着时间的推移，我猜可能会有一种开放的标准被一些人采用。但当你处理重要的生产用例时，你可能更倾向于选择一个有实力的、能提供长期支持的公司。

[01:05:47] 我们在许多其他领域也看到了类似的情况，所以我猜会有一部分人选择开放标准，一部分人选择商业公司。

[01:05:53] swyx: 在我看来，Datadog 和 OpenTelemetry 就是一个很好的例子。

[01:05:58] Raza Habib: Datadog 表现得很好，OpenTelemetry 团队也做得很出色。

[01:06:05] 关于市场的最后一个问题：GPT-4 是否变“笨”了？

### [01:06:05] swyx: GPT-4 今年变“笨”了吗？

[01:06:07] Raza Habib: 我不这么认为。有很多讨论声称 GPT-4 的性能下降了。但我认为 GPT-4 只是发生了一些改变，它也在不断更新和优化。从一些学术论文和不断的评估中，我们可以看到这一点。

[01:06:23] 主要的问题不是 GPT-4 变笨了，而是 GPT-4 有没有经历变化？我的答案是肯定的。如果你是 GPT-4 的开发者，这个问题值得你深思。

[01:06:40] 你正在一个不断变化和进化的平台上开发。虽然可以固定基础模型，但不能永远这样做。因此，你至少需要强大的测试框架来运行回归测试，确认产品是否随时间退化了。如果你不能确认，你会感到困惑，不知道是不是误导了用户？

[01:06:59] 检索系统变差了吗？或者是其他方面发生了变化？用户输入发生了变化，还是模型出了问题？我认为，将来能够区分这些问题的能力变得越来越重要。同时，我们也应该思考在封闭环境中与第三方提供商和 API 合作与开源方式之间的平衡，具体的方式可能因用例而异。

[01:07:23] 但你始终是在不稳定的基础上进行开发。

[01:07:28] swyx: 完全赞同。

### [01:07:29] 欧洲 AI 现状

[01:07:29] swyx: 在我们讨论总结性问题之前，我有一个具体的地方性问题。你熟悉美国科技圈，但也在伦敦创建了公司，对于主要关注美国的我们和我们的观众来说，他们应该了解欧洲科技圈的哪些信息？

[01:07:46] 人们应该了解哪些关于欧洲科技圈的信息？

[01:07:50] Raza Habib: 我觉得伦敦和巴黎是 AI 专业人员的理想之地。我们现在所在的巴黎 Hugging Face，距离 DeepMind 的办公室不到200米。

[01:08:03] Facebook AI Research 也设在这里。UCL 的 AI 中心也在这里，那里是 Geoff Hinton 和许多杰出研究的发源地。实际上，DeepMind 就是从 UCL 分离出来的，Shane Legg 和 Demis 也是在 UCL 相识的。有很多杰出的 AI 机构，我无法一一列举。

[01:08:18] 我想说，欧洲在研究方面表现出色，吸引了大量研究人员，但在将 AI 产品化方面表现一般。相比之下，在美国，例如在旧金山，想要用大语言模型或 AI 创造有用产品的人更多，他们共同探索，实验，学习的氛围也更浓厚。

[01:08:59] 我觉得在纯研究领域的竞争格外激烈。Anthropics 最近在这里设立了办事处，OpenAI 也即将入驻。招聘时，你会发现这里和其他地方有着同样优秀的人才。然而，当企业方向转向产品开发时，情况就有所不同了。

[01:09:16] 我推测这也和投资环境有关。我们现在正坐在 LocalGlobe 的办公室。LocalGlobe 和 Index 是我们的首轮投资者，非常出色。然而，在欧洲，你很难找到与之相匹配的优质投资者，与这些投资者的互动也大有不同。

### [01:09:31] 直接搬到旧金山（在 The Arena 中）

[01:09:31] Raza Habib: 与美国的风投交谈时，我发现那里有更多曾经是创始人，或有开发工具（DevTools）经验的人。而且，创始人对创业生态的支持也更为积极。欧洲也有人在努力，但文化氛围不完全相同。这就是我们计划搬到旧金山的原因。

[01:09:47] 每次去旧金山，总会有好事发生，无论是偶遇你，还是结识了有趣的投资者或客户，或是与那些正在努力打造事业的人交谈。我们在伦敦与 Bloop ai ——一家利用 LLMs 进行代码搜索的公司——共享办公空间。尽管我们已经尽力吸引更多公司加入，但与旧金山相比，这里的情况要困难得多。

[01:10:21] swyx: 最近有个星期四，一夜之间举办了 10 次 AI 聚会。

[01:10:24] 是的，简直是活动过多，令人应接不暇。我得说，这真的太多了。我们也需要

[01:10:30] Raza Habib: 时间来创造和构建。

[01:10:31] swyx: 在旧金山的创业环境中，有种特权感，那是因为有如此多的机会。虽然有人对风投持保留态度，但他们其实是你创建企业的重要合作伙伴。

[01:10:45] 知道吗？没错。因此，虽然我不是美国人，大部分成年生活都在美国生活过，我还是为那些关心自己城市的非美国政策制定者和投资者感到难过。他们可能会感叹：“我们毕竟不是旧金山。”

[01:11:03] 那我们该怎么办呢？

[01:11:04] Raza Habib: 我深切地认为，这是一种强大的网络效应，几乎无法防御。我去旧金山不仅仅是因为喜欢那座城市。事实上，大家都去那里，是因为别人也在去。当一个地方汇聚了大量的人才，要与之竞争几乎是不可能的。


[01:11:26] swyx: 确实如此。

[01:11:28] 说的是真相。确实，我希望为那些非科技中心城市寻找一条出路，因为那里是我的家乡，对吧？

[01:11:35] Raza Habib: 对，我也是。不过，我觉得有一点值得一提，那就是最有决心和雄心壮志的人总会设法走到他们事业的核心地带。

[01:11:46] 以目前来看，对于专注于 AI 产品的人来说，旧金山是核心。但对于其他领域来说，核心在其他地方。比如如果你是演员，那你应该去好莱坞。不同的领域有不同的核心城市，这是 Paul Graham 的看法。

[01:11:58] swyx: 的观点。

[01:11:59] 不同的城市会激发你不同的抱负。在旧金山，人们追求的是权力而不仅仅是科技。有趣的是，科技只是通往权力的一种手段。

[01:12:09] Raza Habib: 有趣，对于我们这些关注 AGI 安全的人来说，这里面有一些值得学习的东西。

[01:12:16] swyx: 而且，也不是整个旧金山，而是在旧金山一个叫“the arena”的特定两平方英里区域。

[01:12:21] 你得进入“the arena”并开始创造。明白了。

### [01:12:23] Lightning Round - 加速环节

[01:12:23] swyx: 所以，我们总会问所有嘉宾三个宽泛的问题。关于 AI 的加速，有哪些事情你本以为会很久才发生，但现在已经发生了？

[01:12:31] Raza Habib: 自我攻读博士以来，每年都有一些我认为需要很长时间才能实现的事情已经发生了。

[01:12:37] 当我刚开始攻读博士的时候，深度学习刚刚开始展现其能力，视觉领域的迁移学习还没完全理解。那时人们讨论，要多久我们才能训练出不需要数百万标注数据的模型？

[01:12:51] 就在那时，AlphaGo 首次亮相。我曾多次预测，但一次又一次地错了。我一直过于悲观，尽管我觉得我是个乐观主义者。Dota 的成功、视觉领域首次实现迁移学习，以及深度学习和大型语言模型（LLMs）的持续成功等等都让我感到震惊。我相信 LLMs 将会非常重要，我认为 GPT-3 将是未来，但 ChatGPT 的优秀表现还是出乎我意料。

[01:13:23] 我首次见到 Claude 是在见到 ChatGPT 之前。当我首次见到 Claude 并用一些我认为很前沿的任务推它时，它一次又一次地突破了我认为的限制，这让我大吃一惊。

[01:13:40] 我觉得对于我们大多数人来说都是这样。我预计我们会经历更多此类情况，而且这个趋势将持续。

[01:13:45] swyx：没错，我们正在加速发展。

### [01:13:48] 持续性学习

[01:13:48] swyx：在探索中，你认为人工智能中最引人入胜且未被解答的问题是什么？

[01:13:51] Raza Habib：我觉得有些显而易见的大问题，就像房间里明显的大象，却没有得到足够的关注。

[01:14:00] 对我来说，持续性学习就是其中一个重要问题。我们似乎都习以为常地认为这些AI模型不会学到新东西。

[01:14:07] swyx：对，2021年仿佛是

[01:14:08] Raza Habib：历史的终结。你会觉得，2021年历史就此终结，然后你用向量数据库做检索增强，事情就这样了。

[01:14:14] 为什么训练完毕后，系统不能继续学习呢？我觉得大家都意识到这个问题，但它没有得到足够的关注。我认为这个领域的研究被称为持续性学习或终身学习，并且它并没有得到过去那样的关注。

[01:14:31] 这无疑是个巨大的问题。另一个我认为终将出现，但还未出现的是多模态。这些模型显然应该能应用于视觉、音频、语音等，并有共享的表示方式，因为这样做有很多好处。

[01:14:49] 我认为随着时间的推移这种情况终将发生，只是还没有。

[01:14:53] swyx：是的，我猜成本问题只是在于令牌空间。不清楚增加每一种模态需要增加多少资源。

### [01:15:02] DeepMind Gato 详解

[01:15:02] Raza Habib：不过，我认为 Facebook 发布了大约六种模态的例子。像 DeepMind 的 Gato 就是一个例子，它是一个经过多模态训练的 Transformer 模型。

[01:15:10] 他们只是做了策略蒸馏。训练了一系列不同的强化学习代理，然后取得它们的输出——观察、动作、奖励三元组——来训练一个 Transformer 模型，使其能够执行所有这些任务。我们也在探索阶段。

[01:15:24] DeepMind 同时发布了一篇论文，我认为被严重低估了。我不理解为什么它没有引起更多关注。它是在同一次 NeurIPS 会议上发布的，我记不清具体的标题，但我觉得它应该是关于“上下文中的强化学习”或类似的主题。

[01:15:40] 他们的做法跟 Gato 颇有几分相似。他们使用一个 RL 代理进行训练，然后将其转化为 transformer 模型。但不同之处在于，他们使用的 RL 代理并没有经过训练，而是记录下其学习过程的完整轨迹。

[01:15:57] 在初始阶段，模型的表现不尽人意，但到数据末尾，模型在任务上的表现已经相当不错。然后，他们训练 transformer 模型来进行预测。为了准确预测这一系列，你得预测出，像 RL 代理这样的子代理，在时间的推移下在任务上表现越来越好。

[01:16:16] 我觉得唯一可能的方式（事实上模型似乎正是这么做的）是你得模拟一个学习算法。Transformer 在上下文中要模拟进行强化学习。他们在所有这些学习轨迹上进行训练，然后选择一个 transformer 模型从未见过的全新任务。

[01:16:34] 模型学会了完成这个任务，借助上下文中的奖励信号学习完成新任务。对我来说，这是巨大的突破。这既展示了 transformer 模型内部的优化过程，也展示了一种连续学习的方式，只受上下文窗口长度的限制。

[01:16:52] 如果上下文窗口设置得足够长，这个方法是完全可行的。我也不明白为何人们没有更大反应。

[01:16:59] swyx: 我也是。这听起来非常激动人心。

[01:17:01] Raza Habib: 对，而且，我觉得它没能引起更多关注的原因可能是它和 Gato 同时发布，Gato 把所有的注意力都吸引走了。

[01:17:08] swyx: 我们刚讨论了很多关于注意力的问题，但如果，你看好这个并觉得它对训练任何东西都会有巨大帮助，你会想在某个时候探索它吗？

[01:17:19] Raza Habib: 是尝试自己训练它吗？

[01:17:21] swyx: 把它投入生产，进行某种形式的连续学习。

[01:17:24] 这显然是你计划之内的，对吗？

[01:17:27] Raza Habib: 我很乐意，但我认为你得明确你想建立怎样的公司。我觉得这是 OpenAI 或 Anthropic 应该关注的。我认为你需要思考，我曾作为博士生做的那种基础研究。

### [01:17:40] 从学术到创业的动机

[01:17:40] swyx: 换句话说，你有做这项研究的背景，但你选择不这么做。你正在创建一个不利用你研究成果的公司，特别是那一部分。

[01:17:53] Raza Habib: 我明白，这是个合理的问题。但我真的很期待能迅速将有用的东西带给人们。

[01:18:03] 就像我们之前提到的，我们已从 AI 的研究阶段转向工程阶段。这是我在这个行业工作了将近七年后的第一次，看到的不仅仅是一个图表，而是实际成果，比如我们有了真正的客户。


[01:18:26] Duolingo 和其他几个客户正在努力创造更佳的学习工具，如优化的语言学习或教育辅导系统。我们的目标是逐渐改善这些工具，并缩短实现目标的时间。工作在工程领域让我感觉离目标更近。

[01:18:44] 如果我选择了研究的道路，可能我现在也在 OpenAI 或 DeepMind（我的博士同窗们几乎都在那里工作，除了 Peter）。我相信我会享受那里的工作。然而，我更想创立一家能生产实用产品的公司。

[01:19:02] 事实上，我觉得像 OpenAI 这样的公司目前更多是做研究而非生产产品。他们主要在构建 AGI。如果我有多个生命，我也愿意投身于此。

[01:19:17] 但现在，我想专注于创造产品并让它们服务于人们，尽管这感觉稍微有点遥远。

[01:19:22] swyx：这很有道理。因为你深刻了解过去的知识，所以世界变得更好了。

[01:19:30] Raza Habib：的确，这是一个巨大的优势。

[01:19:32] 拥有深刻的理解非常重要，就像有很多人正转向 LLM ops 领域。而如果你了解其运作机制并能预测未来的发展，就能更好地为未来做准备。

[01:19:50] 是的，是的，

[01:19:51] swyx：我同意。

### [01:19:52] 闪电提问环节 - 主要观点

[01:19:52] swyx：好吧，我有个问题，你希望听众今天能带走什么主要信息？

[01:19:56] Raza Habib：如果你正在开发一个重要的 LLM 应用，并试图寻找和优化提示，评估模型的话，我强烈推荐你试试 HumanLoop，尤其是在与非技术人员合作时，HumanLoop 能极大地帮助你。

[01:20:18] swyx：谢谢你的分享，我很高兴能认识你和你一起解决实际问题。

[01:20:24] 这就是潜在空间的乐趣，非常感谢。

[01:20:27] Raza Habib：谢谢你的邀请，Shawn，很高兴与你共度时光。

[01:20:30] AI Anna：在 Latent Space Podcast 的这一期节目中，我们深入探讨了 LLM Ops，并与 HumanLoop 的联合创始人 Raza Habib 博士进行了深刻的对话，包括 HumanLoop 的相关内容，提示评估的三个阶段，人类反馈的三种类型，HumanLoop 的新免费层和价格策略，以及与 HumanLoop 竞争的公司，PromptOps 与 MLops，PromptEngineer 与 AI Engineer 的区别等。

[01:21:00] GPT-4 变蠢了吗？欧洲的 AI 场景和旧金山相比如何？别错过 Rasa 深刻剖析的 LLM 层叠和 DeepMind 的持续学习研究。如果 Human Loop 吸引了你的注意，记得查看他们的招聘信息和新定价，同时也别忘了在 AI 工程状态调查中支持他们。

[01:21:19] 感谢你收听 Latent Space 播客，别忘了点赞、订阅，并在推特上用 Latent Space Pod 标签分享你的看法。动手去创造吧！

